Loading training data...
Using 19 files out of 198 (10.0% of dataset)
Found 19 matching SSM-LB file pairs
Loading all data into memory for balanced sampling...
Found 19 files to process
Added 3475 points to the memory
Loaded 1001: 3475 annotated points; (excluded 0 non-annotated)
Loaded 1001: 3475 points
Added 18827 points to the memory
Loaded 2435: 18827 annotated points; (excluded 0 non-annotated)
Loaded 2435: 18827 points
Added 8117 points to the memory
Loaded 1611: 8117 annotated points; (excluded 0 non-annotated)
Loaded 1611: 8117 points
Added 14604 points to the memory
Loaded 1840: 14604 annotated points; (excluded 0 non-annotated)
Loaded 1840: 14604 points
Added 9144 points to the memory
Loaded 1751: 9144 annotated points; (excluded 0 non-annotated)
Loaded 1751: 9144 points
Added 12789 points to the memory
Loaded 0746: 12789 annotated points; (excluded 0 non-annotated)
Loaded 0746: 12789 points
Added 15410 points to the memory
Loaded 0513: 15410 annotated points; (excluded 0 non-annotated)
Loaded 0513: 15410 points
Added 22256 points to the memory
Loaded 1173: 22256 annotated points; (excluded 0 non-annotated)
Loaded 1173: 22256 points
Added 10978 points to the memory
Loaded 1761: 10978 annotated points; (excluded 0 non-annotated)
Loaded 1761: 10978 points
Added 10196 points to the memory
Loaded 1226: 10196 annotated points; (excluded 0 non-annotated)
Loaded 1226: 10196 points
Added 6734 points to the memory
Loaded 0189: 6734 annotated points; (excluded 0 non-annotated)
Loaded 0189: 6734 points
Added 12747 points to the memory
Loaded 0654: 12747 annotated points; (excluded 0 non-annotated)
Loaded 0654: 12747 points
Added 2750 points to the memory
Loaded 1608: 2750 annotated points; (excluded 0 non-annotated)
Loaded 1608: 2750 points
Added 11288 points to the memory
Loaded 0233: 11288 annotated points; (excluded 0 non-annotated)
Loaded 0233: 11288 points
Added 12802 points to the memory
Loaded 1627: 12802 annotated points; (excluded 0 non-annotated)
Loaded 1627: 12802 points
Added 11286 points to the memory
Loaded 2690: 11286 annotated points; (excluded 0 non-annotated)
Loaded 2690: 11286 points
Added 9075 points to the memory
Loaded 1739: 9075 annotated points; (excluded 0 non-annotated)
Loaded 1739: 9075 points
Added 7018 points to the memory
Loaded 2714: 7018 annotated points; (excluded 0 non-annotated)
Loaded 2714: 7018 points
Added 7735 points to the memory
Loaded 0871: 7735 annotated points; (excluded 0 non-annotated)
Loaded 0871: 7735 points

=== Data Loading Summary ===
Total points in dataset: 207231
Non-annotated points (excluded): 0
Annotated points (kept for training): 207231
Filtering ratio: 100.00%

=== Class Distribution ===
Class 0 (non-edge): 194659 points (93.93%)
Class 1 (edge): 12572 points (6.07%)
== Preparing balanced points... ==
Class 0: 194659 points
Class 1: 12572 points
Maximum class size: 194659
Class 0: replicated to 194659 points
Class 1: replicated to 194659 points
Total balanced pool size: 389318
== Finish Preparing balanced points... ==
Found 50 matching SSM-LB file pairs
Loading all data into memory for balanced sampling...
Found 50 files to process
Added 18826 points to the memory
Loaded 2139: 18826 annotated points; (excluded 0 non-annotated)
Loaded 2139: 18826 points
Added 16623 points to the memory
Loaded 1155: 16623 annotated points; (excluded 0 non-annotated)
Loaded 1155: 16623 points
Added 16137 points to the memory
Loaded 0994: 16137 annotated points; (excluded 0 non-annotated)
Loaded 0994: 16137 points
Added 10499 points to the memory
Loaded 1884: 10499 annotated points; (excluded 0 non-annotated)
Loaded 1884: 10499 points
Added 19659 points to the memory
Loaded 1051: 19659 annotated points; (excluded 0 non-annotated)
Loaded 1051: 19659 points
Added 22574 points to the memory
Loaded 2465: 22574 annotated points; (excluded 0 non-annotated)
Loaded 2465: 22574 points
Added 1555 points to the memory
Loaded 2117: 1555 annotated points; (excluded 0 non-annotated)
Loaded 2117: 1555 points
Added 16478 points to the memory
Loaded 1957: 16478 annotated points; (excluded 0 non-annotated)
Loaded 1957: 16478 points
Added 20205 points to the memory
Loaded 2431: 20205 annotated points; (excluded 0 non-annotated)
Loaded 2431: 20205 points
Added 22028 points to the memory
Loaded 2248: 22028 annotated points; (excluded 0 non-annotated)
Loaded 2248: 22028 points
Added 11879 points to the memory
Loaded 0576: 11879 annotated points; (excluded 0 non-annotated)
Loaded 0576: 11879 points
Added 15903 points to the memory
Loaded 0277: 15903 annotated points; (excluded 0 non-annotated)
Loaded 0277: 15903 points
Added 16339 points to the memory
Loaded 2038: 16339 annotated points; (excluded 0 non-annotated)
Loaded 2038: 16339 points
Added 8263 points to the memory
Loaded 1402: 8263 annotated points; (excluded 0 non-annotated)
Loaded 1402: 8263 points
Added 8242 points to the memory
Loaded 1534: 8242 annotated points; (excluded 0 non-annotated)
Loaded 1534: 8242 points
Added 10371 points to the memory
Loaded 0844: 10371 annotated points; (excluded 0 non-annotated)
Loaded 0844: 10371 points
Added 7601 points to the memory
Loaded 1384: 7601 annotated points; (excluded 0 non-annotated)
Loaded 1384: 7601 points
Added 1798 points to the memory
Loaded 1612: 1798 annotated points; (excluded 0 non-annotated)
Loaded 1612: 1798 points
Added 5238 points to the memory
Loaded 1672: 5238 annotated points; (excluded 0 non-annotated)
Loaded 1672: 5238 points
Added 2327 points to the memory
Loaded 1258: 2327 annotated points; (excluded 0 non-annotated)
Loaded 1258: 2327 points
Added 10681 points to the memory
Loaded 0402: 10681 annotated points; (excluded 0 non-annotated)
Loaded 0402: 10681 points
Added 8263 points to the memory
Loaded 2572: 8263 annotated points; (excluded 0 non-annotated)
Loaded 2572: 8263 points
Added 24817 points to the memory
Loaded 0667: 24817 annotated points; (excluded 0 non-annotated)
Loaded 0667: 24817 points
Added 11949 points to the memory
Loaded 2703: 11949 annotated points; (excluded 0 non-annotated)
Loaded 2703: 11949 points
Added 6738 points to the memory
Loaded 2192: 6738 annotated points; (excluded 0 non-annotated)
Loaded 2192: 6738 points
Added 34340 points to the memory
Loaded 0353: 34340 annotated points; (excluded 0 non-annotated)
Loaded 0353: 34340 points
Added 1950 points to the memory
Loaded 0939: 1950 annotated points; (excluded 0 non-annotated)
Loaded 0939: 1950 points
Added 16446 points to the memory
Loaded 0643: 16446 annotated points; (excluded 0 non-annotated)
Loaded 0643: 16446 points
Added 17117 points to the memory
Loaded 1813: 17117 annotated points; (excluded 0 non-annotated)
Loaded 1813: 17117 points
Added 17431 points to the memory
Loaded 1937: 17431 annotated points; (excluded 0 non-annotated)
Loaded 1937: 17431 points
Added 5520 points to the memory
Loaded 0198: 5520 annotated points; (excluded 0 non-annotated)
Loaded 0198: 5520 points
Added 23925 points to the memory
Loaded 2775: 23925 annotated points; (excluded 0 non-annotated)
Loaded 2775: 23925 points
Added 9086 points to the memory
Loaded 0487: 9086 annotated points; (excluded 0 non-annotated)
Loaded 0487: 9086 points
Added 27164 points to the memory
Loaded 1716: 27164 annotated points; (excluded 0 non-annotated)
Loaded 1716: 27164 points
Added 13974 points to the memory
Loaded 1323: 13974 annotated points; (excluded 0 non-annotated)
Loaded 1323: 13974 points
Added 27323 points to the memory
Loaded 1217: 27323 annotated points; (excluded 0 non-annotated)
Loaded 1217: 27323 points
Added 8124 points to the memory
Loaded 2337: 8124 annotated points; (excluded 0 non-annotated)
Loaded 2337: 8124 points
Added 1004 points to the memory
Loaded 0713: 1004 annotated points; (excluded 0 non-annotated)
Loaded 0713: 1004 points
Added 18663 points to the memory
Loaded 2667: 18663 annotated points; (excluded 0 non-annotated)
Loaded 2667: 18663 points
Added 4867 points to the memory
Loaded 2738: 4867 annotated points; (excluded 0 non-annotated)
Loaded 2738: 4867 points
Added 12716 points to the memory
Loaded 0091: 12716 annotated points; (excluded 0 non-annotated)
Loaded 0091: 12716 points
Added 9583 points to the memory
Loaded 2392: 9583 annotated points; (excluded 0 non-annotated)
Loaded 2392: 9583 points
Added 25136 points to the memory
Loaded 2507: 25136 annotated points; (excluded 0 non-annotated)
Loaded 2507: 25136 points
Added 1950 points to the memory
Loaded 1594: 1950 annotated points; (excluded 0 non-annotated)
Loaded 1594: 1950 points
Added 29317 points to the memory
Loaded 1743: 29317 annotated points; (excluded 0 non-annotated)
Loaded 1743: 29317 points
Added 12841 points to the memory
Loaded 0541: 12841 annotated points; (excluded 0 non-annotated)
Loaded 0541: 12841 points
Added 1454 points to the memory
Loaded 1106: 1454 annotated points; (excluded 0 non-annotated)
Loaded 1106: 1454 points
Added 26287 points to the memory
Loaded 0008: 26287 annotated points; (excluded 0 non-annotated)
Loaded 0008: 26287 points
Added 22419 points to the memory
Loaded 1433: 22419 annotated points; (excluded 0 non-annotated)
Loaded 1433: 22419 points
Added 6581 points to the memory
Loaded 0138: 6581 annotated points; (excluded 0 non-annotated)
Loaded 0138: 6581 points

=== Data Loading Summary ===
Total points in dataset: 690211
Non-annotated points (excluded): 0
Annotated points (kept for training): 690211
Filtering ratio: 100.00%

=== Class Distribution ===
Class 0 (non-edge): 650122 points (94.19%)
Class 1 (edge): 40089 points (5.81%)
Training data shape: (391168, 320)
Validation data shape: (692224, 320)
Training labels distribution: [195584 195584]
Grouping features by descriptors...
After grouping - Training data shape: (391168, 20)
After grouping - Validation data shape: (692224, 20)
Starting RL training...
============================================================

--- Episode 1/50 ---
Episode 1 - Epsilon: 1.000 (100.0% random, 0.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 9
  New selection: [9]
  Calculating reward for descriptors: [9]
  Total reward: 1.2022, Per descriptor: 1.2022
Step 1: Currently selected descriptors: [9]
  Action chosen: ADD descriptor 6
  New selection: [6, 9]
  Calculating reward for descriptors: [6, 9]
  Total reward: -4.6514, Per descriptor: -2.3257
Step 2: Currently selected descriptors: [6, 9]
  Action chosen: ADD descriptor 3
  New selection: [3, 6, 9]
  Calculating reward for descriptors: [3, 6, 9]
  Total reward: -4.6189, Per descriptor: -1.5396
Step 3: Currently selected descriptors: [3, 6, 9]
  Action chosen: ADD descriptor 7
  New selection: [3, 6, 7, 9]
  Calculating reward for descriptors: [3, 6, 7, 9]
  Total reward: -4.3484, Per descriptor: -1.0871
Step 4: Currently selected descriptors: [3, 6, 7, 9]
  Action chosen: ADD descriptor 4
  New selection: [3, 4, 6, 7, 9]
  Calculating reward for descriptors: [3, 4, 6, 7, 9]
  Total reward: -4.3635, Per descriptor: -0.8727
Step 5: Currently selected descriptors: [3, 4, 6, 7, 9]
  Action chosen: REMOVE descriptor 3
  New selection: [4, 6, 7, 9]
  Calculating reward for descriptors: [4, 6, 7, 9]
  Total reward: -4.3761, Per descriptor: -1.0940
Step 6: Currently selected descriptors: [4, 6, 7, 9]
  Action chosen: ADD descriptor 16
  New selection: [4, 6, 7, 9, 16]
  Calculating reward for descriptors: [4, 6, 7, 9, 16]
  Total reward: -4.3926, Per descriptor: -0.8785
Step 7: Currently selected descriptors: [4, 6, 7, 9, 16]
  Action chosen: ADD descriptor 13
  New selection: [4, 6, 7, 9, 13, 16]
  Calculating reward for descriptors: [4, 6, 7, 9, 13, 16]
  Total reward: -4.4655, Per descriptor: -0.7443
Step 8: Currently selected descriptors: [4, 6, 7, 9, 13, 16]
  Action chosen: ADD descriptor 15
  New selection: [4, 6, 7, 9, 13, 15, 16]
  Calculating reward for descriptors: [4, 6, 7, 9, 13, 15, 16]
  Total reward: -4.5492, Per descriptor: -0.6499
Step 9: Currently selected descriptors: [4, 6, 7, 9, 13, 15, 16]
  Action chosen: ADD descriptor 17
  New selection: [4, 6, 7, 9, 13, 15, 16, 17]
  Calculating reward for descriptors: [4, 6, 7, 9, 13, 15, 16, 17]
  Total reward: -4.5053, Per descriptor: -0.5632
Step 10: Currently selected descriptors: [4, 6, 7, 9, 13, 15, 16, 17]
  Action chosen: ADD descriptor 1
  New selection: [1, 4, 6, 7, 9, 13, 15, 16, 17]
  Calculating reward for descriptors: [1, 4, 6, 7, 9, 13, 15, 16, 17]
  Total reward: -4.5156, Per descriptor: -0.5017
Step 11: Currently selected descriptors: [1, 4, 6, 7, 9, 13, 15, 16, 17]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 4, 6, 7, 9, 13, 15, 17]
  Calculating reward for descriptors: [1, 4, 6, 7, 9, 13, 15, 17]
  Total reward: -4.4988, Per descriptor: -0.5624
Step 12: Currently selected descriptors: [1, 4, 6, 7, 9, 13, 15, 17]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 4, 6, 7, 9, 13, 17]
  Calculating reward for descriptors: [1, 4, 6, 7, 9, 13, 17]
  Total reward: -4.5218, Per descriptor: -0.6460
Step 13: Currently selected descriptors: [1, 4, 6, 7, 9, 13, 17]
  Action chosen: ADD descriptor 16
  New selection: [1, 4, 6, 7, 9, 13, 16, 17]
  Calculating reward for descriptors: [1, 4, 6, 7, 9, 13, 16, 17]
  Total reward: -4.4864, Per descriptor: -0.5608
Step 14: Currently selected descriptors: [1, 4, 6, 7, 9, 13, 16, 17]
  Action chosen: ADD descriptor 8
  New selection: [1, 4, 6, 7, 8, 9, 13, 16, 17]
  Calculating reward for descriptors: [1, 4, 6, 7, 8, 9, 13, 16, 17]
  Total reward: -4.5011, Per descriptor: -0.5001
Step 15: Currently selected descriptors: [1, 4, 6, 7, 8, 9, 13, 16, 17]
  Action chosen: ADD descriptor 5
  New selection: [1, 4, 5, 6, 7, 8, 9, 13, 16, 17]
  Calculating reward for descriptors: [1, 4, 5, 6, 7, 8, 9, 13, 16, 17]
  Total reward: -4.4786, Per descriptor: -0.4479
Step 16: Currently selected descriptors: [1, 4, 5, 6, 7, 8, 9, 13, 16, 17]
  Action chosen: REMOVE descriptor 9
  New selection: [1, 4, 5, 6, 7, 8, 13, 16, 17]
  Calculating reward for descriptors: [1, 4, 5, 6, 7, 8, 13, 16, 17]
  Total reward: -4.4462, Per descriptor: -0.4940
Step 17: Currently selected descriptors: [1, 4, 5, 6, 7, 8, 13, 16, 17]
  Action chosen: ADD descriptor 14
  New selection: [1, 4, 5, 6, 7, 8, 13, 14, 16, 17]
  Calculating reward for descriptors: [1, 4, 5, 6, 7, 8, 13, 14, 16, 17]
  Total reward: -4.3923, Per descriptor: -0.4392
Step 18: Currently selected descriptors: [1, 4, 5, 6, 7, 8, 13, 14, 16, 17]
  Action chosen: REMOVE descriptor 17
  New selection: [1, 4, 5, 6, 7, 8, 13, 14, 16]
  Calculating reward for descriptors: [1, 4, 5, 6, 7, 8, 13, 14, 16]
  Total reward: -4.3790, Per descriptor: -0.4866
Step 19: Currently selected descriptors: [1, 4, 5, 6, 7, 8, 13, 14, 16]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 4, 6, 7, 8, 13, 14, 16]
  Calculating reward for descriptors: [1, 4, 6, 7, 8, 13, 14, 16]
  Total reward: -4.3802, Per descriptor: -0.5475
Step 20: Currently selected descriptors: [1, 4, 6, 7, 8, 13, 14, 16]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 4, 6, 7, 8, 13, 14, 16]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 13, 14, 16]
  Total reward: -4.4071, Per descriptor: -0.4897
Step 21: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 13, 14, 16]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 2, 4, 6, 8, 13, 14, 16]
  Calculating reward for descriptors: [1, 2, 4, 6, 8, 13, 14, 16]
  Total reward: -4.4320, Per descriptor: -0.5540
Step 22: Currently selected descriptors: [1, 2, 4, 6, 8, 13, 14, 16]
  Action chosen: REMOVE descriptor 8
  New selection: [1, 2, 4, 6, 13, 14, 16]
  Calculating reward for descriptors: [1, 2, 4, 6, 13, 14, 16]
  Total reward: -4.4309, Per descriptor: -0.6330
Step 23: Currently selected descriptors: [1, 2, 4, 6, 13, 14, 16]
  Action chosen: STOP
  Agent chose to STOP
  Updated target network weights
  NEW BEST! Reward: -96.9386 with 7 descriptors
Episode 1 Summary:
  Total reward: -96.9386
  Steps taken: 23
  Final descriptors: 7
  Epsilon: 0.995 (99.5% random, 0.5% DQN)
  Avg last 10 episodes: -96.9386
  Best so far: -96.9386 (7 descriptors)

--- Episode 2/50 ---
Episode 2 - Epsilon: 0.995 (99.5% random, 0.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 5
  New selection: [5]
  Calculating reward for descriptors: [5]
  Total reward: 1.4590, Per descriptor: 1.4590
Step 1: Currently selected descriptors: [5]
  Action chosen: ADD descriptor 16
  New selection: [5, 16]
  Calculating reward for descriptors: [5, 16]
  Total reward: -4.1722, Per descriptor: -2.0861
Step 2: Currently selected descriptors: [5, 16]
  Action chosen: ADD descriptor 17
  New selection: [5, 16, 17]
  Calculating reward for descriptors: [5, 16, 17]
  Total reward: -4.2911, Per descriptor: -1.4304
Step 3: Currently selected descriptors: [5, 16, 17]
  Action chosen: ADD descriptor 2
  New selection: [2, 5, 16, 17]
  Calculating reward for descriptors: [2, 5, 16, 17]
  Total reward: -4.4721, Per descriptor: -1.1180
Step 4: Currently selected descriptors: [2, 5, 16, 17]
  Action chosen: ADD descriptor 4
  New selection: [2, 4, 5, 16, 17]
  Calculating reward for descriptors: [2, 4, 5, 16, 17]
  Total reward: -4.4623, Per descriptor: -0.8925
Step 5: Currently selected descriptors: [2, 4, 5, 16, 17]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 4, 5, 16, 17]
  Calculating reward for descriptors: [0, 2, 4, 5, 16, 17]
  Total reward: -4.4939, Per descriptor: -0.7490
Step 6: Currently selected descriptors: [0, 2, 4, 5, 16, 17]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 4, 5, 16, 17]
  Calculating reward for descriptors: [2, 4, 5, 16, 17]
  Total reward: -4.4623, Per descriptor: -0.8925
Step 7: Currently selected descriptors: [2, 4, 5, 16, 17]
  Action chosen: ADD descriptor 14
  New selection: [2, 4, 5, 14, 16, 17]
  Calculating reward for descriptors: [2, 4, 5, 14, 16, 17]
  Total reward: -4.3732, Per descriptor: -0.7289
Step 8: Currently selected descriptors: [2, 4, 5, 14, 16, 17]
  Action chosen: ADD descriptor 3
  New selection: [2, 3, 4, 5, 14, 16, 17]
  Calculating reward for descriptors: [2, 3, 4, 5, 14, 16, 17]
  Total reward: -4.3874, Per descriptor: -0.6268
Step 9: Currently selected descriptors: [2, 3, 4, 5, 14, 16, 17]
  Action chosen: ADD descriptor 8
  New selection: [2, 3, 4, 5, 8, 14, 16, 17]
  Calculating reward for descriptors: [2, 3, 4, 5, 8, 14, 16, 17]
  Total reward: -4.3660, Per descriptor: -0.5458
Step 10: Currently selected descriptors: [2, 3, 4, 5, 8, 14, 16, 17]
  Action chosen: ADD descriptor 18
  New selection: [2, 3, 4, 5, 8, 14, 16, 17, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 8, 14, 16, 17, 18]
  Total reward: -4.4045, Per descriptor: -0.4894
Step 11: Currently selected descriptors: [2, 3, 4, 5, 8, 14, 16, 17, 18]
  Action chosen: ADD descriptor 11
  New selection: [2, 3, 4, 5, 8, 11, 14, 16, 17, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 8, 11, 14, 16, 17, 18]
  Total reward: -4.3756, Per descriptor: -0.4376
Step 12: Currently selected descriptors: [2, 3, 4, 5, 8, 11, 14, 16, 17, 18]
  Action chosen: ADD descriptor 9
  New selection: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Total reward: -4.3887, Per descriptor: -0.3990
Step 13: Currently selected descriptors: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Action chosen: REMOVE descriptor 4
  New selection: [2, 3, 5, 8, 9, 11, 14, 16, 17, 18]
  Calculating reward for descriptors: [2, 3, 5, 8, 9, 11, 14, 16, 17, 18]
  Total reward: -4.3890, Per descriptor: -0.4389
Step 14: Currently selected descriptors: [2, 3, 5, 8, 9, 11, 14, 16, 17, 18]
  Action chosen: ADD descriptor 4
  New selection: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Total reward: -4.3887, Per descriptor: -0.3990
Step 15: Currently selected descriptors: [2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Total reward: -4.4249, Per descriptor: -0.3687
Step 16: Currently selected descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18]
  Action chosen: ADD descriptor 19
  New selection: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18, 19]
  Total reward: -4.4160, Per descriptor: -0.3397
Step 17: Currently selected descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 16, 17, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [1, 2, 3, 4, 5, 8, 9, 11, 14, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 15, 16, 17, 18, 19]
  Total reward: -4.4140, Per descriptor: -0.3153
Step 18: Currently selected descriptors: [1, 2, 3, 4, 5, 8, 9, 11, 14, 15, 16, 17, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [1, 2, 3, 4, 5, 6, 8, 9, 11, 14, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 6, 8, 9, 11, 14, 15, 16, 17, 18, 19]
  Total reward: -4.4278, Per descriptor: -0.2952
  Reached maximum descriptors limit
  Training DQN with 42 experiences...
  DQN training loss: 20549428.000000
  NEW BEST! Reward: -77.6509 with 15 descriptors
Episode 2 Summary:
  Total reward: -77.6509
  Steps taken: 19
  Final descriptors: 15
  Epsilon: 0.990 (99.0% random, 1.0% DQN)
  Avg last 10 episodes: -87.2948
  Best so far: -77.6509 (15 descriptors)

--- Episode 3/50 ---
Episode 3 - Epsilon: 0.990 (99.0% random, 1.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 2
  New selection: [2]
  Calculating reward for descriptors: [2]
  Total reward: 1.5826, Per descriptor: 1.5826
Step 1: Currently selected descriptors: [2]
  Action chosen: ADD descriptor 9
  New selection: [2, 9]
  Calculating reward for descriptors: [2, 9]
  Total reward: -4.6174, Per descriptor: -2.3087
Step 2: Currently selected descriptors: [2, 9]
  Action chosen: ADD descriptor 10
  New selection: [2, 9, 10]
  Calculating reward for descriptors: [2, 9, 10]
  Total reward: -4.7162, Per descriptor: -1.5721
Step 3: Currently selected descriptors: [2, 9, 10]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 9, 10]
  Calculating reward for descriptors: [1, 2, 9, 10]
  Total reward: -4.7180, Per descriptor: -1.1795
Step 4: Currently selected descriptors: [1, 2, 9, 10]
  Action chosen: ADD descriptor 18
  New selection: [1, 2, 9, 10, 18]
  Calculating reward for descriptors: [1, 2, 9, 10, 18]
  Total reward: -4.7015, Per descriptor: -0.9403
Step 5: Currently selected descriptors: [1, 2, 9, 10, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 2, 9, 10]
  Calculating reward for descriptors: [1, 2, 9, 10]
  Total reward: -4.7221, Per descriptor: -1.1805
Step 6: Currently selected descriptors: [1, 2, 9, 10]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 48 experiences...
  DQN training loss: 12466399.000000
  NEW BEST! Reward: -21.8927 with 4 descriptors
Episode 3 Summary:
  Total reward: -21.8927
  Steps taken: 6
  Final descriptors: 4
  Epsilon: 0.985 (98.5% random, 1.5% DQN)
  Avg last 10 episodes: -65.4941
  Best so far: -21.8927 (4 descriptors)

--- Episode 4/50 ---
Episode 4 - Epsilon: 0.985 (98.5% random, 1.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 14
  New selection: [14]
  Calculating reward for descriptors: [14]
  Total reward: 1.4364, Per descriptor: 1.4364
Step 1: Currently selected descriptors: [14]
  Action chosen: ADD descriptor 6
  New selection: [6, 14]
  Calculating reward for descriptors: [6, 14]
  Total reward: -4.2901, Per descriptor: -2.1451
Step 2: Currently selected descriptors: [6, 14]
  Action chosen: ADD descriptor 4
  New selection: [4, 6, 14]
  Calculating reward for descriptors: [4, 6, 14]
  Total reward: -4.3854, Per descriptor: -1.4618
Step 3: Currently selected descriptors: [4, 6, 14]
  Action chosen: ADD descriptor 7
  New selection: [4, 6, 7, 14]
  Calculating reward for descriptors: [4, 6, 7, 14]
  Total reward: -4.2611, Per descriptor: -1.0653
Step 4: Currently selected descriptors: [4, 6, 7, 14]
  Action chosen: ADD descriptor 2
  New selection: [2, 4, 6, 7, 14]
  Calculating reward for descriptors: [2, 4, 6, 7, 14]
  Total reward: -4.3335, Per descriptor: -0.8667
Step 5: Currently selected descriptors: [2, 4, 6, 7, 14]
  Action chosen: ADD descriptor 13
  New selection: [2, 4, 6, 7, 13, 14]
  Calculating reward for descriptors: [2, 4, 6, 7, 13, 14]
  Total reward: -4.3504, Per descriptor: -0.7251
Step 6: Currently selected descriptors: [2, 4, 6, 7, 13, 14]
  Action chosen: ADD descriptor 15
  New selection: [2, 4, 6, 7, 13, 14, 15]
  Calculating reward for descriptors: [2, 4, 6, 7, 13, 14, 15]
  Total reward: -4.3849, Per descriptor: -0.6264
Step 7: Currently selected descriptors: [2, 4, 6, 7, 13, 14, 15]
  Action chosen: REMOVE descriptor 6
  New selection: [2, 4, 7, 13, 14, 15]
  Calculating reward for descriptors: [2, 4, 7, 13, 14, 15]
  Total reward: -4.3674, Per descriptor: -0.7279
Step 8: Currently selected descriptors: [2, 4, 7, 13, 14, 15]
  Action chosen: ADD descriptor 8
  New selection: [2, 4, 7, 8, 13, 14, 15]
  Calculating reward for descriptors: [2, 4, 7, 8, 13, 14, 15]
  Total reward: -4.3782, Per descriptor: -0.6255
Step 9: Currently selected descriptors: [2, 4, 7, 8, 13, 14, 15]
  Action chosen: ADD descriptor 3
  New selection: [2, 3, 4, 7, 8, 13, 14, 15]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 13, 14, 15]
  Total reward: -4.3632, Per descriptor: -0.5454
Step 10: Currently selected descriptors: [2, 3, 4, 7, 8, 13, 14, 15]
  Action chosen: REMOVE descriptor 15
  New selection: [2, 3, 4, 7, 8, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 13, 14]
  Total reward: -4.3450, Per descriptor: -0.6207
Step 11: Currently selected descriptors: [2, 3, 4, 7, 8, 13, 14]
  Action chosen: ADD descriptor 11
  New selection: [2, 3, 4, 7, 8, 11, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Total reward: -4.4845, Per descriptor: -0.5606
Step 12: Currently selected descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Action chosen: ADD descriptor 17
  New selection: [2, 3, 4, 7, 8, 11, 13, 14, 17]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 11, 13, 14, 17]
  Total reward: -4.4778, Per descriptor: -0.4975
Step 13: Currently selected descriptors: [2, 3, 4, 7, 8, 11, 13, 14, 17]
  Action chosen: REMOVE descriptor 17
  New selection: [2, 3, 4, 7, 8, 11, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Total reward: -4.4845, Per descriptor: -0.5606
Step 14: Currently selected descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Action chosen: REMOVE descriptor 4
  New selection: [2, 3, 7, 8, 11, 13, 14]
  Calculating reward for descriptors: [2, 3, 7, 8, 11, 13, 14]
  Total reward: -4.5474, Per descriptor: -0.6496
Step 15: Currently selected descriptors: [2, 3, 7, 8, 11, 13, 14]
  Action chosen: ADD descriptor 4
  New selection: [2, 3, 4, 7, 8, 11, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Total reward: -4.4845, Per descriptor: -0.5606
Step 16: Currently selected descriptors: [2, 3, 4, 7, 8, 11, 13, 14]
  Action chosen: ADD descriptor 12
  New selection: [2, 3, 4, 7, 8, 11, 12, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 7, 8, 11, 12, 13, 14]
  Total reward: -4.5303, Per descriptor: -0.5034
Step 17: Currently selected descriptors: [2, 3, 4, 7, 8, 11, 12, 13, 14]
  Action chosen: ADD descriptor 5
  New selection: [2, 3, 4, 5, 7, 8, 11, 12, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 5, 7, 8, 11, 12, 13, 14]
  Total reward: -4.4820, Per descriptor: -0.4482
Step 18: Currently selected descriptors: [2, 3, 4, 5, 7, 8, 11, 12, 13, 14]
  Action chosen: ADD descriptor 10
  New selection: [2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Calculating reward for descriptors: [2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Total reward: -4.4674, Per descriptor: -0.4061
Step 19: Currently selected descriptors: [2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Total reward: -4.4701, Per descriptor: -0.3725
Step 20: Currently selected descriptors: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14]
  Action chosen: ADD descriptor 6
  New selection: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14]
  Total reward: -4.4760, Per descriptor: -0.3443
Step 21: Currently selected descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14]
  Action chosen: ADD descriptor 18
  New selection: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]
  Total reward: -4.4855, Per descriptor: -0.3204
Step 22: Currently selected descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]
  Calculating reward for descriptors: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]
  Total reward: -4.4860, Per descriptor: -0.2991
  Reached maximum descriptors limit
  Training DQN with 71 experiences...
  DQN training loss: 16294710.000000
Episode 4 Summary:
  Total reward: -95.8985
  Steps taken: 23
  Final descriptors: 15
  Epsilon: 0.980 (98.0% random, 2.0% DQN)
  Avg last 10 episodes: -73.0952
  Best so far: -21.8927 (4 descriptors)

--- Episode 5/50 ---
Episode 5 - Epsilon: 0.980 (98.0% random, 2.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: ADD descriptor 9
  New selection: [9, 16]
  Calculating reward for descriptors: [9, 16]
  Total reward: -4.2658, Per descriptor: -2.1329
Step 2: Currently selected descriptors: [9, 16]
  Action chosen: ADD descriptor 4
  New selection: [4, 9, 16]
  Calculating reward for descriptors: [4, 9, 16]
  Total reward: -4.2771, Per descriptor: -1.4257
Step 3: Currently selected descriptors: [4, 9, 16]
  Action chosen: ADD descriptor 6
  New selection: [4, 6, 9, 16]
  Calculating reward for descriptors: [4, 6, 9, 16]
  Total reward: -4.3600, Per descriptor: -1.0900
Step 4: Currently selected descriptors: [4, 6, 9, 16]
  Action chosen: REMOVE descriptor 9
  New selection: [4, 6, 16]
  Calculating reward for descriptors: [4, 6, 16]
  Total reward: -4.3461, Per descriptor: -1.4487
Step 5: Currently selected descriptors: [4, 6, 16]
  Action chosen: ADD descriptor 14
  New selection: [4, 6, 14, 16]
  Calculating reward for descriptors: [4, 6, 14, 16]
  Total reward: -4.2550, Per descriptor: -1.0637
Step 6: Currently selected descriptors: [4, 6, 14, 16]
  Action chosen: ADD descriptor 5
  New selection: [4, 5, 6, 14, 16]
  Calculating reward for descriptors: [4, 5, 6, 14, 16]
  Total reward: -4.3170, Per descriptor: -0.8634
Step 7: Currently selected descriptors: [4, 5, 6, 14, 16]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 5, 6, 14, 16]
  Calculating reward for descriptors: [0, 4, 5, 6, 14, 16]
  Total reward: -4.3483, Per descriptor: -0.7247
Step 8: Currently selected descriptors: [0, 4, 5, 6, 14, 16]
  Action chosen: ADD descriptor 13
  New selection: [0, 4, 5, 6, 13, 14, 16]
  Calculating reward for descriptors: [0, 4, 5, 6, 13, 14, 16]
  Total reward: -4.3540, Per descriptor: -0.6220
Step 9: Currently selected descriptors: [0, 4, 5, 6, 13, 14, 16]
  Action chosen: ADD descriptor 10
  New selection: [0, 4, 5, 6, 10, 13, 14, 16]
  Calculating reward for descriptors: [0, 4, 5, 6, 10, 13, 14, 16]
  Total reward: -4.3885, Per descriptor: -0.5486
Step 10: Currently selected descriptors: [0, 4, 5, 6, 10, 13, 14, 16]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 4, 5, 10, 13, 14, 16]
  Calculating reward for descriptors: [0, 4, 5, 10, 13, 14, 16]
  Total reward: -4.3454, Per descriptor: -0.6208
Step 11: Currently selected descriptors: [0, 4, 5, 10, 13, 14, 16]
  Action chosen: ADD descriptor 19
  New selection: [0, 4, 5, 10, 13, 14, 16, 19]
  Calculating reward for descriptors: [0, 4, 5, 10, 13, 14, 16, 19]
  Total reward: -4.3429, Per descriptor: -0.5429
Step 12: Currently selected descriptors: [0, 4, 5, 10, 13, 14, 16, 19]
  Action chosen: ADD descriptor 2
  New selection: [0, 2, 4, 5, 10, 13, 14, 16, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 10, 13, 14, 16, 19]
  Total reward: -4.3917, Per descriptor: -0.4880
Step 13: Currently selected descriptors: [0, 2, 4, 5, 10, 13, 14, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 2, 4, 5, 10, 13, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 10, 13, 14, 16, 18, 19]
  Total reward: -4.4246, Per descriptor: -0.4425
Step 14: Currently selected descriptors: [0, 2, 4, 5, 10, 13, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 2, 4, 5, 13, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 13, 14, 16, 18, 19]
  Total reward: -4.4032, Per descriptor: -0.4892
Step 15: Currently selected descriptors: [0, 2, 4, 5, 13, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 2, 4, 5, 13, 14, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 13, 14, 18, 19]
  Total reward: -4.4629, Per descriptor: -0.5579
Step 16: Currently selected descriptors: [0, 2, 4, 5, 13, 14, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 2, 4, 5, 6, 13, 14, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 6, 13, 14, 18, 19]
  Total reward: -4.5003, Per descriptor: -0.5000
Step 17: Currently selected descriptors: [0, 2, 4, 5, 6, 13, 14, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 2, 4, 5, 6, 7, 13, 14, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 6, 7, 13, 14, 18, 19]
  Total reward: -4.4342, Per descriptor: -0.4434
Step 18: Currently selected descriptors: [0, 2, 4, 5, 6, 7, 13, 14, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Total reward: -4.4226, Per descriptor: -0.4021
Step 19: Currently selected descriptors: [0, 2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Total reward: -4.4088, Per descriptor: -0.4409
Step 20: Currently selected descriptors: [2, 4, 5, 6, 7, 12, 13, 14, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [2, 4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [2, 4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Total reward: -4.4001, Per descriptor: -0.4000
Step 21: Currently selected descriptors: [2, 4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Total reward: -4.3864, Per descriptor: -0.4386
Step 22: Currently selected descriptors: [4, 5, 6, 7, 8, 12, 13, 14, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [4, 5, 6, 7, 8, 12, 13, 14, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 12, 13, 14, 19]
  Total reward: -4.3535, Per descriptor: -0.4837
Step 23: Currently selected descriptors: [4, 5, 6, 7, 8, 12, 13, 14, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [4, 5, 6, 7, 8, 12, 14, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 12, 14, 19]
  Total reward: -4.3285, Per descriptor: -0.5411
Step 24: Currently selected descriptors: [4, 5, 6, 7, 8, 12, 14, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 4, 5, 6, 7, 8, 12, 14, 19]
  Calculating reward for descriptors: [2, 4, 5, 6, 7, 8, 12, 14, 19]
  Total reward: -4.3540, Per descriptor: -0.4838
Step 25: Currently selected descriptors: [2, 4, 5, 6, 7, 8, 12, 14, 19]
  Action chosen: ADD descriptor 17
  New selection: [2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Calculating reward for descriptors: [2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Total reward: -4.3781, Per descriptor: -0.4378
Step 26: Currently selected descriptors: [2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Total reward: -4.4175, Per descriptor: -0.4016
Step 27: Currently selected descriptors: [1, 2, 4, 5, 6, 7, 8, 12, 14, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 2, 4, 6, 7, 8, 12, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 12, 14, 17, 19]
  Total reward: -4.4183, Per descriptor: -0.4418
Step 28: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 12, 14, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [1, 2, 4, 6, 7, 8, 10, 12, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 10, 12, 14, 17, 19]
  Total reward: -4.4388, Per descriptor: -0.4035
Step 29: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 10, 12, 14, 17, 19]
  Action chosen: ADD descriptor 11
  New selection: [1, 2, 4, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Total reward: -4.4969, Per descriptor: -0.3747
Step 30: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Action chosen: ADD descriptor 5
  New selection: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Total reward: -4.4795, Per descriptor: -0.3446
Step 31: Currently selected descriptors: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 14, 17, 19]
  Action chosen: ADD descriptor 13
  New selection: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 19]
  Total reward: -4.4731, Per descriptor: -0.3195
Step 32: Currently selected descriptors: [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 103 experiences...
  DQN training loss: 9156912.000000
Episode 5 Summary:
  Total reward: -134.3783
  Steps taken: 32
  Final descriptors: 14
  Epsilon: 0.975 (97.5% random, 2.5% DQN)
  Avg last 10 episodes: -85.3518
  Best so far: -21.8927 (4 descriptors)

--- Episode 6/50 ---
Episode 6 - Epsilon: 0.975 (97.5% random, 2.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: ADD descriptor 18
  New selection: [16, 18]
  Calculating reward for descriptors: [16, 18]
  Total reward: -4.2372, Per descriptor: -2.1186
Step 2: Currently selected descriptors: [16, 18]
  Action chosen: ADD descriptor 5
  New selection: [5, 16, 18]
  Calculating reward for descriptors: [5, 16, 18]
  Total reward: -4.4425, Per descriptor: -1.4808
Step 3: Currently selected descriptors: [5, 16, 18]
  Action chosen: ADD descriptor 9
  New selection: [5, 9, 16, 18]
  Calculating reward for descriptors: [5, 9, 16, 18]
  Total reward: -4.3927, Per descriptor: -1.0982
Step 4: Currently selected descriptors: [5, 9, 16, 18]
  Action chosen: ADD descriptor 17
  New selection: [5, 9, 16, 17, 18]
  Calculating reward for descriptors: [5, 9, 16, 17, 18]
  Total reward: -4.4184, Per descriptor: -0.8837
Step 5: Currently selected descriptors: [5, 9, 16, 17, 18]
  Action chosen: ADD descriptor 15
  New selection: [5, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [5, 9, 15, 16, 17, 18]
  Total reward: -4.4464, Per descriptor: -0.7411
Step 6: Currently selected descriptors: [5, 9, 15, 16, 17, 18]
  Action chosen: ADD descriptor 6
  New selection: [5, 6, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [5, 6, 9, 15, 16, 17, 18]
  Total reward: -4.4714, Per descriptor: -0.6388
Step 7: Currently selected descriptors: [5, 6, 9, 15, 16, 17, 18]
  Action chosen: ADD descriptor 2
  New selection: [2, 5, 6, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [2, 5, 6, 9, 15, 16, 17, 18]
  Total reward: -4.5004, Per descriptor: -0.5626
Step 8: Currently selected descriptors: [2, 5, 6, 9, 15, 16, 17, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 5, 6, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [0, 2, 5, 6, 9, 15, 16, 17, 18]
  Total reward: -4.5135, Per descriptor: -0.5015
Step 9: Currently selected descriptors: [0, 2, 5, 6, 9, 15, 16, 17, 18]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 5, 6, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [2, 5, 6, 9, 15, 16, 17, 18]
  Total reward: -4.5004, Per descriptor: -0.5626
Step 10: Currently selected descriptors: [2, 5, 6, 9, 15, 16, 17, 18]
  Action chosen: REMOVE descriptor 6
  New selection: [2, 5, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [2, 5, 9, 15, 16, 17, 18]
  Total reward: -4.4819, Per descriptor: -0.6403
Step 11: Currently selected descriptors: [2, 5, 9, 15, 16, 17, 18]
  Action chosen: ADD descriptor 8
  New selection: [2, 5, 8, 9, 15, 16, 17, 18]
  Calculating reward for descriptors: [2, 5, 8, 9, 15, 16, 17, 18]
  Total reward: -4.4708, Per descriptor: -0.5589
Step 12: Currently selected descriptors: [2, 5, 8, 9, 15, 16, 17, 18]
  Action chosen: REMOVE descriptor 17
  New selection: [2, 5, 8, 9, 15, 16, 18]
  Calculating reward for descriptors: [2, 5, 8, 9, 15, 16, 18]
  Total reward: -4.4587, Per descriptor: -0.6370
Step 13: Currently selected descriptors: [2, 5, 8, 9, 15, 16, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 5, 8, 9, 15, 16, 18]
  Calculating reward for descriptors: [0, 2, 5, 8, 9, 15, 16, 18]
  Total reward: -4.4696, Per descriptor: -0.5587
Step 14: Currently selected descriptors: [0, 2, 5, 8, 9, 15, 16, 18]
  Action chosen: ADD descriptor 12
  New selection: [0, 2, 5, 8, 9, 12, 15, 16, 18]
  Calculating reward for descriptors: [0, 2, 5, 8, 9, 12, 15, 16, 18]
  Total reward: -4.4918, Per descriptor: -0.4991
Step 15: Currently selected descriptors: [0, 2, 5, 8, 9, 12, 15, 16, 18]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 2, 5, 8, 9, 12, 15, 18]
  Calculating reward for descriptors: [0, 2, 5, 8, 9, 12, 15, 18]
  Total reward: -4.4736, Per descriptor: -0.5592
Step 16: Currently selected descriptors: [0, 2, 5, 8, 9, 12, 15, 18]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 2, 5, 8, 9, 12, 18]
  Calculating reward for descriptors: [0, 2, 5, 8, 9, 12, 18]
  Total reward: -4.4819, Per descriptor: -0.6403
Step 17: Currently selected descriptors: [0, 2, 5, 8, 9, 12, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 2, 5, 8, 9, 12]
  Calculating reward for descriptors: [0, 2, 5, 8, 9, 12]
  Total reward: -4.4545, Per descriptor: -0.7424
Step 18: Currently selected descriptors: [0, 2, 5, 8, 9, 12]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 2, 5, 8, 9]
  Calculating reward for descriptors: [0, 2, 5, 8, 9]
  Total reward: -4.5993, Per descriptor: -0.9199
Step 19: Currently selected descriptors: [0, 2, 5, 8, 9]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 122 experiences...
  DQN training loss: 9284938.000000
Episode 6 Summary:
  Total reward: -78.7100
  Steps taken: 19
  Final descriptors: 5
  Epsilon: 0.970 (97.0% random, 3.0% DQN)
  Avg last 10 episodes: -84.2448
  Best so far: -21.8927 (4 descriptors)

--- Episode 7/50 ---
Episode 7 - Epsilon: 0.970 (97.0% random, 3.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 18
  New selection: [18]
  Calculating reward for descriptors: [18]
  Total reward: 1.5359, Per descriptor: 1.5359
Step 1: Currently selected descriptors: [18]
  Action chosen: ADD descriptor 15
  New selection: [15, 18]
  Calculating reward for descriptors: [15, 18]
  Total reward: -4.1998, Per descriptor: -2.0999
Step 2: Currently selected descriptors: [15, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [15]
  Calculating reward for descriptors: [15]
  Total reward: 1.5184, Per descriptor: 1.5184
Step 3: Currently selected descriptors: [15]
  Action chosen: REMOVE descriptor 15
  New selection: []
  Calculating reward for descriptors: []
  Total reward: 0.0000, Per descriptor: 0.0000
Step 4: Currently selected descriptors: None
  Action chosen: ADD descriptor 6
  New selection: [6]
  Calculating reward for descriptors: [6]
  Total reward: 1.5139, Per descriptor: 1.5139
Step 5: Currently selected descriptors: [6]
  Action chosen: ADD descriptor 13
  New selection: [6, 13]
  Calculating reward for descriptors: [6, 13]
  Total reward: -4.4799, Per descriptor: -2.2399
Step 6: Currently selected descriptors: [6, 13]
  Action chosen: ADD descriptor 2
  New selection: [2, 6, 13]
  Calculating reward for descriptors: [2, 6, 13]
  Total reward: -4.6182, Per descriptor: -1.5394
Step 7: Currently selected descriptors: [2, 6, 13]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 129 experiences...
  DQN training loss: 12790837.000000
  NEW BEST! Reward: -8.7296 with 3 descriptors
Episode 7 Summary:
  Total reward: -8.7296
  Steps taken: 7
  Final descriptors: 3
  Epsilon: 0.966 (96.6% random, 3.4% DQN)
  Avg last 10 episodes: -73.4569
  Best so far: -8.7296 (3 descriptors)

--- Episode 8/50 ---
Episode 8 - Epsilon: 0.966 (96.6% random, 3.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 14
  New selection: [14]
  Calculating reward for descriptors: [14]
  Total reward: 1.4364, Per descriptor: 1.4364
Step 1: Currently selected descriptors: [14]
  Action chosen: ADD descriptor 18
  New selection: [14, 18]
  Calculating reward for descriptors: [14, 18]
  Total reward: -4.2804, Per descriptor: -2.1402
Step 2: Currently selected descriptors: [14, 18]
  Action chosen: ADD descriptor 6
  New selection: [6, 14, 18]
  Calculating reward for descriptors: [6, 14, 18]
  Total reward: -4.5235, Per descriptor: -1.5078
Step 3: Currently selected descriptors: [6, 14, 18]
  Action chosen: ADD descriptor 17
  New selection: [6, 14, 17, 18]
  Calculating reward for descriptors: [6, 14, 17, 18]
  Total reward: -4.5205, Per descriptor: -1.1301
Step 4: Currently selected descriptors: [6, 14, 17, 18]
  Action chosen: ADD descriptor 11
  New selection: [6, 11, 14, 17, 18]
  Calculating reward for descriptors: [6, 11, 14, 17, 18]
  Total reward: -4.3670, Per descriptor: -0.8734
Step 5: Currently selected descriptors: [6, 11, 14, 17, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 6, 11, 14, 17, 18]
  Calculating reward for descriptors: [0, 6, 11, 14, 17, 18]
  Total reward: -4.4109, Per descriptor: -0.7351
Step 6: Currently selected descriptors: [0, 6, 11, 14, 17, 18]
  Action chosen: ADD descriptor 5
  New selection: [0, 5, 6, 11, 14, 17, 18]
  Calculating reward for descriptors: [0, 5, 6, 11, 14, 17, 18]
  Total reward: -4.4276, Per descriptor: -0.6325
Step 7: Currently selected descriptors: [0, 5, 6, 11, 14, 17, 18]
  Action chosen: ADD descriptor 10
  New selection: [0, 5, 6, 10, 11, 14, 17, 18]
  Calculating reward for descriptors: [0, 5, 6, 10, 11, 14, 17, 18]
  Total reward: -4.4523, Per descriptor: -0.5565
Step 8: Currently selected descriptors: [0, 5, 6, 10, 11, 14, 17, 18]
  Action chosen: REMOVE descriptor 5
  New selection: [0, 6, 10, 11, 14, 17, 18]
  Calculating reward for descriptors: [0, 6, 10, 11, 14, 17, 18]
  Total reward: -4.4470, Per descriptor: -0.6353
Step 9: Currently selected descriptors: [0, 6, 10, 11, 14, 17, 18]
  Action chosen: ADD descriptor 15
  New selection: [0, 6, 10, 11, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 6, 10, 11, 14, 15, 17, 18]
  Total reward: -4.4318, Per descriptor: -0.5540
Step 10: Currently selected descriptors: [0, 6, 10, 11, 14, 15, 17, 18]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 10, 11, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 10, 11, 14, 15, 17, 18]
  Total reward: -4.4097, Per descriptor: -0.6300
Step 11: Currently selected descriptors: [0, 10, 11, 14, 15, 17, 18]
  Action chosen: ADD descriptor 8
  New selection: [0, 8, 10, 11, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 8, 10, 11, 14, 15, 17, 18]
  Total reward: -4.3928, Per descriptor: -0.5491
Step 12: Currently selected descriptors: [0, 8, 10, 11, 14, 15, 17, 18]
  Action chosen: ADD descriptor 16
  New selection: [0, 8, 10, 11, 14, 15, 16, 17, 18]
  Calculating reward for descriptors: [0, 8, 10, 11, 14, 15, 16, 17, 18]
  Total reward: -4.4211, Per descriptor: -0.4912
Step 13: Currently selected descriptors: [0, 8, 10, 11, 14, 15, 16, 17, 18]
  Action chosen: REMOVE descriptor 8
  New selection: [0, 10, 11, 14, 15, 16, 17, 18]
  Calculating reward for descriptors: [0, 10, 11, 14, 15, 16, 17, 18]
  Total reward: -4.4526, Per descriptor: -0.5566
Step 14: Currently selected descriptors: [0, 10, 11, 14, 15, 16, 17, 18]
  Action chosen: ADD descriptor 6
  New selection: [0, 6, 10, 11, 14, 15, 16, 17, 18]
  Calculating reward for descriptors: [0, 6, 10, 11, 14, 15, 16, 17, 18]
  Total reward: -4.4529, Per descriptor: -0.4948
Step 15: Currently selected descriptors: [0, 6, 10, 11, 14, 15, 16, 17, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 6, 10, 11, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 6, 10, 11, 14, 15, 16, 17]
  Total reward: -4.4488, Per descriptor: -0.5561
Step 16: Currently selected descriptors: [0, 6, 10, 11, 14, 15, 16, 17]
  Action chosen: ADD descriptor 8
  New selection: [0, 6, 8, 10, 11, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 6, 8, 10, 11, 14, 15, 16, 17]
  Total reward: -4.4215, Per descriptor: -0.4913
Step 17: Currently selected descriptors: [0, 6, 8, 10, 11, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 8, 10, 11, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 11, 14, 15, 16, 17]
  Total reward: -4.4319, Per descriptor: -0.5540
Step 18: Currently selected descriptors: [0, 8, 10, 11, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 8
  New selection: [0, 10, 11, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 10, 11, 14, 15, 16, 17]
  Total reward: -4.4729, Per descriptor: -0.6390
Step 19: Currently selected descriptors: [0, 10, 11, 14, 15, 16, 17]
  Action chosen: ADD descriptor 8
  New selection: [0, 8, 10, 11, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 11, 14, 15, 16, 17]
  Total reward: -4.4319, Per descriptor: -0.5540
Step 20: Currently selected descriptors: [0, 8, 10, 11, 14, 15, 16, 17]
  Action chosen: ADD descriptor 12
  New selection: [0, 8, 10, 11, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 11, 12, 14, 15, 16, 17]
  Total reward: -4.5143, Per descriptor: -0.5016
Step 21: Currently selected descriptors: [0, 8, 10, 11, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 8, 10, 11, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 1, 8, 10, 11, 12, 14, 15, 16, 17]
  Total reward: -4.4921, Per descriptor: -0.4492
Step 22: Currently selected descriptors: [0, 1, 8, 10, 11, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 8
  New selection: [0, 1, 10, 11, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 1, 10, 11, 12, 14, 15, 16, 17]
  Total reward: -4.5394, Per descriptor: -0.5044
Step 23: Currently selected descriptors: [0, 1, 10, 11, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 0
  New selection: [1, 10, 11, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [1, 10, 11, 12, 14, 15, 16, 17]
  Total reward: -4.5876, Per descriptor: -0.5735
Step 24: Currently selected descriptors: [1, 10, 11, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 10
  New selection: [1, 11, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [1, 11, 12, 14, 15, 16, 17]
  Total reward: -4.6803, Per descriptor: -0.6686
Step 25: Currently selected descriptors: [1, 11, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 11, 12, 14, 16, 17]
  Calculating reward for descriptors: [1, 11, 12, 14, 16, 17]
  Total reward: -4.5233, Per descriptor: -0.7539
Step 26: Currently selected descriptors: [1, 11, 12, 14, 16, 17]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 11, 12, 14, 16, 17]
  Calculating reward for descriptors: [1, 3, 11, 12, 14, 16, 17]
  Total reward: -4.4658, Per descriptor: -0.6380
Step 27: Currently selected descriptors: [1, 3, 11, 12, 14, 16, 17]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 3, 11, 12, 14, 17]
  Calculating reward for descriptors: [1, 3, 11, 12, 14, 17]
  Total reward: -4.4216, Per descriptor: -0.7369
Step 28: Currently selected descriptors: [1, 3, 11, 12, 14, 17]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 157 experiences...
  DQN training loss: 8537198.000000
Episode 8 Summary:
  Total reward: -118.9854
  Steps taken: 28
  Final descriptors: 6
  Epsilon: 0.961 (96.1% random, 3.9% DQN)
  Avg last 10 episodes: -79.1480
  Best so far: -8.7296 (3 descriptors)

--- Episode 9/50 ---
Episode 9 - Epsilon: 0.961 (96.1% random, 3.9% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: ADD descriptor 10
  New selection: [10, 16]
  Calculating reward for descriptors: [10, 16]
  Total reward: -4.1178, Per descriptor: -2.0589
Step 2: Currently selected descriptors: [10, 16]
  Action chosen: ADD descriptor 13
  New selection: [10, 13, 16]
  Calculating reward for descriptors: [10, 13, 16]
  Total reward: -4.3460, Per descriptor: -1.4487
Step 3: Currently selected descriptors: [10, 13, 16]
  Action chosen: ADD descriptor 0
  New selection: [0, 10, 13, 16]
  Calculating reward for descriptors: [0, 10, 13, 16]
  Total reward: -4.4575, Per descriptor: -1.1144
Step 4: Currently selected descriptors: [0, 10, 13, 16]
  Action chosen: ADD descriptor 3
  New selection: [0, 3, 10, 13, 16]
  Calculating reward for descriptors: [0, 3, 10, 13, 16]
  Total reward: -4.4417, Per descriptor: -0.8883
Step 5: Currently selected descriptors: [0, 3, 10, 13, 16]
  Action chosen: REMOVE descriptor 0
  New selection: [3, 10, 13, 16]
  Calculating reward for descriptors: [3, 10, 13, 16]
  Total reward: -4.3467, Per descriptor: -1.0867
Step 6: Currently selected descriptors: [3, 10, 13, 16]
  Action chosen: REMOVE descriptor 10
  New selection: [3, 13, 16]
  Calculating reward for descriptors: [3, 13, 16]
  Total reward: -4.3132, Per descriptor: -1.4377
Step 7: Currently selected descriptors: [3, 13, 16]
  Action chosen: ADD descriptor 8
  New selection: [3, 8, 13, 16]
  Calculating reward for descriptors: [3, 8, 13, 16]
  Total reward: -4.4178, Per descriptor: -1.1044
Step 8: Currently selected descriptors: [3, 8, 13, 16]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 165 experiences...
  DQN training loss: 7383759.000000
Episode 9 Summary:
  Total reward: -28.8456
  Steps taken: 8
  Final descriptors: 4
  Epsilon: 0.956 (95.6% random, 4.4% DQN)
  Avg last 10 episodes: -73.5588
  Best so far: -8.7296 (3 descriptors)

--- Episode 10/50 ---
Episode 10 - Epsilon: 0.956 (95.6% random, 4.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 3
  New selection: [3]
  Calculating reward for descriptors: [3]
  Total reward: 1.5744, Per descriptor: 1.5744
Step 1: Currently selected descriptors: [3]
  Action chosen: ADD descriptor 16
  New selection: [3, 16]
  Calculating reward for descriptors: [3, 16]
  Total reward: -4.2223, Per descriptor: -2.1112
Step 2: Currently selected descriptors: [3, 16]
  Action chosen: ADD descriptor 12
  New selection: [3, 12, 16]
  Calculating reward for descriptors: [3, 12, 16]
  Total reward: -4.5750, Per descriptor: -1.5250
Step 3: Currently selected descriptors: [3, 12, 16]
  Action chosen: ADD descriptor 15
  New selection: [3, 12, 15, 16]
  Calculating reward for descriptors: [3, 12, 15, 16]
  Total reward: -4.9930, Per descriptor: -1.2482
Step 4: Currently selected descriptors: [3, 12, 15, 16]
  Action chosen: REMOVE descriptor 15
  New selection: [3, 12, 16]
  Calculating reward for descriptors: [3, 12, 16]
  Total reward: -4.5750, Per descriptor: -1.5250
Step 5: Currently selected descriptors: [3, 12, 16]
  Action chosen: REMOVE descriptor 3
  New selection: [12, 16]
  Calculating reward for descriptors: [12, 16]
  Total reward: -5.3602, Per descriptor: -2.6801
Step 6: Currently selected descriptors: [12, 16]
  Action chosen: ADD descriptor 18
  New selection: [12, 16, 18]
  Calculating reward for descriptors: [12, 16, 18]
  Total reward: -4.5887, Per descriptor: -1.5296
Step 7: Currently selected descriptors: [12, 16, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 172 experiences...
  DQN training loss: 8674750.000000
Episode 10 Summary:
  Total reward: -26.7397
  Steps taken: 7
  Final descriptors: 3
  Epsilon: 0.951 (95.1% random, 4.9% DQN)
  Avg last 10 episodes: -68.8769
  Best so far: -8.7296 (3 descriptors)

--- Episode 11/50 ---
Episode 11 - Epsilon: 0.951 (95.1% random, 4.9% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: ADD descriptor 6
  New selection: [6, 16]
  Calculating reward for descriptors: [6, 16]
  Total reward: -4.2260, Per descriptor: -2.1130
Step 2: Currently selected descriptors: [6, 16]
  Action chosen: ADD descriptor 18
  New selection: [6, 16, 18]
  Calculating reward for descriptors: [6, 16, 18]
  Total reward: -4.4838, Per descriptor: -1.4946
Step 3: Currently selected descriptors: [6, 16, 18]
  Action chosen: ADD descriptor 7
  New selection: [6, 7, 16, 18]
  Calculating reward for descriptors: [6, 7, 16, 18]
  Total reward: -4.5122, Per descriptor: -1.1280
Step 4: Currently selected descriptors: [6, 7, 16, 18]
  Action chosen: ADD descriptor 19
  New selection: [6, 7, 16, 18, 19]
  Calculating reward for descriptors: [6, 7, 16, 18, 19]
  Total reward: -4.4272, Per descriptor: -0.8854
Step 5: Currently selected descriptors: [6, 7, 16, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 6, 7, 16, 18, 19]
  Calculating reward for descriptors: [4, 6, 7, 16, 18, 19]
  Total reward: -4.4228, Per descriptor: -0.7371
Step 6: Currently selected descriptors: [4, 6, 7, 16, 18, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 4, 6, 7, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 16, 18, 19]
  Total reward: -4.4543, Per descriptor: -0.6363
Step 7: Currently selected descriptors: [2, 4, 6, 7, 16, 18, 19]
  Action chosen: ADD descriptor 9
  New selection: [2, 4, 6, 7, 9, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 9, 16, 18, 19]
  Total reward: -4.4354, Per descriptor: -0.5544
Step 8: Currently selected descriptors: [2, 4, 6, 7, 9, 16, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [2, 4, 6, 7, 8, 9, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 9, 16, 18, 19]
  Total reward: -4.4367, Per descriptor: -0.4930
Step 9: Currently selected descriptors: [2, 4, 6, 7, 8, 9, 16, 18, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [2, 4, 6, 7, 8, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 16, 18, 19]
  Total reward: -4.4136, Per descriptor: -0.5517
Step 10: Currently selected descriptors: [2, 4, 6, 7, 8, 16, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [2, 4, 6, 7, 8, 12, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 12, 16, 18, 19]
  Total reward: -4.4470, Per descriptor: -0.4941
Step 11: Currently selected descriptors: [2, 4, 6, 7, 8, 12, 16, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [2, 4, 6, 7, 8, 12, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 12, 16, 19]
  Total reward: -4.4347, Per descriptor: -0.5543
Step 12: Currently selected descriptors: [2, 4, 6, 7, 8, 12, 16, 19]
  Action chosen: ADD descriptor 13
  New selection: [2, 4, 6, 7, 8, 12, 13, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 12, 13, 16, 19]
  Total reward: -4.4441, Per descriptor: -0.4938
Step 13: Currently selected descriptors: [2, 4, 6, 7, 8, 12, 13, 16, 19]
  Action chosen: ADD descriptor 10
  New selection: [2, 4, 6, 7, 8, 10, 12, 13, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 10, 12, 13, 16, 19]
  Total reward: -4.4472, Per descriptor: -0.4447
Step 14: Currently selected descriptors: [2, 4, 6, 7, 8, 10, 12, 13, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [2, 4, 6, 7, 8, 9, 10, 12, 13, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 9, 10, 12, 13, 16, 19]
  Total reward: -4.4662, Per descriptor: -0.4060
Step 15: Currently selected descriptors: [2, 4, 6, 7, 8, 9, 10, 12, 13, 16, 19]
  Action chosen: ADD descriptor 15
  New selection: [2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Total reward: -4.5030, Per descriptor: -0.3752
Step 16: Currently selected descriptors: [2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Total reward: -4.5073, Per descriptor: -0.3467
Step 17: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 2, 4, 6, 7, 8, 9, 10, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 13, 15, 16, 19]
  Total reward: -4.4860, Per descriptor: -0.3738
Step 18: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 13, 15, 16, 19]
  Action chosen: ADD descriptor 11
  New selection: [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 19]
  Total reward: -4.5406, Per descriptor: -0.3493
Step 19: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 15, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5729, Per descriptor: -0.3266
Step 20: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.5713, Per descriptor: -0.3516
Step 21: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [1, 2, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.6092, Per descriptor: -0.3841
Step 22: Currently selected descriptors: [1, 2, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.5172, Per descriptor: -0.4107
Step 23: Currently selected descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5137, Per descriptor: -0.3761
Step 24: Currently selected descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Action chosen: ADD descriptor 17
  New selection: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Total reward: -4.5112, Per descriptor: -0.3470
Step 25: Currently selected descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Total reward: -4.5097, Per descriptor: -0.3758
Step 26: Currently selected descriptors: [1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Total reward: -4.5123, Per descriptor: -0.3471
Step 27: Currently selected descriptors: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 17, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Total reward: -4.5098, Per descriptor: -0.3221
Step 28: Currently selected descriptors: [0, 1, 2, 6, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 1, 2, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Total reward: -4.5096, Per descriptor: -0.3469
Step 29: Currently selected descriptors: [0, 1, 2, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19]
  Action chosen: ADD descriptor 13
  New selection: [0, 1, 2, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]
  Total reward: -4.5179, Per descriptor: -0.3227
Step 30: Currently selected descriptors: [0, 1, 2, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 2, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Total reward: -4.5082, Per descriptor: -0.3468
Step 31: Currently selected descriptors: [0, 1, 2, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Action chosen: ADD descriptor 3
  New selection: [0, 1, 2, 3, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 3, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Total reward: -4.5007, Per descriptor: -0.3215
Step 32: Currently selected descriptors: [0, 1, 2, 3, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19]
  Action chosen: ADD descriptor 14
  New selection: [0, 1, 2, 3, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 3, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19]
  Total reward: -4.4565, Per descriptor: -0.2971
  Reached maximum descriptors limit
  Training DQN with 205 experiences...
  DQN training loss: 11650669.000000
  Updated target network weights
Episode 11 Summary:
  Total reward: -141.8131
  Steps taken: 33
  Final descriptors: 15
  Epsilon: 0.946 (94.6% random, 5.4% DQN)
  Avg last 10 episodes: -73.3644
  Best so far: -8.7296 (3 descriptors)

--- Episode 12/50 ---
Episode 12 - Epsilon: 0.946 (94.6% random, 5.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 3
  New selection: [3]
  Calculating reward for descriptors: [3]
  Total reward: 1.5744, Per descriptor: 1.5744
Step 1: Currently selected descriptors: [3]
  Action chosen: ADD descriptor 4
  New selection: [3, 4]
  Calculating reward for descriptors: [3, 4]
  Total reward: -4.4663, Per descriptor: -2.2332
Step 2: Currently selected descriptors: [3, 4]
  Action chosen: ADD descriptor 8
  New selection: [3, 4, 8]
  Calculating reward for descriptors: [3, 4, 8]
  Total reward: -4.3718, Per descriptor: -1.4573
Step 3: Currently selected descriptors: [3, 4, 8]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 4, 8]
  Calculating reward for descriptors: [1, 3, 4, 8]
  Total reward: -4.4816, Per descriptor: -1.1204
Step 4: Currently selected descriptors: [1, 3, 4, 8]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 209 experiences...
  DQN training loss: 6874923.500000
Episode 12 Summary:
  Total reward: -11.7453
  Steps taken: 4
  Final descriptors: 4
  Epsilon: 0.942 (94.2% random, 5.8% DQN)
  Avg last 10 episodes: -66.7738
  Best so far: -8.7296 (3 descriptors)

--- Episode 13/50 ---
Episode 13 - Epsilon: 0.942 (94.2% random, 5.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 0
  New selection: [0]
  Calculating reward for descriptors: [0]
  Total reward: 1.6602, Per descriptor: 1.6602
Step 1: Currently selected descriptors: [0]
  Action chosen: ADD descriptor 6
  New selection: [0, 6]
  Calculating reward for descriptors: [0, 6]
  Total reward: -4.6716, Per descriptor: -2.3358
Step 2: Currently selected descriptors: [0, 6]
  Action chosen: REMOVE descriptor 6
  New selection: [0]
  Calculating reward for descriptors: [0]
  Total reward: 1.6602, Per descriptor: 1.6602
Step 3: Currently selected descriptors: [0]
  Action chosen: ADD descriptor 19
  New selection: [0, 19]
  Calculating reward for descriptors: [0, 19]
  Total reward: -4.5610, Per descriptor: -2.2805
Step 4: Currently selected descriptors: [0, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 8, 19]
  Calculating reward for descriptors: [0, 8, 19]
  Total reward: -4.4330, Per descriptor: -1.4777
Step 5: Currently selected descriptors: [0, 8, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 8, 12, 19]
  Calculating reward for descriptors: [0, 8, 12, 19]
  Total reward: -4.2851, Per descriptor: -1.0713
Step 6: Currently selected descriptors: [0, 8, 12, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 8, 19]
  Calculating reward for descriptors: [0, 8, 19]
  Total reward: -4.4330, Per descriptor: -1.4777
Step 7: Currently selected descriptors: [0, 8, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [8, 19]
  Calculating reward for descriptors: [8, 19]
  Total reward: -4.2496, Per descriptor: -2.1248
Step 8: Currently selected descriptors: [8, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 8, 19]
  Calculating reward for descriptors: [1, 8, 19]
  Total reward: -4.4052, Per descriptor: -1.4684
Step 9: Currently selected descriptors: [1, 8, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [8, 19]
  Calculating reward for descriptors: [8, 19]
  Total reward: -4.2496, Per descriptor: -2.1248
Step 10: Currently selected descriptors: [8, 19]
  Action chosen: ADD descriptor 14
  New selection: [8, 14, 19]
  Calculating reward for descriptors: [8, 14, 19]
  Total reward: -4.2033, Per descriptor: -1.4011
Step 11: Currently selected descriptors: [8, 14, 19]
  Action chosen: ADD descriptor 6
  New selection: [6, 8, 14, 19]
  Calculating reward for descriptors: [6, 8, 14, 19]
  Total reward: -4.2748, Per descriptor: -1.0687
Step 12: Currently selected descriptors: [6, 8, 14, 19]
  Action chosen: ADD descriptor 17
  New selection: [6, 8, 14, 17, 19]
  Calculating reward for descriptors: [6, 8, 14, 17, 19]
  Total reward: -4.3570, Per descriptor: -0.8714
Step 13: Currently selected descriptors: [6, 8, 14, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [6, 8, 14, 17]
  Calculating reward for descriptors: [6, 8, 14, 17]
  Total reward: -4.3548, Per descriptor: -1.0887
Step 14: Currently selected descriptors: [6, 8, 14, 17]
  Action chosen: ADD descriptor 1
  New selection: [1, 6, 8, 14, 17]
  Calculating reward for descriptors: [1, 6, 8, 14, 17]
  Total reward: -4.4591, Per descriptor: -0.8918
Step 15: Currently selected descriptors: [1, 6, 8, 14, 17]
  Action chosen: ADD descriptor 15
  New selection: [1, 6, 8, 14, 15, 17]
  Calculating reward for descriptors: [1, 6, 8, 14, 15, 17]
  Total reward: -4.3527, Per descriptor: -0.7254
Step 16: Currently selected descriptors: [1, 6, 8, 14, 15, 17]
  Action chosen: ADD descriptor 13
  New selection: [1, 6, 8, 13, 14, 15, 17]
  Calculating reward for descriptors: [1, 6, 8, 13, 14, 15, 17]
  Total reward: -4.4003, Per descriptor: -0.6286
Step 17: Currently selected descriptors: [1, 6, 8, 13, 14, 15, 17]
  Action chosen: ADD descriptor 4
  New selection: [1, 4, 6, 8, 13, 14, 15, 17]
  Calculating reward for descriptors: [1, 4, 6, 8, 13, 14, 15, 17]
  Total reward: -4.4053, Per descriptor: -0.5507
Step 18: Currently selected descriptors: [1, 4, 6, 8, 13, 14, 15, 17]
  Action chosen: ADD descriptor 18
  New selection: [1, 4, 6, 8, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [1, 4, 6, 8, 13, 14, 15, 17, 18]
  Total reward: -4.4403, Per descriptor: -0.4934
Step 19: Currently selected descriptors: [1, 4, 6, 8, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 4, 6, 8, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 4, 6, 8, 13, 14, 15, 17, 18]
  Total reward: -4.4548, Per descriptor: -0.4455
Step 20: Currently selected descriptors: [0, 1, 4, 6, 8, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 3
  New selection: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Total reward: -4.4499, Per descriptor: -0.4045
Step 21: Currently selected descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18, 19]
  Total reward: -4.4409, Per descriptor: -0.3701
Step 22: Currently selected descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Total reward: -4.4499, Per descriptor: -0.4045
Step 23: Currently selected descriptors: [0, 1, 3, 4, 6, 8, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 3, 4, 6, 7, 8, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 3, 4, 6, 7, 8, 13, 14, 15, 17, 18]
  Total reward: -4.4330, Per descriptor: -0.3694
Step 24: Currently selected descriptors: [0, 1, 3, 4, 6, 7, 8, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 10
  New selection: [0, 1, 3, 4, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 3, 4, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Total reward: -4.4435, Per descriptor: -0.3418
Step 25: Currently selected descriptors: [0, 1, 3, 4, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Total reward: -4.4441, Per descriptor: -0.3174
Step 26: Currently selected descriptors: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Total reward: -4.4213, Per descriptor: -0.3401
Step 27: Currently selected descriptors: [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Action chosen: REMOVE descriptor 3
  New selection: [0, 1, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Calculating reward for descriptors: [0, 1, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Total reward: -4.4249, Per descriptor: -0.3687
Step 28: Currently selected descriptors: [0, 1, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Total reward: -4.4545, Per descriptor: -0.3427
Step 29: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 7, 8, 10, 13, 14, 15, 17]
  Action chosen: ADD descriptor 11
  New selection: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 17]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 17]
  Total reward: -4.4846, Per descriptor: -0.3203
Step 30: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 17, 19]
  Total reward: -4.4690, Per descriptor: -0.2979
  Reached maximum descriptors limit
  Training DQN with 240 experiences...
  DQN training loss: 7244915.000000
Episode 13 Summary:
  Total reward: -124.5854
  Steps taken: 31
  Final descriptors: 15
  Epsilon: 0.937 (93.7% random, 6.3% DQN)
  Avg last 10 episodes: -77.0431
  Best so far: -8.7296 (3 descriptors)

--- Episode 14/50 ---
Episode 14 - Epsilon: 0.937 (93.7% random, 6.3% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 10
  New selection: [10]
  Calculating reward for descriptors: [10]
  Total reward: 1.4672, Per descriptor: 1.4672
Step 1: Currently selected descriptors: [10]
  Action chosen: ADD descriptor 18
  New selection: [10, 18]
  Calculating reward for descriptors: [10, 18]
  Total reward: -4.6289, Per descriptor: -2.3145
Step 2: Currently selected descriptors: [10, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 10, 18]
  Calculating reward for descriptors: [0, 10, 18]
  Total reward: -4.7410, Per descriptor: -1.5803
Step 3: Currently selected descriptors: [0, 10, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 10]
  Calculating reward for descriptors: [0, 10]
  Total reward: -4.9783, Per descriptor: -2.4892
Step 4: Currently selected descriptors: [0, 10]
  Action chosen: REMOVE descriptor 0
  New selection: [10]
  Calculating reward for descriptors: [10]
  Total reward: 1.4672, Per descriptor: 1.4672
Step 5: Currently selected descriptors: [10]
  Action chosen: ADD descriptor 5
  New selection: [5, 10]
  Calculating reward for descriptors: [5, 10]
  Total reward: -4.5006, Per descriptor: -2.2503
Step 6: Currently selected descriptors: [5, 10]
  Action chosen: ADD descriptor 7
  New selection: [5, 7, 10]
  Calculating reward for descriptors: [5, 7, 10]
  Total reward: -4.2417, Per descriptor: -1.4139
Step 7: Currently selected descriptors: [5, 7, 10]
  Action chosen: ADD descriptor 8
  New selection: [5, 7, 8, 10]
  Calculating reward for descriptors: [5, 7, 8, 10]
  Total reward: -4.3130, Per descriptor: -1.0782
Step 8: Currently selected descriptors: [5, 7, 8, 10]
  Action chosen: ADD descriptor 11
  New selection: [5, 7, 8, 10, 11]
  Calculating reward for descriptors: [5, 7, 8, 10, 11]
  Total reward: -4.7472, Per descriptor: -0.9494
Step 9: Currently selected descriptors: [5, 7, 8, 10, 11]
  Action chosen: ADD descriptor 13
  New selection: [5, 7, 8, 10, 11, 13]
  Calculating reward for descriptors: [5, 7, 8, 10, 11, 13]
  Total reward: -4.6853, Per descriptor: -0.7809
Step 10: Currently selected descriptors: [5, 7, 8, 10, 11, 13]
  Action chosen: ADD descriptor 19
  New selection: [5, 7, 8, 10, 11, 13, 19]
  Calculating reward for descriptors: [5, 7, 8, 10, 11, 13, 19]
  Total reward: -4.5645, Per descriptor: -0.6521
Step 11: Currently selected descriptors: [5, 7, 8, 10, 11, 13, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [5, 7, 8, 11, 13, 19]
  Calculating reward for descriptors: [5, 7, 8, 11, 13, 19]
  Total reward: -4.6357, Per descriptor: -0.7726
Step 12: Currently selected descriptors: [5, 7, 8, 11, 13, 19]
  Action chosen: ADD descriptor 6
  New selection: [5, 6, 7, 8, 11, 13, 19]
  Calculating reward for descriptors: [5, 6, 7, 8, 11, 13, 19]
  Total reward: -4.5611, Per descriptor: -0.6516
Step 13: Currently selected descriptors: [5, 6, 7, 8, 11, 13, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 5, 6, 7, 8, 11, 13, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 11, 13, 19]
  Total reward: -4.5184, Per descriptor: -0.5648
Step 14: Currently selected descriptors: [4, 5, 6, 7, 8, 11, 13, 19]
  Action chosen: ADD descriptor 17
  New selection: [4, 5, 6, 7, 8, 11, 13, 17, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 11, 13, 17, 19]
  Total reward: -4.4898, Per descriptor: -0.4989
Step 15: Currently selected descriptors: [4, 5, 6, 7, 8, 11, 13, 17, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [4, 5, 6, 7, 8, 13, 17, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 13, 17, 19]
  Total reward: -4.4086, Per descriptor: -0.5511
Step 16: Currently selected descriptors: [4, 5, 6, 7, 8, 13, 17, 19]
  Action chosen: ADD descriptor 15
  New selection: [4, 5, 6, 7, 8, 13, 15, 17, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 8, 13, 15, 17, 19]
  Total reward: -4.3951, Per descriptor: -0.4883
Step 17: Currently selected descriptors: [4, 5, 6, 7, 8, 13, 15, 17, 19]
  Action chosen: REMOVE descriptor 8
  New selection: [4, 5, 6, 7, 13, 15, 17, 19]
  Calculating reward for descriptors: [4, 5, 6, 7, 13, 15, 17, 19]
  Total reward: -4.3992, Per descriptor: -0.5499
Step 18: Currently selected descriptors: [4, 5, 6, 7, 13, 15, 17, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 5, 6, 7, 13, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 13, 15, 17, 19]
  Total reward: -4.4192, Per descriptor: -0.4910
Step 19: Currently selected descriptors: [0, 4, 5, 6, 7, 13, 15, 17, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [0, 4, 5, 6, 7, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Total reward: -4.4270, Per descriptor: -0.5534
Step 20: Currently selected descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 4, 5, 6, 7, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 17, 19]
  Total reward: -4.4445, Per descriptor: -0.6349
Step 21: Currently selected descriptors: [0, 4, 5, 6, 7, 17, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 4, 5, 6, 7, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Total reward: -4.4270, Per descriptor: -0.5534
Step 22: Currently selected descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 4, 5, 6, 7, 15, 17]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 15, 17]
  Total reward: -4.4472, Per descriptor: -0.6353
Step 23: Currently selected descriptors: [0, 4, 5, 6, 7, 15, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 4, 5, 6, 7, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Total reward: -4.4270, Per descriptor: -0.5534
Step 24: Currently selected descriptors: [0, 4, 5, 6, 7, 15, 17, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 4, 5, 7, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 7, 15, 17, 19]
  Total reward: -4.4040, Per descriptor: -0.6291
Step 25: Currently selected descriptors: [0, 4, 5, 7, 15, 17, 19]
  Action chosen: ADD descriptor 9
  New selection: [0, 4, 5, 7, 9, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 7, 9, 15, 17, 19]
  Total reward: -4.3954, Per descriptor: -0.5494
Step 26: Currently selected descriptors: [0, 4, 5, 7, 9, 15, 17, 19]
  Action chosen: ADD descriptor 11
  New selection: [0, 4, 5, 7, 9, 11, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 7, 9, 11, 15, 17, 19]
  Total reward: -4.5327, Per descriptor: -0.5036
Step 27: Currently selected descriptors: [0, 4, 5, 7, 9, 11, 15, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5172, Per descriptor: -0.4517
Step 28: Currently selected descriptors: [0, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [0, 4, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [0, 4, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5640, Per descriptor: -0.5071
Step 29: Currently selected descriptors: [0, 4, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [4, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [4, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5937, Per descriptor: -0.5742
Step 30: Currently selected descriptors: [4, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: ADD descriptor 3
  New selection: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5395, Per descriptor: -0.5044
Step 31: Currently selected descriptors: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: ADD descriptor 5
  New selection: [3, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [3, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.4952, Per descriptor: -0.4495
Step 32: Currently selected descriptors: [3, 4, 5, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5395, Per descriptor: -0.5044
Step 33: Currently selected descriptors: [3, 4, 7, 9, 10, 11, 15, 17, 19]
  Action chosen: ADD descriptor 8
  New selection: [3, 4, 7, 8, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [3, 4, 7, 8, 9, 10, 11, 15, 17, 19]
  Total reward: -4.5097, Per descriptor: -0.4510
Step 34: Currently selected descriptors: [3, 4, 7, 8, 9, 10, 11, 15, 17, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [3, 4, 7, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [3, 4, 7, 8, 9, 10, 11, 17, 19]
  Total reward: -4.5062, Per descriptor: -0.5007
Step 35: Currently selected descriptors: [3, 4, 7, 8, 9, 10, 11, 17, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [3, 7, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [3, 7, 8, 9, 10, 11, 17, 19]
  Total reward: -4.5489, Per descriptor: -0.5686
Step 36: Currently selected descriptors: [3, 7, 8, 9, 10, 11, 17, 19]
  Action chosen: ADD descriptor 14
  New selection: [3, 7, 8, 9, 10, 11, 14, 17, 19]
  Calculating reward for descriptors: [3, 7, 8, 9, 10, 11, 14, 17, 19]
  Total reward: -4.4621, Per descriptor: -0.4958
Step 37: Currently selected descriptors: [3, 7, 8, 9, 10, 11, 14, 17, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Calculating reward for descriptors: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Total reward: -4.4706, Per descriptor: -0.4471
Step 38: Currently selected descriptors: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Action chosen: ADD descriptor 5
  New selection: [1, 3, 5, 7, 8, 9, 10, 11, 14, 17, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 8, 9, 10, 11, 14, 17, 19]
  Total reward: -4.4452, Per descriptor: -0.4041
Step 39: Currently selected descriptors: [1, 3, 5, 7, 8, 9, 10, 11, 14, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Calculating reward for descriptors: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Total reward: -4.4706, Per descriptor: -0.4471
Step 40: Currently selected descriptors: [1, 3, 7, 8, 9, 10, 11, 14, 17, 19]
  Action chosen: REMOVE descriptor 14
  New selection: [1, 3, 7, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [1, 3, 7, 8, 9, 10, 11, 17, 19]
  Total reward: -4.5412, Per descriptor: -0.5046
Step 41: Currently selected descriptors: [1, 3, 7, 8, 9, 10, 11, 17, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [1, 3, 7, 8, 9, 11, 17, 19]
  Calculating reward for descriptors: [1, 3, 7, 8, 9, 11, 17, 19]
  Total reward: -4.5506, Per descriptor: -0.5688
Step 42: Currently selected descriptors: [1, 3, 7, 8, 9, 11, 17, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [1, 3, 7, 8, 9, 11, 19]
  Calculating reward for descriptors: [1, 3, 7, 8, 9, 11, 19]
  Total reward: -4.5760, Per descriptor: -0.6537
Step 43: Currently selected descriptors: [1, 3, 7, 8, 9, 11, 19]
  Action chosen: ADD descriptor 4
  New selection: [1, 3, 4, 7, 8, 9, 11, 19]
  Calculating reward for descriptors: [1, 3, 4, 7, 8, 9, 11, 19]
  Total reward: -4.5257, Per descriptor: -0.5657
Step 44: Currently selected descriptors: [1, 3, 4, 7, 8, 9, 11, 19]
  Action chosen: ADD descriptor 5
  New selection: [1, 3, 4, 5, 7, 8, 9, 11, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 8, 9, 11, 19]
  Total reward: -4.4882, Per descriptor: -0.4987
Step 45: Currently selected descriptors: [1, 3, 4, 5, 7, 8, 9, 11, 19]
  Action chosen: ADD descriptor 17
  New selection: [1, 3, 4, 5, 7, 8, 9, 11, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 8, 9, 11, 17, 19]
  Total reward: -4.4871, Per descriptor: -0.4487
Step 46: Currently selected descriptors: [1, 3, 4, 5, 7, 8, 9, 11, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [1, 3, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Total reward: -4.4890, Per descriptor: -0.4081
Step 47: Currently selected descriptors: [1, 3, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Total reward: -4.5077, Per descriptor: -0.4508
Step 48: Currently selected descriptors: [1, 4, 5, 7, 8, 9, 10, 11, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 4, 5, 8, 9, 10, 11, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 8, 9, 10, 11, 17, 19]
  Total reward: -4.4635, Per descriptor: -0.4959
Step 49: Currently selected descriptors: [1, 4, 5, 8, 9, 10, 11, 17, 19]
  Action chosen: ADD descriptor 15
  New selection: [1, 4, 5, 8, 9, 10, 11, 15, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 8, 9, 10, 11, 15, 17, 19]
  Total reward: -4.4296, Per descriptor: -0.4430
Step 50: Currently selected descriptors: [1, 4, 5, 8, 9, 10, 11, 15, 17, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [1, 4, 5, 8, 9, 11, 15, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 8, 9, 11, 15, 17, 19]
  Total reward: -4.4147, Per descriptor: -0.4905
Step 51: Currently selected descriptors: [1, 4, 5, 8, 9, 11, 15, 17, 19]
  Action chosen: ADD descriptor 13
  New selection: [1, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Total reward: -4.4498, Per descriptor: -0.4450
Step 52: Currently selected descriptors: [1, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Total reward: -4.4354, Per descriptor: -0.4032
Step 53: Currently selected descriptors: [1, 3, 4, 5, 8, 9, 11, 13, 15, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [1, 3, 4, 5, 8, 9, 10, 11, 13, 15, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 8, 9, 10, 11, 13, 15, 17, 19]
  Total reward: -4.4450, Per descriptor: -0.3704
Step 54: Currently selected descriptors: [1, 3, 4, 5, 8, 9, 10, 11, 13, 15, 17, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Total reward: -4.4736, Per descriptor: -0.4067
Step 55: Currently selected descriptors: [1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Total reward: -4.4896, Per descriptor: -0.3741
Step 56: Currently selected descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17]
  Total reward: -4.5096, Per descriptor: -0.4100
Step 57: Currently selected descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17]
  Total reward: -4.4719, Per descriptor: -0.3727
Step 58: Currently selected descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17, 19]
  Total reward: -4.4558, Per descriptor: -0.3428
Step 59: Currently selected descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 16, 17, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Total reward: -4.4896, Per descriptor: -0.3741
Step 60: Currently selected descriptors: [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 17, 19]
  Action chosen: REMOVE descriptor 8
  New selection: [0, 1, 3, 4, 5, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 9, 10, 11, 13, 17, 19]
  Total reward: -4.4836, Per descriptor: -0.4076
Step 61: Currently selected descriptors: [0, 1, 3, 4, 5, 9, 10, 11, 13, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Total reward: -4.5090, Per descriptor: -0.3757
Step 62: Currently selected descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Total reward: -4.5158, Per descriptor: -0.3474
Step 63: Currently selected descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [0, 1, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Total reward: -4.5268, Per descriptor: -0.3772
Step 64: Currently selected descriptors: [0, 1, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Total reward: -4.5203, Per descriptor: -0.4109
Step 65: Currently selected descriptors: [0, 3, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Total reward: -4.5063, Per descriptor: -0.3755
Step 66: Currently selected descriptors: [0, 3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Calculating reward for descriptors: [3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Total reward: -4.4959, Per descriptor: -0.4087
Step 67: Currently selected descriptors: [3, 4, 5, 7, 9, 10, 11, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [3, 4, 5, 7, 9, 10, 11, 13, 18, 19]
  Calculating reward for descriptors: [3, 4, 5, 7, 9, 10, 11, 13, 18, 19]
  Total reward: -4.5024, Per descriptor: -0.4502
Step 68: Currently selected descriptors: [3, 4, 5, 7, 9, 10, 11, 13, 18, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [3, 5, 7, 9, 10, 11, 13, 18, 19]
  Calculating reward for descriptors: [3, 5, 7, 9, 10, 11, 13, 18, 19]
  Total reward: -4.5258, Per descriptor: -0.5029
Step 69: Currently selected descriptors: [3, 5, 7, 9, 10, 11, 13, 18, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 5, 7, 9, 10, 11, 13, 18, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 18, 19]
  Total reward: -4.5255, Per descriptor: -0.4526
Step 70: Currently selected descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 3, 5, 7, 9, 10, 11, 13, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 19]
  Total reward: -4.5253, Per descriptor: -0.5028
Step 71: Currently selected descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 19]
  Action chosen: ADD descriptor 17
  New selection: [1, 3, 5, 7, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 17, 19]
  Total reward: -4.5230, Per descriptor: -0.4523
Step 72: Currently selected descriptors: [1, 3, 5, 7, 9, 10, 11, 13, 17, 19]
  Action chosen: ADD descriptor 4
  New selection: [1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Total reward: -4.5028, Per descriptor: -0.4093
Step 73: Currently selected descriptors: [1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Total reward: -4.5090, Per descriptor: -0.3757
Step 74: Currently selected descriptors: [0, 1, 3, 4, 5, 7, 9, 10, 11, 13, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 314 experiences...
  DQN training loss: 6925462.000000
Episode 14 Summary:
  Total reward: -321.3258
  Steps taken: 74
  Final descriptors: 12
  Epsilon: 0.932 (93.2% random, 6.8% DQN)
  Avg last 10 episodes: -99.5858
  Best so far: -8.7296 (3 descriptors)

--- Episode 15/50 ---
Episode 15 - Epsilon: 0.932 (93.2% random, 6.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 12
  New selection: [12]
  Calculating reward for descriptors: [12]
  Total reward: 1.5090, Per descriptor: 1.5090
Step 1: Currently selected descriptors: [12]
  Action chosen: ADD descriptor 13
  New selection: [12, 13]
  Calculating reward for descriptors: [12, 13]
  Total reward: -4.4055, Per descriptor: -2.2027
Step 2: Currently selected descriptors: [12, 13]
  Action chosen: ADD descriptor 7
  New selection: [7, 12, 13]
  Calculating reward for descriptors: [7, 12, 13]
  Total reward: -5.0026, Per descriptor: -1.6675
Step 3: Currently selected descriptors: [7, 12, 13]
  Action chosen: ADD descriptor 3
  New selection: [3, 7, 12, 13]
  Calculating reward for descriptors: [3, 7, 12, 13]
  Total reward: -4.6174, Per descriptor: -1.1543
Step 4: Currently selected descriptors: [3, 7, 12, 13]
  Action chosen: REMOVE descriptor 3
  New selection: [7, 12, 13]
  Calculating reward for descriptors: [7, 12, 13]
  Total reward: -5.0026, Per descriptor: -1.6675
Step 5: Currently selected descriptors: [7, 12, 13]
  Action chosen: ADD descriptor 3
  New selection: [3, 7, 12, 13]
  Calculating reward for descriptors: [3, 7, 12, 13]
  Total reward: -4.6174, Per descriptor: -1.1543
Step 6: Currently selected descriptors: [3, 7, 12, 13]
  Action chosen: ADD descriptor 16
  New selection: [3, 7, 12, 13, 16]
  Calculating reward for descriptors: [3, 7, 12, 13, 16]
  Total reward: -4.6856, Per descriptor: -0.9371
Step 7: Currently selected descriptors: [3, 7, 12, 13, 16]
  Action chosen: ADD descriptor 11
  New selection: [3, 7, 11, 12, 13, 16]
  Calculating reward for descriptors: [3, 7, 11, 12, 13, 16]
  Total reward: -5.0743, Per descriptor: -0.8457
Step 8: Currently selected descriptors: [3, 7, 11, 12, 13, 16]
  Action chosen: ADD descriptor 18
  New selection: [3, 7, 11, 12, 13, 16, 18]
  Calculating reward for descriptors: [3, 7, 11, 12, 13, 16, 18]
  Total reward: -4.8560, Per descriptor: -0.6937
Step 9: Currently selected descriptors: [3, 7, 11, 12, 13, 16, 18]
  Action chosen: REMOVE descriptor 11
  New selection: [3, 7, 12, 13, 16, 18]
  Calculating reward for descriptors: [3, 7, 12, 13, 16, 18]
  Total reward: -4.5675, Per descriptor: -0.7612
Step 10: Currently selected descriptors: [3, 7, 12, 13, 16, 18]
  Action chosen: ADD descriptor 19
  New selection: [3, 7, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [3, 7, 12, 13, 16, 18, 19]
  Total reward: -4.4855, Per descriptor: -0.6408
Step 11: Currently selected descriptors: [3, 7, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 3, 7, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 3, 7, 12, 13, 16, 18, 19]
  Total reward: -4.4665, Per descriptor: -0.5583
Step 12: Currently selected descriptors: [0, 3, 7, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Total reward: -4.4429, Per descriptor: -0.4937
Step 13: Currently selected descriptors: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [0, 3, 5, 7, 11, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 11, 12, 13, 16, 18, 19]
  Total reward: -4.5735, Per descriptor: -0.4573
Step 14: Currently selected descriptors: [0, 3, 5, 7, 11, 12, 13, 16, 18, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Total reward: -4.4429, Per descriptor: -0.4937
Step 15: Currently selected descriptors: [0, 3, 5, 7, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 3, 5, 7, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4460, Per descriptor: -0.4446
Step 16: Currently selected descriptors: [0, 3, 5, 7, 12, 13, 16, 17, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 3, 5, 7, 8, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 8, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4317, Per descriptor: -0.4029
Step 17: Currently selected descriptors: [0, 3, 5, 7, 8, 12, 13, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 3, 5, 7, 8, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 8, 12, 13, 17, 18, 19]
  Total reward: -4.4296, Per descriptor: -0.4430
Step 18: Currently selected descriptors: [0, 3, 5, 7, 8, 12, 13, 17, 18, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 3, 5, 7, 8, 10, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 7, 8, 10, 12, 13, 17, 18, 19]
  Total reward: -4.4448, Per descriptor: -0.4041
Step 19: Currently selected descriptors: [0, 3, 5, 7, 8, 10, 12, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 3, 5, 8, 10, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 8, 10, 12, 13, 17, 18, 19]
  Total reward: -4.4582, Per descriptor: -0.4458
Step 20: Currently selected descriptors: [0, 3, 5, 8, 10, 12, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 3, 5, 8, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 8, 12, 13, 17, 18, 19]
  Total reward: -4.4362, Per descriptor: -0.4929
Step 21: Currently selected descriptors: [0, 3, 5, 8, 12, 13, 17, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 3, 5, 8, 12, 13, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 8, 12, 13, 15, 17, 18, 19]
  Total reward: -4.4264, Per descriptor: -0.4426
Step 22: Currently selected descriptors: [0, 3, 5, 8, 12, 13, 15, 17, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 3, 5, 6, 8, 12, 13, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 6, 8, 12, 13, 15, 17, 18, 19]
  Total reward: -4.4433, Per descriptor: -0.4039
Step 23: Currently selected descriptors: [0, 3, 5, 6, 8, 12, 13, 15, 17, 18, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 3, 5, 6, 8, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 5, 6, 8, 12, 13, 17, 18, 19]
  Total reward: -4.4583, Per descriptor: -0.4458
Step 24: Currently selected descriptors: [0, 3, 5, 6, 8, 12, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [0, 3, 6, 8, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 6, 8, 12, 13, 17, 18, 19]
  Total reward: -4.4620, Per descriptor: -0.4958
Step 25: Currently selected descriptors: [0, 3, 6, 8, 12, 13, 17, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 3, 6, 7, 8, 12, 13, 17, 18, 19]
  Calculating reward for descriptors: [0, 3, 6, 7, 8, 12, 13, 17, 18, 19]
  Total reward: -4.4542, Per descriptor: -0.4454
Step 26: Currently selected descriptors: [0, 3, 6, 7, 8, 12, 13, 17, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 3, 6, 7, 8, 12, 13, 17, 18]
  Calculating reward for descriptors: [0, 3, 6, 7, 8, 12, 13, 17, 18]
  Total reward: -4.4749, Per descriptor: -0.4972
Step 27: Currently selected descriptors: [0, 3, 6, 7, 8, 12, 13, 17, 18]
  Action chosen: ADD descriptor 11
  New selection: [0, 3, 6, 7, 8, 11, 12, 13, 17, 18]
  Calculating reward for descriptors: [0, 3, 6, 7, 8, 11, 12, 13, 17, 18]
  Total reward: -4.5770, Per descriptor: -0.4577
Step 28: Currently selected descriptors: [0, 3, 6, 7, 8, 11, 12, 13, 17, 18]
  Action chosen: REMOVE descriptor 0
  New selection: [3, 6, 7, 8, 11, 12, 13, 17, 18]
  Calculating reward for descriptors: [3, 6, 7, 8, 11, 12, 13, 17, 18]
  Total reward: -4.5982, Per descriptor: -0.5109
Step 29: Currently selected descriptors: [3, 6, 7, 8, 11, 12, 13, 17, 18]
  Action chosen: ADD descriptor 16
  New selection: [3, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Calculating reward for descriptors: [3, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Total reward: -4.6014, Per descriptor: -0.4601
Step 30: Currently selected descriptors: [3, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Action chosen: ADD descriptor 4
  New selection: [3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Calculating reward for descriptors: [3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Total reward: -4.5535, Per descriptor: -0.4140
Step 31: Currently selected descriptors: [3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18]
  Action chosen: REMOVE descriptor 6
  New selection: [3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Calculating reward for descriptors: [3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Total reward: -4.5745, Per descriptor: -0.4574
Step 32: Currently selected descriptors: [3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Calculating reward for descriptors: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Total reward: -4.5616, Per descriptor: -0.4147
Step 33: Currently selected descriptors: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18]
  Action chosen: ADD descriptor 19
  New selection: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Total reward: -4.5221, Per descriptor: -0.3768
Step 34: Currently selected descriptors: [1, 3, 4, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [1, 3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Total reward: -4.5159, Per descriptor: -0.3474
Step 35: Currently selected descriptors: [1, 3, 4, 6, 7, 8, 11, 12, 13, 16, 17, 18, 19]
  Action chosen: ADD descriptor 14
  New selection: [1, 3, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 3, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Total reward: -4.4665, Per descriptor: -0.3190
Step 36: Currently selected descriptors: [1, 3, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Total reward: -4.4825, Per descriptor: -0.3448
Step 37: Currently selected descriptors: [1, 4, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Calculating reward for descriptors: [1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Total reward: -4.4850, Per descriptor: -0.3738
Step 38: Currently selected descriptors: [1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Total reward: -4.4782, Per descriptor: -0.3445
Step 39: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [0, 1, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Total reward: -4.4948, Per descriptor: -0.3746
Step 40: Currently selected descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 17, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19]
  Total reward: -4.5119, Per descriptor: -0.3471
Step 41: Currently selected descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 17, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]
  Total reward: -4.5228, Per descriptor: -0.3231
Step 42: Currently selected descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 19]
  Total reward: -4.5373, Per descriptor: -0.3490
Step 43: Currently selected descriptors: [0, 1, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 357 experiences...
  DQN training loss: 4779395.500000
Episode 15 Summary:
  Total reward: -189.5797
  Steps taken: 43
  Final descriptors: 13
  Epsilon: 0.928 (92.8% random, 7.2% DQN)
  Avg last 10 episodes: -105.1060
  Best so far: -8.7296 (3 descriptors)

--- Episode 16/50 ---
Episode 16 - Epsilon: 0.928 (92.8% random, 7.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 5
  New selection: [5]
  Calculating reward for descriptors: [5]
  Total reward: 1.4590, Per descriptor: 1.4590
Step 1: Currently selected descriptors: [5]
  Action chosen: ADD descriptor 3
  New selection: [3, 5]
  Calculating reward for descriptors: [3, 5]
  Total reward: -4.4456, Per descriptor: -2.2228
Step 2: Currently selected descriptors: [3, 5]
  Action chosen: ADD descriptor 2
  New selection: [2, 3, 5]
  Calculating reward for descriptors: [2, 3, 5]
  Total reward: -4.6062, Per descriptor: -1.5354
Step 3: Currently selected descriptors: [2, 3, 5]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 3, 5]
  Calculating reward for descriptors: [0, 2, 3, 5]
  Total reward: -4.6251, Per descriptor: -1.1563
Step 4: Currently selected descriptors: [0, 2, 3, 5]
  Action chosen: REMOVE descriptor 3
  New selection: [0, 2, 5]
  Calculating reward for descriptors: [0, 2, 5]
  Total reward: -4.6376, Per descriptor: -1.5459
Step 5: Currently selected descriptors: [0, 2, 5]
  Action chosen: ADD descriptor 18
  New selection: [0, 2, 5, 18]
  Calculating reward for descriptors: [0, 2, 5, 18]
  Total reward: -4.7032, Per descriptor: -1.1758
Step 6: Currently selected descriptors: [0, 2, 5, 18]
  Action chosen: ADD descriptor 3
  New selection: [0, 2, 3, 5, 18]
  Calculating reward for descriptors: [0, 2, 3, 5, 18]
  Total reward: -4.6598, Per descriptor: -0.9320
Step 7: Currently selected descriptors: [0, 2, 3, 5, 18]
  Action chosen: ADD descriptor 4
  New selection: [0, 2, 3, 4, 5, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 18]
  Total reward: -4.6290, Per descriptor: -0.7715
Step 8: Currently selected descriptors: [0, 2, 3, 4, 5, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 2, 3, 4, 5]
  Calculating reward for descriptors: [0, 2, 3, 4, 5]
  Total reward: -4.5871, Per descriptor: -0.9174
Step 9: Currently selected descriptors: [0, 2, 3, 4, 5]
  Action chosen: ADD descriptor 11
  New selection: [0, 2, 3, 4, 5, 11]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 11]
  Total reward: -4.4446, Per descriptor: -0.7408
Step 10: Currently selected descriptors: [0, 2, 3, 4, 5, 11]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 3, 4, 5, 11]
  Calculating reward for descriptors: [2, 3, 4, 5, 11]
  Total reward: -4.3996, Per descriptor: -0.8799
Step 11: Currently selected descriptors: [2, 3, 4, 5, 11]
  Action chosen: ADD descriptor 18
  New selection: [2, 3, 4, 5, 11, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 11, 18]
  Total reward: -4.4713, Per descriptor: -0.7452
Step 12: Currently selected descriptors: [2, 3, 4, 5, 11, 18]
  Action chosen: ADD descriptor 10
  New selection: [2, 3, 4, 5, 10, 11, 18]
  Calculating reward for descriptors: [2, 3, 4, 5, 10, 11, 18]
  Total reward: -4.4817, Per descriptor: -0.6402
Step 13: Currently selected descriptors: [2, 3, 4, 5, 10, 11, 18]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 3, 4, 5, 10, 11, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 10, 11, 18]
  Total reward: -4.5112, Per descriptor: -0.5639
Step 14: Currently selected descriptors: [0, 2, 3, 4, 5, 10, 11, 18]
  Action chosen: ADD descriptor 16
  New selection: [0, 2, 3, 4, 5, 10, 11, 16, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 10, 11, 16, 18]
  Total reward: -4.4676, Per descriptor: -0.4964
Step 15: Currently selected descriptors: [0, 2, 3, 4, 5, 10, 11, 16, 18]
  Action chosen: ADD descriptor 17
  New selection: [0, 2, 3, 4, 5, 10, 11, 16, 17, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 10, 11, 16, 17, 18]
  Total reward: -4.4887, Per descriptor: -0.4489
Step 16: Currently selected descriptors: [0, 2, 3, 4, 5, 10, 11, 16, 17, 18]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 2, 3, 4, 5, 10, 11, 17, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 10, 11, 17, 18]
  Total reward: -4.5358, Per descriptor: -0.5040
Step 17: Currently selected descriptors: [0, 2, 3, 4, 5, 10, 11, 17, 18]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 2, 3, 4, 5, 11, 17, 18]
  Calculating reward for descriptors: [0, 2, 3, 4, 5, 11, 17, 18]
  Total reward: -4.5243, Per descriptor: -0.5655
Step 18: Currently selected descriptors: [0, 2, 3, 4, 5, 11, 17, 18]
  Action chosen: REMOVE descriptor 2
  New selection: [0, 3, 4, 5, 11, 17, 18]
  Calculating reward for descriptors: [0, 3, 4, 5, 11, 17, 18]
  Total reward: -4.4705, Per descriptor: -0.6386
Step 19: Currently selected descriptors: [0, 3, 4, 5, 11, 17, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 376 experiences...
  DQN training loss: 6441809.000000
Episode 16 Summary:
  Total reward: -80.2299
  Steps taken: 19
  Final descriptors: 7
  Epsilon: 0.923 (92.3% random, 7.7% DQN)
  Avg last 10 episodes: -105.2580
  Best so far: -8.7296 (3 descriptors)

--- Episode 17/50 ---
Episode 17 - Epsilon: 0.923 (92.3% random, 7.7% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 10
  New selection: [10]
  Calculating reward for descriptors: [10]
  Total reward: 1.4672, Per descriptor: 1.4672
Step 1: Currently selected descriptors: [10]
  Action chosen: ADD descriptor 4
  New selection: [4, 10]
  Calculating reward for descriptors: [4, 10]
  Total reward: -4.6485, Per descriptor: -2.3242
Step 2: Currently selected descriptors: [4, 10]
  Action chosen: ADD descriptor 19
  New selection: [4, 10, 19]
  Calculating reward for descriptors: [4, 10, 19]
  Total reward: -4.5490, Per descriptor: -1.5163
Step 3: Currently selected descriptors: [4, 10, 19]
  Action chosen: ADD descriptor 6
  New selection: [4, 6, 10, 19]
  Calculating reward for descriptors: [4, 6, 10, 19]
  Total reward: -4.5680, Per descriptor: -1.1420
Step 4: Currently selected descriptors: [4, 6, 10, 19]
  Action chosen: ADD descriptor 16
  New selection: [4, 6, 10, 16, 19]
  Calculating reward for descriptors: [4, 6, 10, 16, 19]
  Total reward: -4.3934, Per descriptor: -0.8787
Step 5: Currently selected descriptors: [4, 6, 10, 16, 19]
  Action chosen: ADD descriptor 8
  New selection: [4, 6, 8, 10, 16, 19]
  Calculating reward for descriptors: [4, 6, 8, 10, 16, 19]
  Total reward: -4.3794, Per descriptor: -0.7299
Step 6: Currently selected descriptors: [4, 6, 8, 10, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [4, 6, 8, 10, 16, 18, 19]
  Calculating reward for descriptors: [4, 6, 8, 10, 16, 18, 19]
  Total reward: -4.4350, Per descriptor: -0.6336
Step 7: Currently selected descriptors: [4, 6, 8, 10, 16, 18, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [4, 6, 8, 16, 18, 19]
  Calculating reward for descriptors: [4, 6, 8, 16, 18, 19]
  Total reward: -4.4013, Per descriptor: -0.7336
Step 8: Currently selected descriptors: [4, 6, 8, 16, 18, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [4, 8, 16, 18, 19]
  Calculating reward for descriptors: [4, 8, 16, 18, 19]
  Total reward: -4.3278, Per descriptor: -0.8656
Step 9: Currently selected descriptors: [4, 8, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [4, 8, 16, 18]
  Calculating reward for descriptors: [4, 8, 16, 18]
  Total reward: -4.3348, Per descriptor: -1.0837
Step 10: Currently selected descriptors: [4, 8, 16, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 386 experiences...
  DQN training loss: 2563679.500000
Episode 17 Summary:
  Total reward: -38.5700
  Steps taken: 10
  Final descriptors: 4
  Epsilon: 0.918 (91.8% random, 8.2% DQN)
  Avg last 10 episodes: -108.2420
  Best so far: -8.7296 (3 descriptors)

--- Episode 18/50 ---
Episode 18 - Epsilon: 0.918 (91.8% random, 8.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 10
  New selection: [10]
  Calculating reward for descriptors: [10]
  Total reward: 1.4672, Per descriptor: 1.4672
Step 1: Currently selected descriptors: [10]
  Action chosen: ADD descriptor 0
  New selection: [0, 10]
  Calculating reward for descriptors: [0, 10]
  Total reward: -4.9783, Per descriptor: -2.4892
Step 2: Currently selected descriptors: [0, 10]
  Action chosen: ADD descriptor 19
  New selection: [0, 10, 19]
  Calculating reward for descriptors: [0, 10, 19]
  Total reward: -4.6647, Per descriptor: -1.5549
Step 3: Currently selected descriptors: [0, 10, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 389 experiences...
  DQN training loss: 5824042.500000
  NEW BEST! Reward: -8.1758 with 3 descriptors
Episode 18 Summary:
  Total reward: -8.1758
  Steps taken: 3
  Final descriptors: 3
  Epsilon: 0.914 (91.4% random, 8.6% DQN)
  Avg last 10 episodes: -97.1610
  Best so far: -8.1758 (3 descriptors)

--- Episode 19/50 ---
Episode 19 - Epsilon: 0.914 (91.4% random, 8.6% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 13
  New selection: [13]
  Calculating reward for descriptors: [13]
  Total reward: 1.4035, Per descriptor: 1.4035
Step 1: Currently selected descriptors: [13]
  Action chosen: ADD descriptor 19
  New selection: [13, 19]
  Calculating reward for descriptors: [13, 19]
  Total reward: -4.2918, Per descriptor: -2.1459
Step 2: Currently selected descriptors: [13, 19]
  Action chosen: ADD descriptor 6
  New selection: [6, 13, 19]
  Calculating reward for descriptors: [6, 13, 19]
  Total reward: -4.4072, Per descriptor: -1.4691
Step 3: Currently selected descriptors: [6, 13, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [13, 19]
  Calculating reward for descriptors: [13, 19]
  Total reward: -4.2918, Per descriptor: -2.1459
Step 4: Currently selected descriptors: [13, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 393 experiences...
  DQN training loss: 5564695.000000
Episode 19 Summary:
  Total reward: -11.5874
  Steps taken: 4
  Final descriptors: 2
  Epsilon: 0.909 (90.9% random, 9.1% DQN)
  Avg last 10 episodes: -95.4352
  Best so far: -8.1758 (3 descriptors)

--- Episode 20/50 ---
Episode 20 - Epsilon: 0.909 (90.9% random, 9.1% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 13
  New selection: [13]
  Calculating reward for descriptors: [13]
  Total reward: 1.4035, Per descriptor: 1.4035
Step 1: Currently selected descriptors: [13]
  Action chosen: ADD descriptor 7
  New selection: [7, 13]
  Calculating reward for descriptors: [7, 13]
  Total reward: -4.4234, Per descriptor: -2.2117
Step 2: Currently selected descriptors: [7, 13]
  Action chosen: ADD descriptor 19
  New selection: [7, 13, 19]
  Calculating reward for descriptors: [7, 13, 19]
  Total reward: -4.2602, Per descriptor: -1.4201
Step 3: Currently selected descriptors: [7, 13, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 7, 13, 19]
  Calculating reward for descriptors: [4, 7, 13, 19]
  Total reward: -4.2915, Per descriptor: -1.0729
Step 4: Currently selected descriptors: [4, 7, 13, 19]
  Action chosen: ADD descriptor 18
  New selection: [4, 7, 13, 18, 19]
  Calculating reward for descriptors: [4, 7, 13, 18, 19]
  Total reward: -4.3581, Per descriptor: -0.8716
Step 5: Currently selected descriptors: [4, 7, 13, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [4, 7, 13, 18]
  Calculating reward for descriptors: [4, 7, 13, 18]
  Total reward: -4.3882, Per descriptor: -1.0970
Step 6: Currently selected descriptors: [4, 7, 13, 18]
  Action chosen: REMOVE descriptor 13
  New selection: [4, 7, 18]
  Calculating reward for descriptors: [4, 7, 18]
  Total reward: -4.3598, Per descriptor: -1.4533
Step 7: Currently selected descriptors: [4, 7, 18]
  Action chosen: ADD descriptor 5
  New selection: [4, 5, 7, 18]
  Calculating reward for descriptors: [4, 5, 7, 18]
  Total reward: -4.4589, Per descriptor: -1.1147
Step 8: Currently selected descriptors: [4, 5, 7, 18]
  Action chosen: ADD descriptor 10
  New selection: [4, 5, 7, 10, 18]
  Calculating reward for descriptors: [4, 5, 7, 10, 18]
  Total reward: -4.4476, Per descriptor: -0.8895
Step 9: Currently selected descriptors: [4, 5, 7, 10, 18]
  Action chosen: REMOVE descriptor 10
  New selection: [4, 5, 7, 18]
  Calculating reward for descriptors: [4, 5, 7, 18]
  Total reward: -4.4589, Per descriptor: -1.1147
Step 10: Currently selected descriptors: [4, 5, 7, 18]
  Action chosen: REMOVE descriptor 7
  New selection: [4, 5, 18]
  Calculating reward for descriptors: [4, 5, 18]
  Total reward: -4.7679, Per descriptor: -1.5893
Step 11: Currently selected descriptors: [4, 5, 18]
  Action chosen: ADD descriptor 9
  New selection: [4, 5, 9, 18]
  Calculating reward for descriptors: [4, 5, 9, 18]
  Total reward: -4.6008, Per descriptor: -1.1502
Step 12: Currently selected descriptors: [4, 5, 9, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 405 experiences...
  DQN training loss: 6160219.500000
Episode 20 Summary:
  Total reward: -47.4117
  Steps taken: 12
  Final descriptors: 4
  Epsilon: 0.905 (90.5% random, 9.5% DQN)
  Avg last 10 episodes: -97.5024
  Best so far: -8.1758 (3 descriptors)

--- Episode 21/50 ---
Episode 21 - Epsilon: 0.905 (90.5% random, 9.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 12
  New selection: [12]
  Calculating reward for descriptors: [12]
  Total reward: 1.5090, Per descriptor: 1.5090
Step 1: Currently selected descriptors: [12]
  Action chosen: ADD descriptor 11
  New selection: [11, 12]
  Calculating reward for descriptors: [11, 12]
  Total reward: -6.2531, Per descriptor: -3.1266
Step 2: Currently selected descriptors: [11, 12]
  Action chosen: ADD descriptor 14
  New selection: [11, 12, 14]
  Calculating reward for descriptors: [11, 12, 14]
  Total reward: -4.8029, Per descriptor: -1.6010
Step 3: Currently selected descriptors: [11, 12, 14]
  Action chosen: ADD descriptor 19
  New selection: [11, 12, 14, 19]
  Calculating reward for descriptors: [11, 12, 14, 19]
  Total reward: -4.4655, Per descriptor: -1.1164
Step 4: Currently selected descriptors: [11, 12, 14, 19]
  Action chosen: ADD descriptor 17
  New selection: [11, 12, 14, 17, 19]
  Calculating reward for descriptors: [11, 12, 14, 17, 19]
  Total reward: -4.4024, Per descriptor: -0.8805
Step 5: Currently selected descriptors: [11, 12, 14, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [11, 12, 14, 17]
  Calculating reward for descriptors: [11, 12, 14, 17]
  Total reward: -4.5115, Per descriptor: -1.1279
Step 6: Currently selected descriptors: [11, 12, 14, 17]
  Action chosen: ADD descriptor 19
  New selection: [11, 12, 14, 17, 19]
  Calculating reward for descriptors: [11, 12, 14, 17, 19]
  Total reward: -4.4024, Per descriptor: -0.8805
Step 7: Currently selected descriptors: [11, 12, 14, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [10, 11, 12, 14, 17, 19]
  Calculating reward for descriptors: [10, 11, 12, 14, 17, 19]
  Total reward: -4.3897, Per descriptor: -0.7316
Step 8: Currently selected descriptors: [10, 11, 12, 14, 17, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [11, 12, 14, 17, 19]
  Calculating reward for descriptors: [11, 12, 14, 17, 19]
  Total reward: -4.4024, Per descriptor: -0.8805
Step 9: Currently selected descriptors: [11, 12, 14, 17, 19]
  Action chosen: ADD descriptor 5
  New selection: [5, 11, 12, 14, 17, 19]
  Calculating reward for descriptors: [5, 11, 12, 14, 17, 19]
  Total reward: -4.3490, Per descriptor: -0.7248
Step 10: Currently selected descriptors: [5, 11, 12, 14, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [5, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 11, 12, 14, 16, 17, 19]
  Total reward: -4.4049, Per descriptor: -0.6293
Step 11: Currently selected descriptors: [5, 11, 12, 14, 16, 17, 19]
  Action chosen: ADD descriptor 9
  New selection: [5, 9, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 9, 11, 12, 14, 16, 17, 19]
  Total reward: -4.3734, Per descriptor: -0.5467
Step 12: Currently selected descriptors: [5, 9, 11, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [5, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 11, 12, 14, 16, 17, 19]
  Total reward: -4.4049, Per descriptor: -0.6293
Step 13: Currently selected descriptors: [5, 11, 12, 14, 16, 17, 19]
  Action chosen: ADD descriptor 8
  New selection: [5, 8, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 8, 11, 12, 14, 16, 17, 19]
  Total reward: -4.3540, Per descriptor: -0.5443
Step 14: Currently selected descriptors: [5, 8, 11, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 8
  New selection: [5, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 11, 12, 14, 16, 17, 19]
  Total reward: -4.4049, Per descriptor: -0.6293
Step 15: Currently selected descriptors: [5, 11, 12, 14, 16, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [5, 7, 11, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [5, 7, 11, 12, 14, 16, 17, 19]
  Total reward: -4.6325, Per descriptor: -0.5791
Step 16: Currently selected descriptors: [5, 7, 11, 12, 14, 16, 17, 19]
  Action chosen: ADD descriptor 15
  New selection: [5, 7, 11, 12, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [5, 7, 11, 12, 14, 15, 16, 17, 19]
  Total reward: -4.7233, Per descriptor: -0.5248
Step 17: Currently selected descriptors: [5, 7, 11, 12, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 5, 7, 11, 12, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 5, 7, 11, 12, 14, 15, 16, 17, 19]
  Total reward: -4.6549, Per descriptor: -0.4655
Step 18: Currently selected descriptors: [1, 5, 7, 11, 12, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 5, 7, 11, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 5, 7, 11, 14, 15, 16, 17, 19]
  Total reward: -4.5752, Per descriptor: -0.5084
Step 19: Currently selected descriptors: [1, 5, 7, 11, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 4
  New selection: [1, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Total reward: -4.5231, Per descriptor: -0.4523
Step 20: Currently selected descriptors: [1, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Total reward: -4.4921, Per descriptor: -0.4084
Step 21: Currently selected descriptors: [1, 3, 4, 5, 7, 11, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 3, 4, 5, 7, 11, 14, 15, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 7, 11, 14, 15, 17, 19]
  Total reward: -4.4730, Per descriptor: -0.4473
Step 22: Currently selected descriptors: [1, 3, 4, 5, 7, 11, 14, 15, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 3, 4, 7, 11, 14, 15, 17, 19]
  Calculating reward for descriptors: [1, 3, 4, 7, 11, 14, 15, 17, 19]
  Total reward: -4.5116, Per descriptor: -0.5013
Step 23: Currently selected descriptors: [1, 3, 4, 7, 11, 14, 15, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 3, 4, 7, 11, 14, 15, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 11, 14, 15, 17, 19]
  Total reward: -4.5162, Per descriptor: -0.4516
Step 24: Currently selected descriptors: [1, 2, 3, 4, 7, 11, 14, 15, 17, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 3, 4, 7, 11, 12, 14, 15, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 11, 12, 14, 15, 17, 19]
  Total reward: -4.5577, Per descriptor: -0.4143
Step 25: Currently selected descriptors: [1, 2, 3, 4, 7, 11, 12, 14, 15, 17, 19]
  Action chosen: REMOVE descriptor 14
  New selection: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Total reward: -4.6522, Per descriptor: -0.4652
Step 26: Currently selected descriptors: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 2, 3, 4, 7, 11, 15, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 11, 15, 17, 19]
  Total reward: -4.6044, Per descriptor: -0.5116
Step 27: Currently selected descriptors: [1, 2, 3, 4, 7, 11, 15, 17, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Total reward: -4.6522, Per descriptor: -0.4652
Step 28: Currently selected descriptors: [1, 2, 3, 4, 7, 11, 12, 15, 17, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [2, 3, 4, 7, 11, 12, 15, 17, 19]
  Calculating reward for descriptors: [2, 3, 4, 7, 11, 12, 15, 17, 19]
  Total reward: -4.6904, Per descriptor: -0.5212
Step 29: Currently selected descriptors: [2, 3, 4, 7, 11, 12, 15, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [2, 3, 4, 7, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [2, 3, 4, 7, 11, 12, 15, 16, 17, 19]
  Total reward: -4.7017, Per descriptor: -0.4702
Step 30: Currently selected descriptors: [2, 3, 4, 7, 11, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [2, 3, 4, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [2, 3, 4, 11, 12, 15, 16, 17, 19]
  Total reward: -4.5610, Per descriptor: -0.5068
Step 31: Currently selected descriptors: [2, 3, 4, 11, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [3, 4, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [3, 4, 11, 12, 15, 16, 17, 19]
  Total reward: -4.5833, Per descriptor: -0.5729
Step 32: Currently selected descriptors: [3, 4, 11, 12, 15, 16, 17, 19]
  Action chosen: ADD descriptor 14
  New selection: [3, 4, 11, 12, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [3, 4, 11, 12, 14, 15, 16, 17, 19]
  Total reward: -4.4835, Per descriptor: -0.4982
Step 33: Currently selected descriptors: [3, 4, 11, 12, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 3, 4, 11, 12, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [2, 3, 4, 11, 12, 14, 15, 16, 17, 19]
  Total reward: -4.4779, Per descriptor: -0.4478
Step 34: Currently selected descriptors: [2, 3, 4, 11, 12, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [2, 3, 4, 11, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [2, 3, 4, 11, 12, 14, 15, 16, 19]
  Total reward: -4.4907, Per descriptor: -0.4990
Step 35: Currently selected descriptors: [2, 3, 4, 11, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 3, 4, 11, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 11, 12, 14, 15, 16, 19]
  Total reward: -4.4798, Per descriptor: -0.4480
Step 36: Currently selected descriptors: [1, 2, 3, 4, 11, 12, 14, 15, 16, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [1, 2, 3, 4, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 12, 14, 15, 16, 19]
  Total reward: -4.4266, Per descriptor: -0.4918
Step 37: Currently selected descriptors: [1, 2, 3, 4, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [1, 2, 3, 4, 7, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 12, 14, 15, 16, 19]
  Total reward: -4.4798, Per descriptor: -0.4480
Step 38: Currently selected descriptors: [1, 2, 3, 4, 7, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [1, 2, 3, 4, 7, 9, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 7, 9, 12, 14, 15, 16, 19]
  Total reward: -4.4522, Per descriptor: -0.4047
Step 39: Currently selected descriptors: [1, 2, 3, 4, 7, 9, 12, 14, 15, 16, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 2, 4, 7, 9, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 7, 9, 12, 14, 15, 16, 19]
  Total reward: -4.4808, Per descriptor: -0.4481
Step 40: Currently selected descriptors: [1, 2, 4, 7, 9, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 8
  New selection: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 19]
  Total reward: -4.4542, Per descriptor: -0.4049
Step 41: Currently selected descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4496, Per descriptor: -0.3708
Step 42: Currently selected descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 13
  New selection: [1, 2, 4, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19]
  Total reward: -4.4624, Per descriptor: -0.3433
Step 43: Currently selected descriptors: [1, 2, 4, 7, 8, 9, 12, 13, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4496, Per descriptor: -0.3708
Step 44: Currently selected descriptors: [1, 2, 4, 7, 8, 9, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 2, 4, 8, 9, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4141, Per descriptor: -0.4013
Step 45: Currently selected descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Total reward: -4.4041, Per descriptor: -0.4404
Step 46: Currently selected descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 2, 4, 8, 9, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 9, 14, 15, 18, 19]
  Total reward: -4.4125, Per descriptor: -0.4903
Step 47: Currently selected descriptors: [1, 2, 4, 8, 9, 14, 15, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Total reward: -4.4041, Per descriptor: -0.4404
Step 48: Currently selected descriptors: [1, 2, 4, 8, 9, 12, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [1, 2, 4, 8, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 12, 14, 15, 18, 19]
  Total reward: -4.3908, Per descriptor: -0.4879
Step 49: Currently selected descriptors: [1, 2, 4, 8, 12, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 2, 4, 8, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 14, 15, 18, 19]
  Total reward: -4.3842, Per descriptor: -0.5480
Step 50: Currently selected descriptors: [1, 2, 4, 8, 14, 15, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [1, 2, 4, 5, 8, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 8, 14, 15, 18, 19]
  Total reward: -4.4036, Per descriptor: -0.4893
Step 51: Currently selected descriptors: [1, 2, 4, 5, 8, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 8
  New selection: [1, 2, 4, 5, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 14, 15, 18, 19]
  Total reward: -4.4294, Per descriptor: -0.5537
Step 52: Currently selected descriptors: [1, 2, 4, 5, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [1, 4, 5, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 14, 15, 18, 19]
  Total reward: -4.3828, Per descriptor: -0.6261
Step 53: Currently selected descriptors: [1, 4, 5, 14, 15, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [1, 4, 5, 11, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 11, 14, 15, 18, 19]
  Total reward: -4.3844, Per descriptor: -0.5481
Step 54: Currently selected descriptors: [1, 4, 5, 11, 14, 15, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [1, 4, 5, 7, 11, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 11, 14, 15, 18, 19]
  Total reward: -4.5222, Per descriptor: -0.5025
Step 55: Currently selected descriptors: [1, 4, 5, 7, 11, 14, 15, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 4, 5, 7, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 11, 12, 14, 15, 18, 19]
  Total reward: -4.5839, Per descriptor: -0.4584
Step 56: Currently selected descriptors: [1, 4, 5, 7, 11, 12, 14, 15, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [1, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.5959, Per descriptor: -0.4178
Step 57: Currently selected descriptors: [1, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.5695, Per descriptor: -0.3808
Step 58: Currently selected descriptors: [1, 2, 4, 5, 7, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4757, Per descriptor: -0.4069
Step 59: Currently selected descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [1, 2, 4, 5, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 18, 19]
  Total reward: -4.4559, Per descriptor: -0.4456
Step 60: Currently selected descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4757, Per descriptor: -0.4069
Step 61: Currently selected descriptors: [1, 2, 4, 5, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 9
  New selection: [1, 2, 4, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4498, Per descriptor: -0.3708
Step 62: Currently selected descriptors: [1, 2, 4, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 14
  New selection: [1, 2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5111, Per descriptor: -0.4101
Step 63: Currently selected descriptors: [1, 2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5055, Per descriptor: -0.4506
Step 64: Currently selected descriptors: [2, 4, 5, 9, 11, 12, 15, 16, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [2, 4, 5, 6, 9, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 5, 6, 9, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5019, Per descriptor: -0.4093
Step 65: Currently selected descriptors: [2, 4, 5, 6, 9, 11, 12, 15, 16, 18, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 470 experiences...
  DQN training loss: 5433455.000000
  Updated target network weights
Episode 21 Summary:
  Total reward: -287.7611
  Steps taken: 65
  Final descriptors: 11
  Epsilon: 0.900 (90.0% random, 10.0% DQN)
  Avg last 10 episodes: -112.0972
  Best so far: -8.1758 (3 descriptors)

--- Episode 22/50 ---
Episode 22 - Epsilon: 0.900 (90.0% random, 10.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 19
  New selection: [19]
  Calculating reward for descriptors: [19]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [19]
  Action chosen: ADD descriptor 13
  New selection: [13, 19]
  Calculating reward for descriptors: [13, 19]
  Total reward: -4.2918, Per descriptor: -2.1459
Step 2: Currently selected descriptors: [13, 19]
  Action chosen: ADD descriptor 15
  New selection: [13, 15, 19]
  Calculating reward for descriptors: [13, 15, 19]
  Total reward: -4.2462, Per descriptor: -1.4154
Step 3: Currently selected descriptors: [13, 15, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 473 experiences...
  DQN training loss: 9735329.000000
  NEW BEST! Reward: -7.0341 with 3 descriptors
Episode 22 Summary:
  Total reward: -7.0341
  Steps taken: 3
  Final descriptors: 3
  Epsilon: 0.896 (89.6% random, 10.4% DQN)
  Avg last 10 episodes: -111.6261
  Best so far: -7.0341 (3 descriptors)

--- Episode 23/50 ---
Episode 23 - Epsilon: 0.896 (89.6% random, 10.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 19
  New selection: [19]
  Calculating reward for descriptors: [19]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [19]
  Action chosen: ADD descriptor 0
  New selection: [0, 19]
  Calculating reward for descriptors: [0, 19]
  Total reward: -4.5610, Per descriptor: -2.2805
Step 2: Currently selected descriptors: [0, 19]
  Action chosen: ADD descriptor 3
  New selection: [0, 3, 19]
  Calculating reward for descriptors: [0, 3, 19]
  Total reward: -4.6101, Per descriptor: -1.5367
Step 3: Currently selected descriptors: [0, 3, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 3, 8, 19]
  Calculating reward for descriptors: [0, 3, 8, 19]
  Total reward: -4.4695, Per descriptor: -1.1174
Step 4: Currently selected descriptors: [0, 3, 8, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 3, 6, 8, 19]
  Calculating reward for descriptors: [0, 3, 6, 8, 19]
  Total reward: -4.4842, Per descriptor: -0.8968
Step 5: Currently selected descriptors: [0, 3, 6, 8, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 3, 6, 8, 12, 19]
  Calculating reward for descriptors: [0, 3, 6, 8, 12, 19]
  Total reward: -4.3713, Per descriptor: -0.7285
Step 6: Currently selected descriptors: [0, 3, 6, 8, 12, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 3, 6, 8, 12, 16, 19]
  Calculating reward for descriptors: [0, 3, 6, 8, 12, 16, 19]
  Total reward: -4.3728, Per descriptor: -0.6247
Step 7: Currently selected descriptors: [0, 3, 6, 8, 12, 16, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 3, 6, 8, 10, 12, 16, 19]
  Calculating reward for descriptors: [0, 3, 6, 8, 10, 12, 16, 19]
  Total reward: -4.4002, Per descriptor: -0.5500
Step 8: Currently selected descriptors: [0, 3, 6, 8, 10, 12, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 3, 6, 8, 10, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 3, 6, 8, 10, 12, 16, 19]
  Total reward: -4.4286, Per descriptor: -0.4921
Step 9: Currently selected descriptors: [0, 1, 3, 6, 8, 10, 12, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 3, 6, 7, 8, 10, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 3, 6, 7, 8, 10, 12, 16, 19]
  Total reward: -4.4449, Per descriptor: -0.4445
Step 10: Currently selected descriptors: [0, 1, 3, 6, 7, 8, 10, 12, 16, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 1, 3, 6, 7, 8, 10, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 6, 7, 8, 10, 12, 16, 17, 19]
  Total reward: -4.4579, Per descriptor: -0.4053
Step 11: Currently selected descriptors: [0, 1, 3, 6, 7, 8, 10, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 1, 3, 6, 7, 8, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 3, 6, 7, 8, 12, 16, 17, 19]
  Total reward: -4.4524, Per descriptor: -0.4452
Step 12: Currently selected descriptors: [0, 1, 3, 6, 7, 8, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 3, 6, 7, 8, 12, 16, 17]
  Calculating reward for descriptors: [0, 1, 3, 6, 7, 8, 12, 16, 17]
  Total reward: -4.4738, Per descriptor: -0.4971
Step 13: Currently selected descriptors: [0, 1, 3, 6, 7, 8, 12, 16, 17]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 3, 5, 6, 7, 8, 12, 16, 17]
  Calculating reward for descriptors: [0, 1, 3, 5, 6, 7, 8, 12, 16, 17]
  Total reward: -4.4539, Per descriptor: -0.4454
Step 14: Currently selected descriptors: [0, 1, 3, 5, 6, 7, 8, 12, 16, 17]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 3, 5, 6, 8, 12, 16, 17]
  Calculating reward for descriptors: [0, 1, 3, 5, 6, 8, 12, 16, 17]
  Total reward: -4.4365, Per descriptor: -0.4929
Step 15: Currently selected descriptors: [0, 1, 3, 5, 6, 8, 12, 16, 17]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 3, 5, 6, 8, 12, 16, 17]
  Calculating reward for descriptors: [0, 1, 2, 3, 5, 6, 8, 12, 16, 17]
  Total reward: -4.4807, Per descriptor: -0.4481
Step 16: Currently selected descriptors: [0, 1, 2, 3, 5, 6, 8, 12, 16, 17]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17]
  Calculating reward for descriptors: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17]
  Total reward: -4.4849, Per descriptor: -0.4077
Step 17: Currently selected descriptors: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17, 19]
  Total reward: -4.4735, Per descriptor: -0.3728
Step 18: Currently selected descriptors: [0, 1, 2, 3, 5, 6, 8, 9, 12, 16, 17, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Total reward: -4.4688, Per descriptor: -0.3438
Step 19: Currently selected descriptors: [0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [0, 1, 2, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Total reward: -4.4716, Per descriptor: -0.3726
Step 20: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 8, 9, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 1, 2, 4, 5, 6, 8, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 8, 12, 16, 17, 19]
  Total reward: -4.4661, Per descriptor: -0.4060
Step 21: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 8, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 2, 4, 5, 6, 8, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 8, 16, 17, 19]
  Total reward: -4.5106, Per descriptor: -0.4511
Step 22: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 8, 16, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 495 experiences...
  DQN training loss: 6311392.500000
Episode 23 Summary:
  Total reward: -92.2692
  Steps taken: 22
  Final descriptors: 10
  Epsilon: 0.891 (89.1% random, 10.9% DQN)
  Avg last 10 episodes: -108.3945
  Best so far: -7.0341 (3 descriptors)

--- Episode 24/50 ---
Episode 24 - Epsilon: 0.891 (89.1% random, 10.9% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 11
  New selection: [11]
  Calculating reward for descriptors: [11]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [11]
  Action chosen: ADD descriptor 1
  New selection: [1, 11]
  Calculating reward for descriptors: [1, 11]
  Total reward: -4.2478, Per descriptor: -2.1239
Step 2: Currently selected descriptors: [1, 11]
  Action chosen: ADD descriptor 13
  New selection: [1, 11, 13]
  Calculating reward for descriptors: [1, 11, 13]
  Total reward: -4.3884, Per descriptor: -1.4628
Step 3: Currently selected descriptors: [1, 11, 13]
  Action chosen: ADD descriptor 17
  New selection: [1, 11, 13, 17]
  Calculating reward for descriptors: [1, 11, 13, 17]
  Total reward: -4.4374, Per descriptor: -1.1094
Step 4: Currently selected descriptors: [1, 11, 13, 17]
  Action chosen: REMOVE descriptor 13
  New selection: [1, 11, 17]
  Calculating reward for descriptors: [1, 11, 17]
  Total reward: -4.4001, Per descriptor: -1.4667
Step 5: Currently selected descriptors: [1, 11, 17]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 11, 17]
  Calculating reward for descriptors: [1, 3, 11, 17]
  Total reward: -4.4362, Per descriptor: -1.1091
Step 6: Currently selected descriptors: [1, 3, 11, 17]
  Action chosen: ADD descriptor 5
  New selection: [1, 3, 5, 11, 17]
  Calculating reward for descriptors: [1, 3, 5, 11, 17]
  Total reward: -4.4309, Per descriptor: -0.8862
Step 7: Currently selected descriptors: [1, 3, 5, 11, 17]
  Action chosen: ADD descriptor 13
  New selection: [1, 3, 5, 11, 13, 17]
  Calculating reward for descriptors: [1, 3, 5, 11, 13, 17]
  Total reward: -4.4233, Per descriptor: -0.7372
Step 8: Currently selected descriptors: [1, 3, 5, 11, 13, 17]
  Action chosen: ADD descriptor 12
  New selection: [1, 3, 5, 11, 12, 13, 17]
  Calculating reward for descriptors: [1, 3, 5, 11, 12, 13, 17]
  Total reward: -4.4570, Per descriptor: -0.6367
Step 9: Currently selected descriptors: [1, 3, 5, 11, 12, 13, 17]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 3, 5, 11, 12, 13, 17]
  Calculating reward for descriptors: [0, 1, 3, 5, 11, 12, 13, 17]
  Total reward: -4.4640, Per descriptor: -0.5580
Step 10: Currently selected descriptors: [0, 1, 3, 5, 11, 12, 13, 17]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 3, 5, 7, 11, 12, 13, 17]
  Calculating reward for descriptors: [0, 1, 3, 5, 7, 11, 12, 13, 17]
  Total reward: -4.6007, Per descriptor: -0.5112
Step 11: Currently selected descriptors: [0, 1, 3, 5, 7, 11, 12, 13, 17]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 3, 5, 11, 12, 13, 17]
  Calculating reward for descriptors: [0, 1, 3, 5, 11, 12, 13, 17]
  Total reward: -4.4640, Per descriptor: -0.5580
Step 12: Currently selected descriptors: [0, 1, 3, 5, 11, 12, 13, 17]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 3, 5, 11, 12, 13, 17]
  Calculating reward for descriptors: [0, 3, 5, 11, 12, 13, 17]
  Total reward: -4.4458, Per descriptor: -0.6351
Step 13: Currently selected descriptors: [0, 3, 5, 11, 12, 13, 17]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 508 experiences...
  DQN training loss: 5725334.000000
Episode 24 Summary:
  Total reward: -51.6915
  Steps taken: 13
  Final descriptors: 7
  Epsilon: 0.887 (88.7% random, 11.3% DQN)
  Avg last 10 episodes: -81.4310
  Best so far: -7.0341 (3 descriptors)

--- Episode 25/50 ---
Episode 25 - Epsilon: 0.887 (88.7% random, 11.3% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 10
  New selection: [10]
  Calculating reward for descriptors: [10]
  Total reward: 1.4672, Per descriptor: 1.4672
Step 1: Currently selected descriptors: [10]
  Action chosen: ADD descriptor 4
  New selection: [4, 10]
  Calculating reward for descriptors: [4, 10]
  Total reward: -4.6485, Per descriptor: -2.3242
Step 2: Currently selected descriptors: [4, 10]
  Action chosen: ADD descriptor 16
  New selection: [4, 10, 16]
  Calculating reward for descriptors: [4, 10, 16]
  Total reward: -4.2766, Per descriptor: -1.4255
Step 3: Currently selected descriptors: [4, 10, 16]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 10, 16]
  Calculating reward for descriptors: [0, 4, 10, 16]
  Total reward: -4.4132, Per descriptor: -1.1033
Step 4: Currently selected descriptors: [0, 4, 10, 16]
  Action chosen: ADD descriptor 9
  New selection: [0, 4, 9, 10, 16]
  Calculating reward for descriptors: [0, 4, 9, 10, 16]
  Total reward: -4.4521, Per descriptor: -0.8904
Step 5: Currently selected descriptors: [0, 4, 9, 10, 16]
  Action chosen: ADD descriptor 5
  New selection: [0, 4, 5, 9, 10, 16]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 16]
  Total reward: -4.4310, Per descriptor: -0.7385
Step 6: Currently selected descriptors: [0, 4, 5, 9, 10, 16]
  Action chosen: ADD descriptor 6
  New selection: [0, 4, 5, 6, 9, 10, 16]
  Calculating reward for descriptors: [0, 4, 5, 6, 9, 10, 16]
  Total reward: -4.4693, Per descriptor: -0.6385
Step 7: Currently selected descriptors: [0, 4, 5, 6, 9, 10, 16]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 4, 5, 9, 10, 16]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 16]
  Total reward: -4.4310, Per descriptor: -0.7385
Step 8: Currently selected descriptors: [0, 4, 5, 9, 10, 16]
  Action chosen: ADD descriptor 17
  New selection: [0, 4, 5, 9, 10, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 16, 17]
  Total reward: -4.4601, Per descriptor: -0.6372
Step 9: Currently selected descriptors: [0, 4, 5, 9, 10, 16, 17]
  Action chosen: ADD descriptor 12
  New selection: [0, 4, 5, 9, 10, 12, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 16, 17]
  Total reward: -4.4240, Per descriptor: -0.5530
Step 10: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 16, 17]
  Action chosen: ADD descriptor 13
  New selection: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Total reward: -4.4513, Per descriptor: -0.4946
Step 11: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 4, 5, 9, 10, 12, 13, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 17]
  Total reward: -4.4820, Per descriptor: -0.5602
Step 12: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 17]
  Action chosen: ADD descriptor 16
  New selection: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Total reward: -4.4513, Per descriptor: -0.4946
Step 13: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17]
  Action chosen: ADD descriptor 15
  New selection: [0, 4, 5, 9, 10, 12, 13, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 15, 16, 17]
  Total reward: -4.4756, Per descriptor: -0.4476
Step 14: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 15, 16, 17]
  Action chosen: ADD descriptor 8
  New selection: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Total reward: -4.4809, Per descriptor: -0.4074
Step 15: Currently selected descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Action chosen: ADD descriptor 14
  New selection: [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17]
  Total reward: -4.4291, Per descriptor: -0.3691
Step 16: Currently selected descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 14
  New selection: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Total reward: -4.4809, Per descriptor: -0.4074
Step 17: Currently selected descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 4, 5, 8, 9, 12, 13, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 12, 13, 15, 16, 17]
  Total reward: -4.4802, Per descriptor: -0.4480
Step 18: Currently selected descriptors: [0, 4, 5, 8, 9, 12, 13, 15, 16, 17]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 4, 5, 8, 9, 12, 13, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 12, 13, 16, 17]
  Total reward: -4.4536, Per descriptor: -0.4948
Step 19: Currently selected descriptors: [0, 4, 5, 8, 9, 12, 13, 16, 17]
  Action chosen: REMOVE descriptor 13
  New selection: [0, 4, 5, 8, 9, 12, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 12, 16, 17]
  Total reward: -4.4051, Per descriptor: -0.5506
Step 20: Currently selected descriptors: [0, 4, 5, 8, 9, 12, 16, 17]
  Action chosen: ADD descriptor 15
  New selection: [0, 4, 5, 8, 9, 12, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 12, 15, 16, 17]
  Total reward: -4.4530, Per descriptor: -0.4948
Step 21: Currently selected descriptors: [0, 4, 5, 8, 9, 12, 15, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 4, 5, 8, 9, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 12, 15, 16, 17, 19]
  Total reward: -4.4222, Per descriptor: -0.4422
Step 22: Currently selected descriptors: [0, 4, 5, 8, 9, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 4, 5, 8, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 8, 12, 15, 16, 17, 19]
  Total reward: -4.4156, Per descriptor: -0.4906
Step 23: Currently selected descriptors: [0, 4, 5, 8, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 4, 5, 8, 12, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 12, 15, 16, 17]
  Total reward: -4.4464, Per descriptor: -0.5558
Step 24: Currently selected descriptors: [0, 4, 5, 8, 12, 15, 16, 17]
  Action chosen: ADD descriptor 14
  New selection: [0, 4, 5, 8, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 12, 14, 15, 16, 17]
  Total reward: -4.3815, Per descriptor: -0.4868
Step 25: Currently selected descriptors: [0, 4, 5, 8, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 13
  New selection: [0, 4, 5, 8, 12, 13, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 5, 8, 12, 13, 14, 15, 16, 17]
  Total reward: -4.3955, Per descriptor: -0.4395
Step 26: Currently selected descriptors: [0, 4, 5, 8, 12, 13, 14, 15, 16, 17]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 534 experiences...
  DQN training loss: 6655299.000000
Episode 25 Summary:
  Total reward: -109.6426
  Steps taken: 26
  Final descriptors: 10
  Epsilon: 0.882 (88.2% random, 11.8% DQN)
  Avg last 10 episodes: -73.4373
  Best so far: -7.0341 (3 descriptors)

--- Episode 26/50 ---
Episode 26 - Epsilon: 0.882 (88.2% random, 11.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: ADD descriptor 17
  New selection: [16, 17]
  Calculating reward for descriptors: [16, 17]
  Total reward: -4.2499, Per descriptor: -2.1250
Step 2: Currently selected descriptors: [16, 17]
  Action chosen: ADD descriptor 2
  New selection: [2, 16, 17]
  Calculating reward for descriptors: [2, 16, 17]
  Total reward: -4.5329, Per descriptor: -1.5110
Step 3: Currently selected descriptors: [2, 16, 17]
  Action chosen: REMOVE descriptor 2
  New selection: [16, 17]
  Calculating reward for descriptors: [16, 17]
  Total reward: -4.2499, Per descriptor: -2.1250
Step 4: Currently selected descriptors: [16, 17]
  Action chosen: ADD descriptor 10
  New selection: [10, 16, 17]
  Calculating reward for descriptors: [10, 16, 17]
  Total reward: -4.3732, Per descriptor: -1.4577
Step 5: Currently selected descriptors: [10, 16, 17]
  Action chosen: ADD descriptor 12
  New selection: [10, 12, 16, 17]
  Calculating reward for descriptors: [10, 12, 16, 17]
  Total reward: -4.4654, Per descriptor: -1.1164
Step 6: Currently selected descriptors: [10, 12, 16, 17]
  Action chosen: ADD descriptor 1
  New selection: [1, 10, 12, 16, 17]
  Calculating reward for descriptors: [1, 10, 12, 16, 17]
  Total reward: -4.4719, Per descriptor: -0.8944
Step 7: Currently selected descriptors: [1, 10, 12, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [1, 10, 12, 16, 17, 19]
  Calculating reward for descriptors: [1, 10, 12, 16, 17, 19]
  Total reward: -4.4429, Per descriptor: -0.7405
Step 8: Currently selected descriptors: [1, 10, 12, 16, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [1, 7, 10, 12, 16, 17, 19]
  Calculating reward for descriptors: [1, 7, 10, 12, 16, 17, 19]
  Total reward: -4.5178, Per descriptor: -0.6454
Step 9: Currently selected descriptors: [1, 7, 10, 12, 16, 17, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 7, 10, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 7, 10, 12, 16, 17, 19]
  Total reward: -4.5005, Per descriptor: -0.5626
Step 10: Currently selected descriptors: [0, 1, 7, 10, 12, 16, 17, 19]
  Action chosen: ADD descriptor 14
  New selection: [0, 1, 7, 10, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 7, 10, 12, 14, 16, 17, 19]
  Total reward: -4.4278, Per descriptor: -0.4920
Step 11: Currently selected descriptors: [0, 1, 7, 10, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 10, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 10, 12, 14, 16, 17, 19]
  Total reward: -4.3945, Per descriptor: -0.5493
Step 12: Currently selected descriptors: [0, 1, 10, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [0, 1, 10, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 10, 12, 14, 16, 19]
  Total reward: -4.3574, Per descriptor: -0.6225
Step 13: Currently selected descriptors: [0, 1, 10, 12, 14, 16, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 1, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 12, 14, 16, 19]
  Total reward: -4.3382, Per descriptor: -0.7230
Step 14: Currently selected descriptors: [0, 1, 12, 14, 16, 19]
  Action chosen: ADD descriptor 13
  New selection: [0, 1, 12, 13, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 12, 13, 14, 16, 19]
  Total reward: -4.3470, Per descriptor: -0.6210
Step 15: Currently selected descriptors: [0, 1, 12, 13, 14, 16, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 549 experiences...
  DQN training loss: 10607178.000000
Episode 26 Summary:
  Total reward: -60.0742
  Steps taken: 15
  Final descriptors: 7
  Epsilon: 0.878 (87.8% random, 12.2% DQN)
  Avg last 10 episodes: -71.4218
  Best so far: -7.0341 (3 descriptors)

--- Episode 27/50 ---
Episode 27 - Epsilon: 0.878 (87.8% random, 12.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 15
  New selection: [15]
  Calculating reward for descriptors: [15]
  Total reward: 1.5184, Per descriptor: 1.5184
Step 1: Currently selected descriptors: [15]
  Action chosen: ADD descriptor 9
  New selection: [9, 15]
  Calculating reward for descriptors: [9, 15]
  Total reward: -4.2767, Per descriptor: -2.1384
Step 2: Currently selected descriptors: [9, 15]
  Action chosen: ADD descriptor 11
  New selection: [9, 11, 15]
  Calculating reward for descriptors: [9, 11, 15]
  Total reward: -4.7875, Per descriptor: -1.5958
Step 3: Currently selected descriptors: [9, 11, 15]
  Action chosen: ADD descriptor 5
  New selection: [5, 9, 11, 15]
  Calculating reward for descriptors: [5, 9, 11, 15]
  Total reward: -4.4960, Per descriptor: -1.1240
Step 4: Currently selected descriptors: [5, 9, 11, 15]
  Action chosen: REMOVE descriptor 5
  New selection: [9, 11, 15]
  Calculating reward for descriptors: [9, 11, 15]
  Total reward: -4.7875, Per descriptor: -1.5958
Step 5: Currently selected descriptors: [9, 11, 15]
  Action chosen: ADD descriptor 4
  New selection: [4, 9, 11, 15]
  Calculating reward for descriptors: [4, 9, 11, 15]
  Total reward: -4.5032, Per descriptor: -1.1258
Step 6: Currently selected descriptors: [4, 9, 11, 15]
  Action chosen: ADD descriptor 3
  New selection: [3, 4, 9, 11, 15]
  Calculating reward for descriptors: [3, 4, 9, 11, 15]
  Total reward: -4.4157, Per descriptor: -0.8831
Step 7: Currently selected descriptors: [3, 4, 9, 11, 15]
  Action chosen: ADD descriptor 19
  New selection: [3, 4, 9, 11, 15, 19]
  Calculating reward for descriptors: [3, 4, 9, 11, 15, 19]
  Total reward: -4.3737, Per descriptor: -0.7290
Step 8: Currently selected descriptors: [3, 4, 9, 11, 15, 19]
  Action chosen: ADD descriptor 12
  New selection: [3, 4, 9, 11, 12, 15, 19]
  Calculating reward for descriptors: [3, 4, 9, 11, 12, 15, 19]
  Total reward: -4.5044, Per descriptor: -0.6435
Step 9: Currently selected descriptors: [3, 4, 9, 11, 12, 15, 19]
  Action chosen: ADD descriptor 16
  New selection: [3, 4, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [3, 4, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5591, Per descriptor: -0.5699
Step 10: Currently selected descriptors: [3, 4, 9, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [4, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [4, 9, 11, 12, 15, 16, 19]
  Total reward: -4.6520, Per descriptor: -0.6646
Step 11: Currently selected descriptors: [4, 9, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [4, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [4, 11, 12, 15, 16, 19]
  Total reward: -4.8137, Per descriptor: -0.8023
Step 12: Currently selected descriptors: [4, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 13
  New selection: [4, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [4, 11, 12, 13, 15, 16, 19]
  Total reward: -4.6734, Per descriptor: -0.6676
Step 13: Currently selected descriptors: [4, 11, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 5
  New selection: [4, 5, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [4, 5, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5697, Per descriptor: -0.5712
Step 14: Currently selected descriptors: [4, 5, 11, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5349, Per descriptor: -0.5039
Step 15: Currently selected descriptors: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [4, 5, 9, 11, 13, 15, 16, 19]
  Calculating reward for descriptors: [4, 5, 9, 11, 13, 15, 16, 19]
  Total reward: -4.4547, Per descriptor: -0.5568
Step 16: Currently selected descriptors: [4, 5, 9, 11, 13, 15, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5349, Per descriptor: -0.5039
Step 17: Currently selected descriptors: [4, 5, 9, 11, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [4, 5, 9, 11, 12, 13, 16, 19]
  Calculating reward for descriptors: [4, 5, 9, 11, 12, 13, 16, 19]
  Total reward: -4.4499, Per descriptor: -0.5562
Step 18: Currently selected descriptors: [4, 5, 9, 11, 12, 13, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 5, 9, 11, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 4, 5, 9, 11, 12, 13, 16, 19]
  Total reward: -4.4382, Per descriptor: -0.4931
Step 19: Currently selected descriptors: [0, 4, 5, 9, 11, 12, 13, 16, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 4, 5, 9, 11, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [0, 4, 5, 9, 11, 12, 13, 16, 17, 19]
  Total reward: -4.4372, Per descriptor: -0.4437
Step 20: Currently selected descriptors: [0, 4, 5, 9, 11, 12, 13, 16, 17, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [0, 4, 9, 11, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [0, 4, 9, 11, 12, 13, 16, 17, 19]
  Total reward: -4.4650, Per descriptor: -0.4961
Step 21: Currently selected descriptors: [0, 4, 9, 11, 12, 13, 16, 17, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 4, 6, 9, 11, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [0, 4, 6, 9, 11, 12, 13, 16, 17, 19]
  Total reward: -4.4602, Per descriptor: -0.4460
Step 22: Currently selected descriptors: [0, 4, 6, 9, 11, 12, 13, 16, 17, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [4, 6, 9, 11, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [4, 6, 9, 11, 12, 13, 16, 17, 19]
  Total reward: -4.4553, Per descriptor: -0.4950
Step 23: Currently selected descriptors: [4, 6, 9, 11, 12, 13, 16, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 572 experiences...
  DQN training loss: 8158641.000000
Episode 27 Summary:
  Total reward: -98.1242
  Steps taken: 23
  Final descriptors: 9
  Epsilon: 0.873 (87.3% random, 12.7% DQN)
  Avg last 10 episodes: -77.3772
  Best so far: -7.0341 (3 descriptors)

--- Episode 28/50 ---
Episode 28 - Epsilon: 0.873 (87.3% random, 12.7% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 12
  New selection: [12]
  Calculating reward for descriptors: [12]
  Total reward: 1.5090, Per descriptor: 1.5090
Step 1: Currently selected descriptors: [12]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 573 experiences...
  DQN training loss: 4043495.500000
  NEW BEST! Reward: 1.5090 with 1 descriptors
Episode 28 Summary:
  Total reward: 1.5090
  Steps taken: 1
  Final descriptors: 1
  Epsilon: 0.869 (86.9% random, 13.1% DQN)
  Avg last 10 episodes: -76.4087
  Best so far: 1.5090 (1 descriptors)

--- Episode 29/50 ---
Episode 29 - Epsilon: 0.869 (86.9% random, 13.1% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 12
  New selection: [12]
  Calculating reward for descriptors: [12]
  Total reward: 1.5090, Per descriptor: 1.5090
Step 1: Currently selected descriptors: [12]
  Action chosen: ADD descriptor 14
  New selection: [12, 14]
  Calculating reward for descriptors: [12, 14]
  Total reward: -4.1198, Per descriptor: -2.0599
Step 2: Currently selected descriptors: [12, 14]
  Action chosen: ADD descriptor 19
  New selection: [12, 14, 19]
  Calculating reward for descriptors: [12, 14, 19]
  Total reward: -4.1236, Per descriptor: -1.3745
Step 3: Currently selected descriptors: [12, 14, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 12, 14, 19]
  Calculating reward for descriptors: [1, 12, 14, 19]
  Total reward: -4.2359, Per descriptor: -1.0590
Step 4: Currently selected descriptors: [1, 12, 14, 19]
  Action chosen: ADD descriptor 16
  New selection: [1, 12, 14, 16, 19]
  Calculating reward for descriptors: [1, 12, 14, 16, 19]
  Total reward: -4.3211, Per descriptor: -0.8642
Step 5: Currently selected descriptors: [1, 12, 14, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [1, 9, 12, 14, 16, 19]
  Calculating reward for descriptors: [1, 9, 12, 14, 16, 19]
  Total reward: -4.3061, Per descriptor: -0.7177
Step 6: Currently selected descriptors: [1, 9, 12, 14, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 9, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 9, 12, 14, 16, 19]
  Total reward: -4.3382, Per descriptor: -0.6197
Step 7: Currently selected descriptors: [0, 1, 9, 12, 14, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 7, 9, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 14, 16, 19]
  Total reward: -4.4076, Per descriptor: -0.5509
Step 8: Currently selected descriptors: [0, 1, 7, 9, 12, 14, 16, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 7, 9, 12, 14, 16]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 14, 16]
  Total reward: -4.4559, Per descriptor: -0.6366
Step 9: Currently selected descriptors: [0, 1, 7, 9, 12, 14, 16]
  Action chosen: ADD descriptor 6
  New selection: [0, 1, 6, 7, 9, 12, 14, 16]
  Calculating reward for descriptors: [0, 1, 6, 7, 9, 12, 14, 16]
  Total reward: -4.4423, Per descriptor: -0.5553
Step 10: Currently selected descriptors: [0, 1, 6, 7, 9, 12, 14, 16]
  Action chosen: REMOVE descriptor 14
  New selection: [0, 1, 6, 7, 9, 12, 16]
  Calculating reward for descriptors: [0, 1, 6, 7, 9, 12, 16]
  Total reward: -4.5349, Per descriptor: -0.6478
Step 11: Currently selected descriptors: [0, 1, 6, 7, 9, 12, 16]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 6, 9, 12, 16]
  Calculating reward for descriptors: [0, 1, 6, 9, 12, 16]
  Total reward: -4.4602, Per descriptor: -0.7434
Step 12: Currently selected descriptors: [0, 1, 6, 9, 12, 16]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 6, 9, 12, 16]
  Calculating reward for descriptors: [0, 1, 2, 6, 9, 12, 16]
  Total reward: -4.4997, Per descriptor: -0.6428
Step 13: Currently selected descriptors: [0, 1, 2, 6, 9, 12, 16]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 586 experiences...
  DQN training loss: 9614904.000000
Episode 29 Summary:
  Total reward: -50.7362
  Steps taken: 13
  Final descriptors: 7
  Epsilon: 0.865 (86.5% random, 13.5% DQN)
  Avg last 10 episodes: -80.3236
  Best so far: 1.5090 (1 descriptors)

--- Episode 30/50 ---
Episode 30 - Epsilon: 0.865 (86.5% random, 13.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 5
  New selection: [5]
  Calculating reward for descriptors: [5]
  Total reward: 1.4590, Per descriptor: 1.4590
Step 1: Currently selected descriptors: [5]
  Action chosen: ADD descriptor 8
  New selection: [5, 8]
  Calculating reward for descriptors: [5, 8]
  Total reward: -4.3302, Per descriptor: -2.1651
Step 2: Currently selected descriptors: [5, 8]
  Action chosen: ADD descriptor 14
  New selection: [5, 8, 14]
  Calculating reward for descriptors: [5, 8, 14]
  Total reward: -4.2402, Per descriptor: -1.4134
Step 3: Currently selected descriptors: [5, 8, 14]
  Action chosen: ADD descriptor 16
  New selection: [5, 8, 14, 16]
  Calculating reward for descriptors: [5, 8, 14, 16]
  Total reward: -4.1757, Per descriptor: -1.0439
Step 4: Currently selected descriptors: [5, 8, 14, 16]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 590 experiences...
  DQN training loss: 8485402.000000
Episode 30 Summary:
  Total reward: -11.2872
  Steps taken: 4
  Final descriptors: 4
  Epsilon: 0.860 (86.0% random, 14.0% DQN)
  Avg last 10 episodes: -76.7111
  Best so far: 1.5090 (1 descriptors)

--- Episode 31/50 ---
Episode 31 - Epsilon: 0.860 (86.0% random, 14.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 4
  New selection: [4]
  Calculating reward for descriptors: [4]
  Total reward: 1.4239, Per descriptor: 1.4239
Step 1: Currently selected descriptors: [4]
  Action chosen: ADD descriptor 12
  New selection: [4, 12]
  Calculating reward for descriptors: [4, 12]
  Total reward: -4.1546, Per descriptor: -2.0773
Step 2: Currently selected descriptors: [4, 12]
  Action chosen: ADD descriptor 6
  New selection: [4, 6, 12]
  Calculating reward for descriptors: [4, 6, 12]
  Total reward: -4.3410, Per descriptor: -1.4470
Step 3: Currently selected descriptors: [4, 6, 12]
  Action chosen: ADD descriptor 5
  New selection: [4, 5, 6, 12]
  Calculating reward for descriptors: [4, 5, 6, 12]
  Total reward: -4.4144, Per descriptor: -1.1036
Step 4: Currently selected descriptors: [4, 5, 6, 12]
  Action chosen: REMOVE descriptor 5
  New selection: [4, 6, 12]
  Calculating reward for descriptors: [4, 6, 12]
  Total reward: -4.3410, Per descriptor: -1.4470
Step 5: Currently selected descriptors: [4, 6, 12]
  Action chosen: ADD descriptor 15
  New selection: [4, 6, 12, 15]
  Calculating reward for descriptors: [4, 6, 12, 15]
  Total reward: -4.5789, Per descriptor: -1.1447
Step 6: Currently selected descriptors: [4, 6, 12, 15]
  Action chosen: ADD descriptor 16
  New selection: [4, 6, 12, 15, 16]
  Calculating reward for descriptors: [4, 6, 12, 15, 16]
  Total reward: -4.6964, Per descriptor: -0.9393
Step 7: Currently selected descriptors: [4, 6, 12, 15, 16]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 6, 12, 15, 16]
  Calculating reward for descriptors: [0, 4, 6, 12, 15, 16]
  Total reward: -4.5806, Per descriptor: -0.7634
Step 8: Currently selected descriptors: [0, 4, 6, 12, 15, 16]
  Action chosen: ADD descriptor 19
  New selection: [0, 4, 6, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 12, 15, 16, 19]
  Total reward: -4.4998, Per descriptor: -0.6428
Step 9: Currently selected descriptors: [0, 4, 6, 12, 15, 16, 19]
  Action chosen: ADD descriptor 14
  New selection: [0, 4, 6, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 12, 14, 15, 16, 19]
  Total reward: -4.4118, Per descriptor: -0.5515
Step 10: Currently selected descriptors: [0, 4, 6, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 4, 6, 7, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 7, 12, 14, 15, 16, 19]
  Total reward: -4.4896, Per descriptor: -0.4988
Step 11: Currently selected descriptors: [0, 4, 6, 7, 12, 14, 15, 16, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 4, 6, 7, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 7, 12, 14, 16, 19]
  Total reward: -4.3951, Per descriptor: -0.5494
Step 12: Currently selected descriptors: [0, 4, 6, 7, 12, 14, 16, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 4, 6, 7, 12, 14, 16]
  Calculating reward for descriptors: [0, 4, 6, 7, 12, 14, 16]
  Total reward: -4.4331, Per descriptor: -0.6333
Step 13: Currently selected descriptors: [0, 4, 6, 7, 12, 14, 16]
  Action chosen: ADD descriptor 19
  New selection: [0, 4, 6, 7, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 7, 12, 14, 16, 19]
  Total reward: -4.3951, Per descriptor: -0.5494
Step 14: Currently selected descriptors: [0, 4, 6, 7, 12, 14, 16, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 4, 7, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 4, 7, 12, 14, 16, 19]
  Total reward: -4.4045, Per descriptor: -0.6292
Step 15: Currently selected descriptors: [0, 4, 7, 12, 14, 16, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 4, 7, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 7, 12, 14, 15, 16, 19]
  Total reward: -4.5323, Per descriptor: -0.5665
Step 16: Currently selected descriptors: [0, 4, 7, 12, 14, 15, 16, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 4, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 12, 14, 15, 16, 19]
  Total reward: -4.4280, Per descriptor: -0.6326
Step 17: Currently selected descriptors: [0, 4, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 4, 10, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 10, 12, 14, 15, 16, 19]
  Total reward: -4.4057, Per descriptor: -0.5507
Step 18: Currently selected descriptors: [0, 4, 10, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 4, 10, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 10, 12, 14, 15, 16, 19]
  Total reward: -4.4135, Per descriptor: -0.4904
Step 19: Currently selected descriptors: [0, 1, 4, 10, 12, 14, 15, 16, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 609 experiences...
  DQN training loss: 6750717.000000
  Updated target network weights
Episode 31 Summary:
  Total reward: -78.4915
  Steps taken: 19
  Final descriptors: 9
  Epsilon: 0.856 (85.6% random, 14.4% DQN)
  Avg last 10 episodes: -55.7842
  Best so far: 1.5090 (1 descriptors)

--- Episode 32/50 ---
Episode 32 - Epsilon: 0.856 (85.6% random, 14.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 15
  New selection: [15]
  Calculating reward for descriptors: [15]
  Total reward: 1.5184, Per descriptor: 1.5184
Step 1: Currently selected descriptors: [15]
  Action chosen: ADD descriptor 19
  New selection: [15, 19]
  Calculating reward for descriptors: [15, 19]
  Total reward: -4.1223, Per descriptor: -2.0612
Step 2: Currently selected descriptors: [15, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 15, 19]
  Calculating reward for descriptors: [1, 15, 19]
  Total reward: -4.2890, Per descriptor: -1.4297
Step 3: Currently selected descriptors: [1, 15, 19]
  Action chosen: ADD descriptor 10
  New selection: [1, 10, 15, 19]
  Calculating reward for descriptors: [1, 10, 15, 19]
  Total reward: -4.3502, Per descriptor: -1.0876
Step 4: Currently selected descriptors: [1, 10, 15, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 10, 15, 19]
  Calculating reward for descriptors: [0, 1, 10, 15, 19]
  Total reward: -4.4414, Per descriptor: -0.8883
Step 5: Currently selected descriptors: [0, 1, 10, 15, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 1, 8, 10, 15, 19]
  Calculating reward for descriptors: [0, 1, 8, 10, 15, 19]
  Total reward: -4.4238, Per descriptor: -0.7373
Step 6: Currently selected descriptors: [0, 1, 8, 10, 15, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 8, 10, 15, 19]
  Calculating reward for descriptors: [0, 8, 10, 15, 19]
  Total reward: -4.3862, Per descriptor: -0.8772
Step 7: Currently selected descriptors: [0, 8, 10, 15, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 8, 10, 12, 15, 19]
  Calculating reward for descriptors: [0, 8, 10, 12, 15, 19]
  Total reward: -4.4361, Per descriptor: -0.7393
Step 8: Currently selected descriptors: [0, 8, 10, 12, 15, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 8, 10, 12, 15, 17, 19]
  Calculating reward for descriptors: [0, 8, 10, 12, 15, 17, 19]
  Total reward: -4.4462, Per descriptor: -0.6352
Step 9: Currently selected descriptors: [0, 8, 10, 12, 15, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 8, 10, 12, 15, 17]
  Calculating reward for descriptors: [0, 8, 10, 12, 15, 17]
  Total reward: -4.4904, Per descriptor: -0.7484
Step 10: Currently selected descriptors: [0, 8, 10, 12, 15, 17]
  Action chosen: ADD descriptor 16
  New selection: [0, 8, 10, 12, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 12, 15, 16, 17]
  Total reward: -4.5381, Per descriptor: -0.6483
Step 11: Currently selected descriptors: [0, 8, 10, 12, 15, 16, 17]
  Action chosen: ADD descriptor 14
  New selection: [0, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4433, Per descriptor: -0.5554
Step 12: Currently selected descriptors: [0, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 4
  New selection: [0, 4, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 4, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4113, Per descriptor: -0.4901
Step 13: Currently selected descriptors: [0, 4, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 4
  New selection: [0, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4433, Per descriptor: -0.5554
Step 14: Currently selected descriptors: [0, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 5
  New selection: [0, 5, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 5, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4041, Per descriptor: -0.4893
Step 15: Currently selected descriptors: [0, 5, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 7
  New selection: [0, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4624, Per descriptor: -0.4462
Step 16: Currently selected descriptors: [0, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: ADD descriptor 2
  New selection: [0, 2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [0, 2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4669, Per descriptor: -0.4061
Step 17: Currently selected descriptors: [0, 2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Calculating reward for descriptors: [2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Total reward: -4.4679, Per descriptor: -0.4468
Step 18: Currently selected descriptors: [2, 5, 7, 8, 10, 12, 14, 15, 16, 17]
  Action chosen: REMOVE descriptor 12
  New selection: [2, 5, 7, 8, 10, 14, 15, 16, 17]
  Calculating reward for descriptors: [2, 5, 7, 8, 10, 14, 15, 16, 17]
  Total reward: -4.4013, Per descriptor: -0.4890
Step 19: Currently selected descriptors: [2, 5, 7, 8, 10, 14, 15, 16, 17]
  Action chosen: ADD descriptor 3
  New selection: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17]
  Calculating reward for descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17]
  Total reward: -4.3938, Per descriptor: -0.4394
Step 20: Currently selected descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17, 19]
  Total reward: -4.3807, Per descriptor: -0.3982
Step 21: Currently selected descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [2, 3, 5, 7, 8, 10, 14, 15, 17, 19]
  Calculating reward for descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 17, 19]
  Total reward: -4.3702, Per descriptor: -0.4370
Step 22: Currently selected descriptors: [2, 3, 5, 7, 8, 10, 14, 15, 17, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [3, 5, 7, 8, 10, 14, 15, 17, 19]
  Calculating reward for descriptors: [3, 5, 7, 8, 10, 14, 15, 17, 19]
  Total reward: -4.3257, Per descriptor: -0.4806
Step 23: Currently selected descriptors: [3, 5, 7, 8, 10, 14, 15, 17, 19]
  Action chosen: ADD descriptor 13
  New selection: [3, 5, 7, 8, 10, 13, 14, 15, 17, 19]
  Calculating reward for descriptors: [3, 5, 7, 8, 10, 13, 14, 15, 17, 19]
  Total reward: -4.3548, Per descriptor: -0.4355
Step 24: Currently selected descriptors: [3, 5, 7, 8, 10, 13, 14, 15, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Total reward: -4.3716, Per descriptor: -0.3974
Step 25: Currently selected descriptors: [3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Total reward: -4.3894, Per descriptor: -0.3658
Step 26: Currently selected descriptors: [1, 3, 5, 7, 8, 10, 13, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Total reward: -4.3734, Per descriptor: -0.3976
Step 27: Currently selected descriptors: [1, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Total reward: -4.4083, Per descriptor: -0.3674
Step 28: Currently selected descriptors: [1, 2, 3, 5, 7, 8, 10, 13, 14, 16, 17, 19]
  Action chosen: ADD descriptor 6
  New selection: [1, 2, 3, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Total reward: -4.4263, Per descriptor: -0.3405
Step 29: Currently selected descriptors: [1, 2, 3, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Action chosen: ADD descriptor 4
  New selection: [1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Total reward: -4.4227, Per descriptor: -0.3159
Step 30: Currently selected descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 16, 17, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 16, 17, 19]
  Total reward: -4.4173, Per descriptor: -0.2945
  Reached maximum descriptors limit
  Training DQN with 640 experiences...
  DQN training loss: 8468096.000000
Episode 32 Summary:
  Total reward: -130.5402
  Steps taken: 31
  Final descriptors: 15
  Epsilon: 0.852 (85.2% random, 14.8% DQN)
  Avg last 10 episodes: -68.1348
  Best so far: 1.5090 (1 descriptors)

--- Episode 33/50 ---
Episode 33 - Epsilon: 0.852 (85.2% random, 14.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 7
  New selection: [7]
  Calculating reward for descriptors: [7]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [7]
  Action chosen: ADD descriptor 10
  New selection: [7, 10]
  Calculating reward for descriptors: [7, 10]
  Total reward: -4.1232, Per descriptor: -2.0616
Step 2: Currently selected descriptors: [7, 10]
  Action chosen: ADD descriptor 2
  New selection: [2, 7, 10]
  Calculating reward for descriptors: [2, 7, 10]
  Total reward: -4.3462, Per descriptor: -1.4487
Step 3: Currently selected descriptors: [2, 7, 10]
  Action chosen: ADD descriptor 19
  New selection: [2, 7, 10, 19]
  Calculating reward for descriptors: [2, 7, 10, 19]
  Total reward: -4.3925, Per descriptor: -1.0981
Step 4: Currently selected descriptors: [2, 7, 10, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 7, 10, 19]
  Calculating reward for descriptors: [0, 2, 7, 10, 19]
  Total reward: -4.4867, Per descriptor: -0.8973
Step 5: Currently selected descriptors: [0, 2, 7, 10, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 2, 7, 10, 18, 19]
  Calculating reward for descriptors: [0, 2, 7, 10, 18, 19]
  Total reward: -4.4991, Per descriptor: -0.7498
Step 6: Currently selected descriptors: [0, 2, 7, 10, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 2, 7, 10, 15, 18, 19]
  Calculating reward for descriptors: [0, 2, 7, 10, 15, 18, 19]
  Total reward: -4.4791, Per descriptor: -0.6399
Step 7: Currently selected descriptors: [0, 2, 7, 10, 15, 18, 19]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 2, 7, 10, 15, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 7, 10, 15, 18, 19]
  Total reward: -4.5040, Per descriptor: -0.5630
Step 8: Currently selected descriptors: [0, 1, 2, 7, 10, 15, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 2, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 7, 10, 15, 16, 18, 19]
  Total reward: -4.5099, Per descriptor: -0.5011
Step 9: Currently selected descriptors: [0, 1, 2, 7, 10, 15, 16, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 1, 2, 6, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 10, 15, 16, 18, 19]
  Total reward: -4.5197, Per descriptor: -0.4520
Step 10: Currently selected descriptors: [0, 1, 2, 6, 7, 10, 15, 16, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Total reward: -4.5989, Per descriptor: -0.4181
Step 11: Currently selected descriptors: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 1, 2, 6, 7, 10, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 10, 11, 12, 15, 16, 18, 19]
  Total reward: -4.6357, Per descriptor: -0.3863
Step 12: Currently selected descriptors: [0, 1, 2, 6, 7, 10, 11, 12, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Total reward: -4.5989, Per descriptor: -0.4181
Step 13: Currently selected descriptors: [0, 1, 2, 6, 7, 10, 11, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Total reward: -4.6347, Per descriptor: -0.4635
Step 14: Currently selected descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 2, 6, 7, 11, 15, 16, 18]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18]
  Total reward: -4.7078, Per descriptor: -0.5231
Step 15: Currently selected descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Total reward: -4.6347, Per descriptor: -0.4635
Step 16: Currently selected descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [0, 1, 6, 7, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 6, 7, 11, 15, 16, 18, 19]
  Total reward: -4.6585, Per descriptor: -0.5176
Step 17: Currently selected descriptors: [0, 1, 6, 7, 11, 15, 16, 18, 19]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Total reward: -4.6347, Per descriptor: -0.4635
Step 18: Currently selected descriptors: [0, 1, 2, 6, 7, 11, 15, 16, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 2, 5, 6, 7, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 6, 7, 11, 15, 16, 18, 19]
  Total reward: -4.5946, Per descriptor: -0.4177
Step 19: Currently selected descriptors: [0, 1, 2, 5, 6, 7, 11, 15, 16, 18, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 1, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Total reward: -4.5688, Per descriptor: -0.3807
Step 20: Currently selected descriptors: [0, 1, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Total reward: -4.5742, Per descriptor: -0.4158
Step 21: Currently selected descriptors: [0, 2, 5, 6, 7, 10, 11, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [0, 2, 5, 6, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 5, 6, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4913, Per descriptor: -0.4491
Step 22: Currently selected descriptors: [0, 2, 5, 6, 7, 10, 15, 16, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 2, 4, 5, 6, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 6, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4818, Per descriptor: -0.4074
Step 23: Currently selected descriptors: [0, 2, 4, 5, 6, 7, 10, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4666, Per descriptor: -0.4467
Step 24: Currently selected descriptors: [0, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [2, 4, 5, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [2, 4, 5, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4562, Per descriptor: -0.4951
Step 25: Currently selected descriptors: [2, 4, 5, 7, 10, 15, 16, 18, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4832, Per descriptor: -0.4483
Step 26: Currently selected descriptors: [1, 2, 4, 5, 7, 10, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [1, 4, 5, 7, 10, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 10, 15, 16, 18, 19]
  Total reward: -4.4671, Per descriptor: -0.4963
Step 27: Currently selected descriptors: [1, 4, 5, 7, 10, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 4, 5, 7, 10, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 5, 7, 10, 15, 16, 19]
  Total reward: -4.4465, Per descriptor: -0.5558
Step 28: Currently selected descriptors: [1, 4, 5, 7, 10, 15, 16, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 4, 7, 10, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 7, 10, 15, 16, 19]
  Total reward: -4.4863, Per descriptor: -0.6409
Step 29: Currently selected descriptors: [1, 4, 7, 10, 15, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 4, 7, 10, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 7, 10, 12, 15, 16, 19]
  Total reward: -4.5896, Per descriptor: -0.5737
Step 30: Currently selected descriptors: [1, 4, 7, 10, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [1, 7, 10, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 7, 10, 12, 15, 16, 19]
  Total reward: -4.6816, Per descriptor: -0.6688
Step 31: Currently selected descriptors: [1, 7, 10, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 10, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 10, 12, 15, 16, 19]
  Total reward: -4.5594, Per descriptor: -0.7599
Step 32: Currently selected descriptors: [1, 10, 12, 15, 16, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 10, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 3, 10, 12, 15, 16, 19]
  Total reward: -4.5062, Per descriptor: -0.6437
Step 33: Currently selected descriptors: [1, 3, 10, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 10, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 10, 12, 15, 16, 19]
  Total reward: -4.5594, Per descriptor: -0.7599
Step 34: Currently selected descriptors: [1, 10, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [10, 12, 15, 16, 19]
  Calculating reward for descriptors: [10, 12, 15, 16, 19]
  Total reward: -4.6579, Per descriptor: -0.9316
Step 35: Currently selected descriptors: [10, 12, 15, 16, 19]
  Action chosen: ADD descriptor 13
  New selection: [10, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [10, 12, 13, 15, 16, 19]
  Total reward: -4.5594, Per descriptor: -0.7599
Step 36: Currently selected descriptors: [10, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 5
  New selection: [5, 10, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [5, 10, 12, 13, 15, 16, 19]
  Total reward: -4.4684, Per descriptor: -0.6383
Step 37: Currently selected descriptors: [5, 10, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [5, 10, 12, 13, 16, 19]
  Calculating reward for descriptors: [5, 10, 12, 13, 16, 19]
  Total reward: -4.3418, Per descriptor: -0.7236
Step 38: Currently selected descriptors: [5, 10, 12, 13, 16, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 678 experiences...
  DQN training loss: 8376598.500000
Episode 33 Summary:
  Total reward: -165.9004
  Steps taken: 38
  Final descriptors: 6
  Epsilon: 0.848 (84.8% random, 15.2% DQN)
  Avg last 10 episodes: -75.4979
  Best so far: 1.5090 (1 descriptors)

--- Episode 34/50 ---
Episode 34 - Epsilon: 0.848 (84.8% random, 15.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 1
  New selection: [1]
  Calculating reward for descriptors: [1]
  Total reward: 1.4807, Per descriptor: 1.4807
Step 1: Currently selected descriptors: [1]
  Action chosen: ADD descriptor 17
  New selection: [1, 17]
  Calculating reward for descriptors: [1, 17]
  Total reward: -4.8124, Per descriptor: -2.4062
Step 2: Currently selected descriptors: [1, 17]
  Action chosen: ADD descriptor 14
  New selection: [1, 14, 17]
  Calculating reward for descriptors: [1, 14, 17]
  Total reward: -4.4709, Per descriptor: -1.4903
Step 3: Currently selected descriptors: [1, 14, 17]
  Action chosen: ADD descriptor 12
  New selection: [1, 12, 14, 17]
  Calculating reward for descriptors: [1, 12, 14, 17]
  Total reward: -4.3055, Per descriptor: -1.0764
Step 4: Currently selected descriptors: [1, 12, 14, 17]
  Action chosen: REMOVE descriptor 17
  New selection: [1, 12, 14]
  Calculating reward for descriptors: [1, 12, 14]
  Total reward: -4.1988, Per descriptor: -1.3996
Step 5: Currently selected descriptors: [1, 12, 14]
  Action chosen: ADD descriptor 19
  New selection: [1, 12, 14, 19]
  Calculating reward for descriptors: [1, 12, 14, 19]
  Total reward: -4.2373, Per descriptor: -1.0593
Step 6: Currently selected descriptors: [1, 12, 14, 19]
  Action chosen: ADD descriptor 13
  New selection: [1, 12, 13, 14, 19]
  Calculating reward for descriptors: [1, 12, 13, 14, 19]
  Total reward: -4.2722, Per descriptor: -0.8544
Step 7: Currently selected descriptors: [1, 12, 13, 14, 19]
  Action chosen: ADD descriptor 18
  New selection: [1, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [1, 12, 13, 14, 18, 19]
  Total reward: -4.3300, Per descriptor: -0.7217
Step 8: Currently selected descriptors: [1, 12, 13, 14, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [1, 11, 12, 13, 14, 18, 19]
  Calculating reward for descriptors: [1, 11, 12, 13, 14, 18, 19]
  Total reward: -4.3909, Per descriptor: -0.6273
Step 9: Currently selected descriptors: [1, 11, 12, 13, 14, 18, 19]
  Action chosen: REMOVE descriptor 14
  New selection: [1, 11, 12, 13, 18, 19]
  Calculating reward for descriptors: [1, 11, 12, 13, 18, 19]
  Total reward: -4.4787, Per descriptor: -0.7464
Step 10: Currently selected descriptors: [1, 11, 12, 13, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [1, 11, 12, 13, 15, 18, 19]
  Calculating reward for descriptors: [1, 11, 12, 13, 15, 18, 19]
  Total reward: -4.5767, Per descriptor: -0.6538
Step 11: Currently selected descriptors: [1, 11, 12, 13, 15, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 11, 12, 13, 15, 18, 19]
  Calculating reward for descriptors: [0, 1, 11, 12, 13, 15, 18, 19]
  Total reward: -4.5333, Per descriptor: -0.5667
Step 12: Currently selected descriptors: [0, 1, 11, 12, 13, 15, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 1, 4, 11, 12, 13, 15, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 11, 12, 13, 15, 18, 19]
  Total reward: -4.5006, Per descriptor: -0.5001
Step 13: Currently selected descriptors: [0, 1, 4, 11, 12, 13, 15, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 4, 11, 12, 13, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 11, 12, 13, 15, 16, 18, 19]
  Total reward: -4.5274, Per descriptor: -0.4527
Step 14: Currently selected descriptors: [0, 1, 4, 11, 12, 13, 15, 16, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Total reward: -4.5000, Per descriptor: -0.4091
Step 15: Currently selected descriptors: [0, 1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Total reward: -4.5253, Per descriptor: -0.4525
Step 16: Currently selected descriptors: [1, 4, 5, 11, 12, 13, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 4, 5, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 5, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5388, Per descriptor: -0.5043
Step 17: Currently selected descriptors: [1, 4, 5, 11, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [1, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Total reward: -4.5205, Per descriptor: -0.4521
Step 18: Currently selected descriptors: [1, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Total reward: -4.4826, Per descriptor: -0.4075
Step 19: Currently selected descriptors: [1, 3, 4, 5, 9, 11, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [1, 3, 4, 5, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 3, 4, 5, 9, 11, 12, 15, 16, 19]
  Total reward: -4.4863, Per descriptor: -0.4486
Step 20: Currently selected descriptors: [1, 3, 4, 5, 9, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 4, 5, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 4, 5, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5258, Per descriptor: -0.5029
Step 21: Currently selected descriptors: [1, 4, 5, 9, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [1, 5, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 5, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5786, Per descriptor: -0.5723
Step 22: Currently selected descriptors: [1, 5, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 5, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [1, 3, 5, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5249, Per descriptor: -0.5028
Step 23: Currently selected descriptors: [1, 3, 5, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 14
  New selection: [1, 3, 5, 9, 11, 12, 14, 15, 16, 19]
  Calculating reward for descriptors: [1, 3, 5, 9, 11, 12, 14, 15, 16, 19]
  Total reward: -4.4482, Per descriptor: -0.4448
Step 24: Currently selected descriptors: [1, 3, 5, 9, 11, 12, 14, 15, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [1, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4437, Per descriptor: -0.4040
Step 25: Currently selected descriptors: [1, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4456, Per descriptor: -0.3705
Step 26: Currently selected descriptors: [1, 2, 3, 5, 9, 11, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [1, 2, 3, 5, 9, 11, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 5, 9, 11, 14, 15, 16, 18, 19]
  Total reward: -4.4126, Per descriptor: -0.4011
Step 27: Currently selected descriptors: [1, 2, 3, 5, 9, 11, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 2, 3, 9, 11, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 9, 11, 14, 15, 16, 18, 19]
  Total reward: -4.4211, Per descriptor: -0.4421
Step 28: Currently selected descriptors: [1, 2, 3, 9, 11, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 2, 9, 11, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 9, 11, 14, 15, 16, 18, 19]
  Total reward: -4.4296, Per descriptor: -0.4922
Step 29: Currently selected descriptors: [1, 2, 9, 11, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [1, 2, 6, 9, 11, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 9, 11, 14, 15, 16, 18, 19]
  Total reward: -4.4402, Per descriptor: -0.4440
Step 30: Currently selected descriptors: [1, 2, 6, 9, 11, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [1, 2, 6, 9, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 9, 14, 15, 16, 18, 19]
  Total reward: -4.4276, Per descriptor: -0.4920
Step 31: Currently selected descriptors: [1, 2, 6, 9, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 6, 9, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 9, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4471, Per descriptor: -0.4447
Step 32: Currently selected descriptors: [1, 2, 6, 9, 12, 14, 15, 16, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [1, 2, 5, 6, 9, 12, 14, 15, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 5, 6, 9, 12, 14, 15, 16, 18, 19]
  Total reward: -4.4410, Per descriptor: -0.4037
Step 33: Currently selected descriptors: [1, 2, 5, 6, 9, 12, 14, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4208, Per descriptor: -0.4421
Step 34: Currently selected descriptors: [1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4329, Per descriptor: -0.4030
Step 35: Currently selected descriptors: [1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4379, Per descriptor: -0.4438
Step 36: Currently selected descriptors: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 3
  New selection: [1, 2, 3, 6, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 3, 6, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4323, Per descriptor: -0.4029
Step 37: Currently selected descriptors: [1, 2, 3, 6, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4379, Per descriptor: -0.4438
Step 38: Currently selected descriptors: [1, 2, 6, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 2, 6, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 2, 6, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4137, Per descriptor: -0.4904
Step 39: Currently selected descriptors: [1, 2, 6, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [1, 6, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 6, 9, 12, 14, 16, 18, 19]
  Total reward: -4.3742, Per descriptor: -0.5468
Step 40: Currently selected descriptors: [1, 6, 9, 12, 14, 16, 18, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 718 experiences...
  DQN training loss: 6910424.500000
Episode 34 Summary:
  Total reward: -172.1431
  Steps taken: 40
  Final descriptors: 8
  Epsilon: 0.843 (84.3% random, 15.7% DQN)
  Avg last 10 episodes: -87.5430
  Best so far: 1.5090 (1 descriptors)

--- Episode 35/50 ---
Episode 35 - Epsilon: 0.843 (84.3% random, 15.7% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 2
  New selection: [2]
  Calculating reward for descriptors: [2]
  Total reward: 1.5826, Per descriptor: 1.5826
Step 1: Currently selected descriptors: [2]
  Action chosen: ADD descriptor 10
  New selection: [2, 10]
  Calculating reward for descriptors: [2, 10]
  Total reward: -4.7638, Per descriptor: -2.3819
Step 2: Currently selected descriptors: [2, 10]
  Action chosen: ADD descriptor 16
  New selection: [2, 10, 16]
  Calculating reward for descriptors: [2, 10, 16]
  Total reward: -4.3613, Per descriptor: -1.4538
Step 3: Currently selected descriptors: [2, 10, 16]
  Action chosen: REMOVE descriptor 16
  New selection: [2, 10]
  Calculating reward for descriptors: [2, 10]
  Total reward: -4.7638, Per descriptor: -2.3819
Step 4: Currently selected descriptors: [2, 10]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 10]
  Calculating reward for descriptors: [1, 2, 10]
  Total reward: -4.7897, Per descriptor: -1.5966
Step 5: Currently selected descriptors: [1, 2, 10]
  Action chosen: ADD descriptor 5
  New selection: [1, 2, 5, 10]
  Calculating reward for descriptors: [1, 2, 5, 10]
  Total reward: -4.6853, Per descriptor: -1.1713
Step 6: Currently selected descriptors: [1, 2, 5, 10]
  Action chosen: REMOVE descriptor 10
  New selection: [1, 2, 5]
  Calculating reward for descriptors: [1, 2, 5]
  Total reward: -4.7533, Per descriptor: -1.5844
Step 7: Currently selected descriptors: [1, 2, 5]
  Action chosen: ADD descriptor 8
  New selection: [1, 2, 5, 8]
  Calculating reward for descriptors: [1, 2, 5, 8]
  Total reward: -4.5770, Per descriptor: -1.1442
Step 8: Currently selected descriptors: [1, 2, 5, 8]
  Action chosen: ADD descriptor 6
  New selection: [1, 2, 5, 6, 8]
  Calculating reward for descriptors: [1, 2, 5, 6, 8]
  Total reward: -4.6265, Per descriptor: -0.9253
Step 9: Currently selected descriptors: [1, 2, 5, 6, 8]
  Action chosen: ADD descriptor 18
  New selection: [1, 2, 5, 6, 8, 18]
  Calculating reward for descriptors: [1, 2, 5, 6, 8, 18]
  Total reward: -4.6830, Per descriptor: -0.7805
Step 10: Currently selected descriptors: [1, 2, 5, 6, 8, 18]
  Action chosen: ADD descriptor 17
  New selection: [1, 2, 5, 6, 8, 17, 18]
  Calculating reward for descriptors: [1, 2, 5, 6, 8, 17, 18]
  Total reward: -4.6806, Per descriptor: -0.6687
Step 11: Currently selected descriptors: [1, 2, 5, 6, 8, 17, 18]
  Action chosen: ADD descriptor 7
  New selection: [1, 2, 5, 6, 7, 8, 17, 18]
  Calculating reward for descriptors: [1, 2, 5, 6, 7, 8, 17, 18]
  Total reward: -4.5489, Per descriptor: -0.5686
Step 12: Currently selected descriptors: [1, 2, 5, 6, 7, 8, 17, 18]
  Action chosen: ADD descriptor 16
  New selection: [1, 2, 5, 6, 7, 8, 16, 17, 18]
  Calculating reward for descriptors: [1, 2, 5, 6, 7, 8, 16, 17, 18]
  Total reward: -4.5040, Per descriptor: -0.5004
Step 13: Currently selected descriptors: [1, 2, 5, 6, 7, 8, 16, 17, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 731 experiences...
  DQN training loss: 11167427.000000
Episode 35 Summary:
  Total reward: -54.1545
  Steps taken: 13
  Final descriptors: 9
  Epsilon: 0.839 (83.9% random, 16.1% DQN)
  Avg last 10 episodes: -81.9942
  Best so far: 1.5090 (1 descriptors)

--- Episode 36/50 ---
Episode 36 - Epsilon: 0.839 (83.9% random, 16.1% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 17
  New selection: [17]
  Calculating reward for descriptors: [17]
  Total reward: 1.5946, Per descriptor: 1.5946
Step 1: Currently selected descriptors: [17]
  Action chosen: ADD descriptor 12
  New selection: [12, 17]
  Calculating reward for descriptors: [12, 17]
  Total reward: -4.1872, Per descriptor: -2.0936
Step 2: Currently selected descriptors: [12, 17]
  Action chosen: ADD descriptor 18
  New selection: [12, 17, 18]
  Calculating reward for descriptors: [12, 17, 18]
  Total reward: -4.3357, Per descriptor: -1.4452
Step 3: Currently selected descriptors: [12, 17, 18]
  Action chosen: ADD descriptor 7
  New selection: [7, 12, 17, 18]
  Calculating reward for descriptors: [7, 12, 17, 18]
  Total reward: -4.6069, Per descriptor: -1.1517
Step 4: Currently selected descriptors: [7, 12, 17, 18]
  Action chosen: ADD descriptor 9
  New selection: [7, 9, 12, 17, 18]
  Calculating reward for descriptors: [7, 9, 12, 17, 18]
  Total reward: -4.5051, Per descriptor: -0.9010
Step 5: Currently selected descriptors: [7, 9, 12, 17, 18]
  Action chosen: ADD descriptor 19
  New selection: [7, 9, 12, 17, 18, 19]
  Calculating reward for descriptors: [7, 9, 12, 17, 18, 19]
  Total reward: -4.4411, Per descriptor: -0.7402
Step 6: Currently selected descriptors: [7, 9, 12, 17, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [6, 7, 9, 12, 17, 18, 19]
  Calculating reward for descriptors: [6, 7, 9, 12, 17, 18, 19]
  Total reward: -4.4529, Per descriptor: -0.6361
Step 7: Currently selected descriptors: [6, 7, 9, 12, 17, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [6, 7, 8, 9, 12, 17, 18, 19]
  Calculating reward for descriptors: [6, 7, 8, 9, 12, 17, 18, 19]
  Total reward: -4.4437, Per descriptor: -0.5555
Step 8: Currently selected descriptors: [6, 7, 8, 9, 12, 17, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 6, 7, 8, 9, 12, 17, 18, 19]
  Calculating reward for descriptors: [4, 6, 7, 8, 9, 12, 17, 18, 19]
  Total reward: -4.4368, Per descriptor: -0.4930
Step 9: Currently selected descriptors: [4, 6, 7, 8, 9, 12, 17, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [4, 6, 7, 8, 9, 12, 17, 19]
  Calculating reward for descriptors: [4, 6, 7, 8, 9, 12, 17, 19]
  Total reward: -4.4171, Per descriptor: -0.5521
Step 10: Currently selected descriptors: [4, 6, 7, 8, 9, 12, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [4, 6, 7, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [4, 6, 7, 8, 9, 12, 16, 17, 19]
  Total reward: -4.4273, Per descriptor: -0.4919
Step 11: Currently selected descriptors: [4, 6, 7, 8, 9, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [4, 6, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [4, 6, 8, 9, 12, 16, 17, 19]
  Total reward: -4.3936, Per descriptor: -0.5492
Step 12: Currently selected descriptors: [4, 6, 8, 9, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [4, 8, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [4, 8, 9, 12, 16, 17, 19]
  Total reward: -4.3809, Per descriptor: -0.6258
Step 13: Currently selected descriptors: [4, 8, 9, 12, 16, 17, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [4, 8, 9, 12, 17, 19]
  Calculating reward for descriptors: [4, 8, 9, 12, 17, 19]
  Total reward: -4.3872, Per descriptor: -0.7312
Step 14: Currently selected descriptors: [4, 8, 9, 12, 17, 19]
  Action chosen: ADD descriptor 10
  New selection: [4, 8, 9, 10, 12, 17, 19]
  Calculating reward for descriptors: [4, 8, 9, 10, 12, 17, 19]
  Total reward: -4.4366, Per descriptor: -0.6338
Step 15: Currently selected descriptors: [4, 8, 9, 10, 12, 17, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [4, 8, 9, 12, 17, 19]
  Calculating reward for descriptors: [4, 8, 9, 12, 17, 19]
  Total reward: -4.3872, Per descriptor: -0.7312
Step 16: Currently selected descriptors: [4, 8, 9, 12, 17, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [8, 9, 12, 17, 19]
  Calculating reward for descriptors: [8, 9, 12, 17, 19]
  Total reward: -4.3931, Per descriptor: -0.8786
Step 17: Currently selected descriptors: [8, 9, 12, 17, 19]
  Action chosen: ADD descriptor 13
  New selection: [8, 9, 12, 13, 17, 19]
  Calculating reward for descriptors: [8, 9, 12, 13, 17, 19]
  Total reward: -4.5085, Per descriptor: -0.7514
Step 18: Currently selected descriptors: [8, 9, 12, 13, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 8, 9, 12, 13, 17, 19]
  Calculating reward for descriptors: [2, 8, 9, 12, 13, 17, 19]
  Total reward: -4.5299, Per descriptor: -0.6471
Step 19: Currently selected descriptors: [2, 8, 9, 12, 13, 17, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 8, 9, 12, 13, 17, 19]
  Calculating reward for descriptors: [1, 2, 8, 9, 12, 13, 17, 19]
  Total reward: -4.5424, Per descriptor: -0.5678
Step 20: Currently selected descriptors: [1, 2, 8, 9, 12, 13, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [1, 2, 8, 9, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 8, 9, 12, 13, 16, 17, 19]
  Total reward: -4.5060, Per descriptor: -0.5007
Step 21: Currently selected descriptors: [1, 2, 8, 9, 12, 13, 16, 17, 19]
  Action chosen: ADD descriptor 4
  New selection: [1, 2, 4, 8, 9, 12, 13, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 4, 8, 9, 12, 13, 16, 17, 19]
  Total reward: -4.4894, Per descriptor: -0.4489
Step 22: Currently selected descriptors: [1, 2, 4, 8, 9, 12, 13, 16, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 753 experiences...
  DQN training loss: 5191070.000000
Episode 36 Summary:
  Total reward: -91.6142
  Steps taken: 22
  Final descriptors: 10
  Epsilon: 0.835 (83.5% random, 16.5% DQN)
  Avg last 10 episodes: -85.1482
  Best so far: 1.5090 (1 descriptors)

--- Episode 37/50 ---
Episode 37 - Epsilon: 0.835 (83.5% random, 16.5% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 3
  New selection: [3]
  Calculating reward for descriptors: [3]
  Total reward: 1.5744, Per descriptor: 1.5744
Step 1: Currently selected descriptors: [3]
  Action chosen: ADD descriptor 2
  New selection: [2, 3]
  Calculating reward for descriptors: [2, 3]
  Total reward: -4.7713, Per descriptor: -2.3857
Step 2: Currently selected descriptors: [2, 3]
  Action chosen: ADD descriptor 5
  New selection: [2, 3, 5]
  Calculating reward for descriptors: [2, 3, 5]
  Total reward: -4.6062, Per descriptor: -1.5354
Step 3: Currently selected descriptors: [2, 3, 5]
  Action chosen: ADD descriptor 1
  New selection: [1, 2, 3, 5]
  Calculating reward for descriptors: [1, 2, 3, 5]
  Total reward: -4.6718, Per descriptor: -1.1680
Step 4: Currently selected descriptors: [1, 2, 3, 5]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 2, 5]
  Calculating reward for descriptors: [1, 2, 5]
  Total reward: -4.7533, Per descriptor: -1.5844
Step 5: Currently selected descriptors: [1, 2, 5]
  Action chosen: ADD descriptor 11
  New selection: [1, 2, 5, 11]
  Calculating reward for descriptors: [1, 2, 5, 11]
  Total reward: -4.4673, Per descriptor: -1.1168
Step 6: Currently selected descriptors: [1, 2, 5, 11]
  Action chosen: REMOVE descriptor 5
  New selection: [1, 2, 11]
  Calculating reward for descriptors: [1, 2, 11]
  Total reward: -4.4555, Per descriptor: -1.4852
Step 7: Currently selected descriptors: [1, 2, 11]
  Action chosen: ADD descriptor 3
  New selection: [1, 2, 3, 11]
  Calculating reward for descriptors: [1, 2, 3, 11]
  Total reward: -4.4806, Per descriptor: -1.1201
Step 8: Currently selected descriptors: [1, 2, 3, 11]
  Action chosen: REMOVE descriptor 2
  New selection: [1, 3, 11]
  Calculating reward for descriptors: [1, 3, 11]
  Total reward: -4.3301, Per descriptor: -1.4434
Step 9: Currently selected descriptors: [1, 3, 11]
  Action chosen: ADD descriptor 8
  New selection: [1, 3, 8, 11]
  Calculating reward for descriptors: [1, 3, 8, 11]
  Total reward: -4.3076, Per descriptor: -1.0769
Step 10: Currently selected descriptors: [1, 3, 8, 11]
  Action chosen: ADD descriptor 5
  New selection: [1, 3, 5, 8, 11]
  Calculating reward for descriptors: [1, 3, 5, 8, 11]
  Total reward: -4.3317, Per descriptor: -0.8663
Step 11: Currently selected descriptors: [1, 3, 5, 8, 11]
  Action chosen: ADD descriptor 14
  New selection: [1, 3, 5, 8, 11, 14]
  Calculating reward for descriptors: [1, 3, 5, 8, 11, 14]
  Total reward: -4.2775, Per descriptor: -0.7129
Step 12: Currently selected descriptors: [1, 3, 5, 8, 11, 14]
  Action chosen: REMOVE descriptor 1
  New selection: [3, 5, 8, 11, 14]
  Calculating reward for descriptors: [3, 5, 8, 11, 14]
  Total reward: -4.2089, Per descriptor: -0.8418
Step 13: Currently selected descriptors: [3, 5, 8, 11, 14]
  Action chosen: ADD descriptor 2
  New selection: [2, 3, 5, 8, 11, 14]
  Calculating reward for descriptors: [2, 3, 5, 8, 11, 14]
  Total reward: -4.2818, Per descriptor: -0.7136
Step 14: Currently selected descriptors: [2, 3, 5, 8, 11, 14]
  Action chosen: REMOVE descriptor 3
  New selection: [2, 5, 8, 11, 14]
  Calculating reward for descriptors: [2, 5, 8, 11, 14]
  Total reward: -4.2496, Per descriptor: -0.8499
Step 15: Currently selected descriptors: [2, 5, 8, 11, 14]
  Action chosen: ADD descriptor 16
  New selection: [2, 5, 8, 11, 14, 16]
  Calculating reward for descriptors: [2, 5, 8, 11, 14, 16]
  Total reward: -4.2923, Per descriptor: -0.7154
Step 16: Currently selected descriptors: [2, 5, 8, 11, 14, 16]
  Action chosen: ADD descriptor 9
  New selection: [2, 5, 8, 9, 11, 14, 16]
  Calculating reward for descriptors: [2, 5, 8, 9, 11, 14, 16]
  Total reward: -4.3437, Per descriptor: -0.6205
Step 17: Currently selected descriptors: [2, 5, 8, 9, 11, 14, 16]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 770 experiences...
  DQN training loss: 7004067.000000
Episode 37 Summary:
  Total reward: -69.2547
  Steps taken: 17
  Final descriptors: 7
  Epsilon: 0.831 (83.1% random, 16.9% DQN)
  Avg last 10 episodes: -82.2613
  Best so far: 1.5090 (1 descriptors)

--- Episode 38/50 ---
Episode 38 - Epsilon: 0.831 (83.1% random, 16.9% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 14
  New selection: [14]
  Calculating reward for descriptors: [14]
  Total reward: 1.4364, Per descriptor: 1.4364
Step 1: Currently selected descriptors: [14]
  Action chosen: ADD descriptor 15
  New selection: [14, 15]
  Calculating reward for descriptors: [14, 15]
  Total reward: -4.1182, Per descriptor: -2.0591
Step 2: Currently selected descriptors: [14, 15]
  Action chosen: ADD descriptor 6
  New selection: [6, 14, 15]
  Calculating reward for descriptors: [6, 14, 15]
  Total reward: -4.1784, Per descriptor: -1.3928
Step 3: Currently selected descriptors: [6, 14, 15]
  Action chosen: ADD descriptor 3
  New selection: [3, 6, 14, 15]
  Calculating reward for descriptors: [3, 6, 14, 15]
  Total reward: -4.2336, Per descriptor: -1.0584
Step 4: Currently selected descriptors: [3, 6, 14, 15]
  Action chosen: REMOVE descriptor 3
  New selection: [6, 14, 15]
  Calculating reward for descriptors: [6, 14, 15]
  Total reward: -4.1784, Per descriptor: -1.3928
Step 5: Currently selected descriptors: [6, 14, 15]
  Action chosen: ADD descriptor 10
  New selection: [6, 10, 14, 15]
  Calculating reward for descriptors: [6, 10, 14, 15]
  Total reward: -4.2458, Per descriptor: -1.0614
Step 6: Currently selected descriptors: [6, 10, 14, 15]
  Action chosen: ADD descriptor 19
  New selection: [6, 10, 14, 15, 19]
  Calculating reward for descriptors: [6, 10, 14, 15, 19]
  Total reward: -4.2701, Per descriptor: -0.8540
Step 7: Currently selected descriptors: [6, 10, 14, 15, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 6, 10, 14, 15, 19]
  Calculating reward for descriptors: [2, 6, 10, 14, 15, 19]
  Total reward: -4.3508, Per descriptor: -0.7251
Step 8: Currently selected descriptors: [2, 6, 10, 14, 15, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 778 experiences...
  DQN training loss: 3727286.250000
Episode 38 Summary:
  Total reward: -28.1388
  Steps taken: 8
  Final descriptors: 6
  Epsilon: 0.827 (82.7% random, 17.3% DQN)
  Avg last 10 episodes: -85.2261
  Best so far: 1.5090 (1 descriptors)

--- Episode 39/50 ---
Episode 39 - Epsilon: 0.827 (82.7% random, 17.3% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 11
  New selection: [11]
  Calculating reward for descriptors: [11]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [11]
  Action chosen: ADD descriptor 9
  New selection: [9, 11]
  Calculating reward for descriptors: [9, 11]
  Total reward: -4.3490, Per descriptor: -2.1745
Step 2: Currently selected descriptors: [9, 11]
  Action chosen: ADD descriptor 4
  New selection: [4, 9, 11]
  Calculating reward for descriptors: [4, 9, 11]
  Total reward: -4.3417, Per descriptor: -1.4472
Step 3: Currently selected descriptors: [4, 9, 11]
  Action chosen: ADD descriptor 19
  New selection: [4, 9, 11, 19]
  Calculating reward for descriptors: [4, 9, 11, 19]
  Total reward: -4.2923, Per descriptor: -1.0731
Step 4: Currently selected descriptors: [4, 9, 11, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [9, 11, 19]
  Calculating reward for descriptors: [9, 11, 19]
  Total reward: -4.2413, Per descriptor: -1.4138
Step 5: Currently selected descriptors: [9, 11, 19]
  Action chosen: ADD descriptor 10
  New selection: [9, 10, 11, 19]
  Calculating reward for descriptors: [9, 10, 11, 19]
  Total reward: -4.3503, Per descriptor: -1.0876
Step 6: Currently selected descriptors: [9, 10, 11, 19]
  Action chosen: ADD descriptor 15
  New selection: [9, 10, 11, 15, 19]
  Calculating reward for descriptors: [9, 10, 11, 15, 19]
  Total reward: -4.4279, Per descriptor: -0.8856
Step 7: Currently selected descriptors: [9, 10, 11, 15, 19]
  Action chosen: ADD descriptor 18
  New selection: [9, 10, 11, 15, 18, 19]
  Calculating reward for descriptors: [9, 10, 11, 15, 18, 19]
  Total reward: -4.4156, Per descriptor: -0.7359
Step 8: Currently selected descriptors: [9, 10, 11, 15, 18, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [9, 10, 11, 18, 19]
  Calculating reward for descriptors: [9, 10, 11, 18, 19]
  Total reward: -4.3794, Per descriptor: -0.8759
Step 9: Currently selected descriptors: [9, 10, 11, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [8, 9, 10, 11, 18, 19]
  Calculating reward for descriptors: [8, 9, 10, 11, 18, 19]
  Total reward: -4.4380, Per descriptor: -0.7397
Step 10: Currently selected descriptors: [8, 9, 10, 11, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 8, 9, 10, 11, 18, 19]
  Calculating reward for descriptors: [4, 8, 9, 10, 11, 18, 19]
  Total reward: -4.4394, Per descriptor: -0.6342
Step 11: Currently selected descriptors: [4, 8, 9, 10, 11, 18, 19]
  Action chosen: ADD descriptor 3
  New selection: [3, 4, 8, 9, 10, 11, 18, 19]
  Calculating reward for descriptors: [3, 4, 8, 9, 10, 11, 18, 19]
  Total reward: -4.4298, Per descriptor: -0.5537
Step 12: Currently selected descriptors: [3, 4, 8, 9, 10, 11, 18, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [3, 4, 8, 10, 11, 18, 19]
  Calculating reward for descriptors: [3, 4, 8, 10, 11, 18, 19]
  Total reward: -4.3892, Per descriptor: -0.6270
Step 13: Currently selected descriptors: [3, 4, 8, 10, 11, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [3, 4, 8, 10, 11, 16, 18, 19]
  Calculating reward for descriptors: [3, 4, 8, 10, 11, 16, 18, 19]
  Total reward: -4.3698, Per descriptor: -0.5462
Step 14: Currently selected descriptors: [3, 4, 8, 10, 11, 16, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [3, 4, 5, 8, 10, 11, 16, 18, 19]
  Calculating reward for descriptors: [3, 4, 5, 8, 10, 11, 16, 18, 19]
  Total reward: -4.3791, Per descriptor: -0.4866
Step 15: Currently selected descriptors: [3, 4, 5, 8, 10, 11, 16, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [3, 4, 5, 6, 8, 10, 11, 16, 18, 19]
  Calculating reward for descriptors: [3, 4, 5, 6, 8, 10, 11, 16, 18, 19]
  Total reward: -4.4117, Per descriptor: -0.4412
Step 16: Currently selected descriptors: [3, 4, 5, 6, 8, 10, 11, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [3, 4, 5, 6, 8, 10, 11, 16, 18]
  Calculating reward for descriptors: [3, 4, 5, 6, 8, 10, 11, 16, 18]
  Total reward: -4.4241, Per descriptor: -0.4916
Step 17: Currently selected descriptors: [3, 4, 5, 6, 8, 10, 11, 16, 18]
  Action chosen: REMOVE descriptor 3
  New selection: [4, 5, 6, 8, 10, 11, 16, 18]
  Calculating reward for descriptors: [4, 5, 6, 8, 10, 11, 16, 18]
  Total reward: -4.4351, Per descriptor: -0.5544
Step 18: Currently selected descriptors: [4, 5, 6, 8, 10, 11, 16, 18]
  Action chosen: REMOVE descriptor 8
  New selection: [4, 5, 6, 10, 11, 16, 18]
  Calculating reward for descriptors: [4, 5, 6, 10, 11, 16, 18]
  Total reward: -4.4662, Per descriptor: -0.6380
Step 19: Currently selected descriptors: [4, 5, 6, 10, 11, 16, 18]
  Action chosen: ADD descriptor 8
  New selection: [4, 5, 6, 8, 10, 11, 16, 18]
  Calculating reward for descriptors: [4, 5, 6, 8, 10, 11, 16, 18]
  Total reward: -4.4351, Per descriptor: -0.5544
Step 20: Currently selected descriptors: [4, 5, 6, 8, 10, 11, 16, 18]
  Action chosen: ADD descriptor 19
  New selection: [4, 5, 6, 8, 10, 11, 16, 18, 19]
  Calculating reward for descriptors: [4, 5, 6, 8, 10, 11, 16, 18, 19]
  Total reward: -4.4148, Per descriptor: -0.4905
Step 21: Currently selected descriptors: [4, 5, 6, 8, 10, 11, 16, 18, 19]
  Action chosen: ADD descriptor 9
  New selection: [4, 5, 6, 8, 9, 10, 11, 16, 18, 19]
  Calculating reward for descriptors: [4, 5, 6, 8, 9, 10, 11, 16, 18, 19]
  Total reward: -4.4328, Per descriptor: -0.4433
Step 22: Currently selected descriptors: [4, 5, 6, 8, 9, 10, 11, 16, 18, 19]
  Action chosen: ADD descriptor 14
  New selection: [4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Calculating reward for descriptors: [4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Total reward: -4.3802, Per descriptor: -0.3982
Step 23: Currently selected descriptors: [4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Action chosen: ADD descriptor 1
  New selection: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Total reward: -4.4103, Per descriptor: -0.3675
Step 24: Currently selected descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 18, 19]
  Action chosen: ADD descriptor 17
  New selection: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 17, 18, 19]
  Total reward: -4.4231, Per descriptor: -0.3402
Step 25: Currently selected descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 14, 16, 17, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19]
  Total reward: -4.4191, Per descriptor: -0.3157
Step 26: Currently selected descriptors: [1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 5, 6, 8, 9, 10, 11, 12, 14, 16, 17, 18, 19]
  Total reward: -4.4274, Per descriptor: -0.2952
  Reached maximum descriptors limit
  Training DQN with 805 experiences...
  DQN training loss: 7442135.500000
Episode 39 Summary:
  Total reward: -112.8189
  Steps taken: 27
  Final descriptors: 15
  Epsilon: 0.822 (82.2% random, 17.8% DQN)
  Avg last 10 episodes: -91.4343
  Best so far: 1.5090 (1 descriptors)

--- Episode 40/50 ---
Episode 40 - Epsilon: 0.822 (82.2% random, 17.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 15
  New selection: [15]
  Calculating reward for descriptors: [15]
  Total reward: 1.5184, Per descriptor: 1.5184
Step 1: Currently selected descriptors: [15]
  Action chosen: ADD descriptor 9
  New selection: [9, 15]
  Calculating reward for descriptors: [9, 15]
  Total reward: -4.2767, Per descriptor: -2.1384
Step 2: Currently selected descriptors: [9, 15]
  Action chosen: ADD descriptor 1
  New selection: [1, 9, 15]
  Calculating reward for descriptors: [1, 9, 15]
  Total reward: -4.3089, Per descriptor: -1.4363
Step 3: Currently selected descriptors: [1, 9, 15]
  Action chosen: ADD descriptor 19
  New selection: [1, 9, 15, 19]
  Calculating reward for descriptors: [1, 9, 15, 19]
  Total reward: -4.3088, Per descriptor: -1.0772
Step 4: Currently selected descriptors: [1, 9, 15, 19]
  Action chosen: ADD descriptor 16
  New selection: [1, 9, 15, 16, 19]
  Calculating reward for descriptors: [1, 9, 15, 16, 19]
  Total reward: -4.4373, Per descriptor: -0.8875
Step 5: Currently selected descriptors: [1, 9, 15, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 9, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 9, 15, 16, 19]
  Total reward: -4.4392, Per descriptor: -0.7399
Step 6: Currently selected descriptors: [0, 1, 9, 15, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 1, 9, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 9, 12, 15, 16, 19]
  Total reward: -4.5143, Per descriptor: -0.6449
Step 7: Currently selected descriptors: [0, 1, 9, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 1, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 9, 12, 16, 19]
  Total reward: -4.4053, Per descriptor: -0.7342
Step 8: Currently selected descriptors: [0, 1, 9, 12, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 7, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 16, 19]
  Total reward: -4.4926, Per descriptor: -0.6418
Step 9: Currently selected descriptors: [0, 1, 7, 9, 12, 16, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [1, 7, 9, 12, 16, 19]
  Calculating reward for descriptors: [1, 7, 9, 12, 16, 19]
  Total reward: -4.5302, Per descriptor: -0.7550
Step 10: Currently selected descriptors: [1, 7, 9, 12, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 7, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 16, 19]
  Total reward: -4.4926, Per descriptor: -0.6418
Step 11: Currently selected descriptors: [0, 1, 7, 9, 12, 16, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 9, 12, 16, 19]
  Total reward: -4.4053, Per descriptor: -0.7342
Step 12: Currently selected descriptors: [0, 1, 9, 12, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 7, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 16, 19]
  Total reward: -4.4926, Per descriptor: -0.6418
Step 13: Currently selected descriptors: [0, 1, 7, 9, 12, 16, 19]
  Action chosen: ADD descriptor 13
  New selection: [0, 1, 7, 9, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 9, 12, 13, 16, 19]
  Total reward: -4.5063, Per descriptor: -0.5633
Step 14: Currently selected descriptors: [0, 1, 7, 9, 12, 13, 16, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 1, 7, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 1, 7, 12, 13, 16, 19]
  Total reward: -4.5062, Per descriptor: -0.6437
Step 15: Currently selected descriptors: [0, 1, 7, 12, 13, 16, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 1, 4, 7, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 7, 12, 13, 16, 19]
  Total reward: -4.4662, Per descriptor: -0.5583
Step 16: Currently selected descriptors: [0, 1, 4, 7, 12, 13, 16, 19]
  Action chosen: ADD descriptor 3
  New selection: [0, 1, 3, 4, 7, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 7, 12, 13, 16, 19]
  Total reward: -4.4485, Per descriptor: -0.4943
Step 17: Currently selected descriptors: [0, 1, 3, 4, 7, 12, 13, 16, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 3, 4, 12, 13, 16, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 12, 13, 16, 19]
  Total reward: -4.4102, Per descriptor: -0.5513
Step 18: Currently selected descriptors: [0, 1, 3, 4, 12, 13, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 1, 3, 4, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 12, 13, 16, 18, 19]
  Total reward: -4.4333, Per descriptor: -0.4926
Step 19: Currently selected descriptors: [0, 1, 3, 4, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 3, 4, 9, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 9, 12, 13, 16, 18, 19]
  Total reward: -4.4467, Per descriptor: -0.4447
Step 20: Currently selected descriptors: [0, 1, 3, 4, 9, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 1, 3, 4, 9, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 3, 4, 9, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4637, Per descriptor: -0.4058
Step 21: Currently selected descriptors: [0, 1, 3, 4, 9, 12, 13, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [0, 1, 4, 9, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 9, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4659, Per descriptor: -0.4466
Step 22: Currently selected descriptors: [0, 1, 4, 9, 12, 13, 16, 17, 18, 19]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4596, Per descriptor: -0.4054
Step 23: Currently selected descriptors: [0, 1, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4346, Per descriptor: -0.4435
Step 24: Currently selected descriptors: [0, 4, 5, 9, 12, 13, 16, 17, 18, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 4, 5, 9, 10, 12, 13, 16, 17, 18, 19]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17, 18, 19]
  Total reward: -4.4493, Per descriptor: -0.4045
Step 25: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 17, 18, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [0, 4, 5, 9, 10, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 18, 19]
  Total reward: -4.4355, Per descriptor: -0.4435
Step 26: Currently selected descriptors: [0, 4, 5, 9, 10, 12, 13, 16, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 4, 5, 8, 9, 10, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 16, 18, 19]
  Total reward: -4.4494, Per descriptor: -0.4045
Step 27: Currently selected descriptors: [0, 4, 5, 8, 9, 10, 12, 13, 16, 18, 19]
  Action chosen: REMOVE descriptor 5
  New selection: [0, 4, 8, 9, 10, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 4, 8, 9, 10, 12, 13, 16, 18, 19]
  Total reward: -4.4608, Per descriptor: -0.4461
Step 28: Currently selected descriptors: [0, 4, 8, 9, 10, 12, 13, 16, 18, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 4, 8, 9, 12, 13, 16, 18, 19]
  Calculating reward for descriptors: [0, 4, 8, 9, 12, 13, 16, 18, 19]
  Total reward: -4.4461, Per descriptor: -0.4940
Step 29: Currently selected descriptors: [0, 4, 8, 9, 12, 13, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 4, 8, 9, 12, 13, 16, 18]
  Calculating reward for descriptors: [0, 4, 8, 9, 12, 13, 16, 18]
  Total reward: -4.4897, Per descriptor: -0.5612
Step 30: Currently selected descriptors: [0, 4, 8, 9, 12, 13, 16, 18]
  Action chosen: ADD descriptor 14
  New selection: [0, 4, 8, 9, 12, 13, 14, 16, 18]
  Calculating reward for descriptors: [0, 4, 8, 9, 12, 13, 14, 16, 18]
  Total reward: -4.4151, Per descriptor: -0.4906
Step 31: Currently selected descriptors: [0, 4, 8, 9, 12, 13, 14, 16, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 836 experiences...
  DQN training loss: 5617626.000000
Episode 40 Summary:
  Total reward: -131.7724
  Steps taken: 31
  Final descriptors: 9
  Epsilon: 0.818 (81.8% random, 18.2% DQN)
  Avg last 10 episodes: -103.4829
  Best so far: 1.5090 (1 descriptors)

--- Episode 41/50 ---
Episode 41 - Epsilon: 0.818 (81.8% random, 18.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 9
  New selection: [9]
  Calculating reward for descriptors: [9]
  Total reward: 1.2022, Per descriptor: 1.2022
Step 1: Currently selected descriptors: [9]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 837 experiences...
  DQN training loss: 7479886.000000
  Updated target network weights
Episode 41 Summary:
  Total reward: 1.2022
  Steps taken: 1
  Final descriptors: 1
  Epsilon: 0.814 (81.4% random, 18.6% DQN)
  Avg last 10 episodes: -95.5135
  Best so far: 1.5090 (1 descriptors)

--- Episode 42/50 ---
Episode 42 - Epsilon: 0.814 (81.4% random, 18.6% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 6
  New selection: [6]
  Calculating reward for descriptors: [6]
  Total reward: 1.5139, Per descriptor: 1.5139
Step 1: Currently selected descriptors: [6]
  Action chosen: ADD descriptor 4
  New selection: [4, 6]
  Calculating reward for descriptors: [4, 6]
  Total reward: -4.7347, Per descriptor: -2.3673
Step 2: Currently selected descriptors: [4, 6]
  Action chosen: ADD descriptor 2
  New selection: [2, 4, 6]
  Calculating reward for descriptors: [2, 4, 6]
  Total reward: -4.7066, Per descriptor: -1.5689
Step 3: Currently selected descriptors: [2, 4, 6]
  Action chosen: ADD descriptor 19
  New selection: [2, 4, 6, 19]
  Calculating reward for descriptors: [2, 4, 6, 19]
  Total reward: -4.6184, Per descriptor: -1.1546
Step 4: Currently selected descriptors: [2, 4, 6, 19]
  Action chosen: ADD descriptor 16
  New selection: [2, 4, 6, 16, 19]
  Calculating reward for descriptors: [2, 4, 6, 16, 19]
  Total reward: -4.4356, Per descriptor: -0.8871
Step 5: Currently selected descriptors: [2, 4, 6, 16, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [4, 6, 16, 19]
  Calculating reward for descriptors: [4, 6, 16, 19]
  Total reward: -4.3484, Per descriptor: -1.0871
Step 6: Currently selected descriptors: [4, 6, 16, 19]
  Action chosen: ADD descriptor 15
  New selection: [4, 6, 15, 16, 19]
  Calculating reward for descriptors: [4, 6, 15, 16, 19]
  Total reward: -4.4278, Per descriptor: -0.8856
Step 7: Currently selected descriptors: [4, 6, 15, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [4, 6, 9, 15, 16, 19]
  Calculating reward for descriptors: [4, 6, 9, 15, 16, 19]
  Total reward: -4.3910, Per descriptor: -0.7318
Step 8: Currently selected descriptors: [4, 6, 9, 15, 16, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [4, 6, 9, 15, 16]
  Calculating reward for descriptors: [4, 6, 9, 15, 16]
  Total reward: -4.4410, Per descriptor: -0.8882
Step 9: Currently selected descriptors: [4, 6, 9, 15, 16]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 6, 9, 15, 16]
  Calculating reward for descriptors: [0, 4, 6, 9, 15, 16]
  Total reward: -4.4414, Per descriptor: -0.7402
Step 10: Currently selected descriptors: [0, 4, 6, 9, 15, 16]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 4, 6, 9, 15]
  Calculating reward for descriptors: [0, 4, 6, 9, 15]
  Total reward: -4.4003, Per descriptor: -0.8801
Step 11: Currently selected descriptors: [0, 4, 6, 9, 15]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 4, 6, 9, 15]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 15]
  Total reward: -4.4782, Per descriptor: -0.7464
Step 12: Currently selected descriptors: [0, 1, 4, 6, 9, 15]
  Action chosen: ADD descriptor 17
  New selection: [0, 1, 4, 6, 9, 15, 17]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 15, 17]
  Total reward: -4.5007, Per descriptor: -0.6430
Step 13: Currently selected descriptors: [0, 1, 4, 6, 9, 15, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 4, 6, 9, 15, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 15, 17, 19]
  Total reward: -4.4791, Per descriptor: -0.5599
Step 14: Currently selected descriptors: [0, 1, 4, 6, 9, 15, 17, 19]
  Action chosen: ADD descriptor 13
  New selection: [0, 1, 4, 6, 9, 13, 15, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 13, 15, 17, 19]
  Total reward: -4.4947, Per descriptor: -0.4994
Step 15: Currently selected descriptors: [0, 1, 4, 6, 9, 13, 15, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 4, 6, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 13, 15, 16, 17, 19]
  Total reward: -4.4752, Per descriptor: -0.4475
Step 16: Currently selected descriptors: [0, 1, 4, 6, 9, 13, 15, 16, 17, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 1, 4, 6, 9, 12, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 9, 12, 13, 15, 16, 17, 19]
  Total reward: -4.4795, Per descriptor: -0.4072
Step 17: Currently selected descriptors: [0, 1, 4, 6, 9, 12, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [0, 1, 6, 9, 12, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 6, 9, 12, 13, 15, 16, 17, 19]
  Total reward: -4.4977, Per descriptor: -0.4498
Step 18: Currently selected descriptors: [0, 1, 6, 9, 12, 13, 15, 16, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 6, 9, 12, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 9, 12, 13, 15, 16, 17, 19]
  Total reward: -4.5183, Per descriptor: -0.4108
Step 19: Currently selected descriptors: [0, 1, 2, 6, 9, 12, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 2, 6, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 9, 13, 15, 16, 17, 19]
  Total reward: -4.5189, Per descriptor: -0.4519
Step 20: Currently selected descriptors: [0, 1, 2, 6, 9, 13, 15, 16, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 2, 6, 7, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 6, 7, 9, 13, 15, 16, 17, 19]
  Total reward: -4.5132, Per descriptor: -0.4103
Step 21: Currently selected descriptors: [0, 1, 2, 6, 7, 9, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 1, 2, 7, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 7, 9, 13, 15, 16, 17, 19]
  Total reward: -4.5178, Per descriptor: -0.4518
Step 22: Currently selected descriptors: [0, 1, 2, 7, 9, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 2, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 9, 13, 15, 16, 17, 19]
  Total reward: -4.5174, Per descriptor: -0.5019
Step 23: Currently selected descriptors: [0, 1, 2, 9, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 1, 2, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 13, 15, 16, 17, 19]
  Total reward: -4.5114, Per descriptor: -0.5639
Step 24: Currently selected descriptors: [0, 1, 2, 13, 15, 16, 17, 19]
  Action chosen: ADD descriptor 14
  New selection: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Total reward: -4.4415, Per descriptor: -0.4935
Step 25: Currently selected descriptors: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Total reward: -4.4527, Per descriptor: -0.4453
Step 26: Currently selected descriptors: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Total reward: -4.4415, Per descriptor: -0.4935
Step 27: Currently selected descriptors: [0, 1, 2, 13, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Total reward: -4.4527, Per descriptor: -0.4453
Step 28: Currently selected descriptors: [0, 1, 2, 9, 13, 14, 15, 16, 17, 19]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 2, 5, 9, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 13, 14, 15, 16, 17, 19]
  Total reward: -4.4378, Per descriptor: -0.4034
Step 29: Currently selected descriptors: [0, 1, 2, 5, 9, 13, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [0, 1, 5, 9, 13, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 5, 9, 13, 14, 15, 16, 17, 19]
  Total reward: -4.3983, Per descriptor: -0.4398
Step 30: Currently selected descriptors: [0, 1, 5, 9, 13, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 14
  New selection: [0, 1, 5, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 5, 9, 13, 15, 16, 17, 19]
  Total reward: -4.4531, Per descriptor: -0.4948
Step 31: Currently selected descriptors: [0, 1, 5, 9, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 1, 5, 9, 13, 15, 17, 19]
  Calculating reward for descriptors: [0, 1, 5, 9, 13, 15, 17, 19]
  Total reward: -4.4606, Per descriptor: -0.5576
Step 32: Currently selected descriptors: [0, 1, 5, 9, 13, 15, 17, 19]
  Action chosen: ADD descriptor 2
  New selection: [0, 1, 2, 5, 9, 13, 15, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 13, 15, 17, 19]
  Total reward: -4.5093, Per descriptor: -0.5010
Step 33: Currently selected descriptors: [0, 1, 2, 5, 9, 13, 15, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 2, 5, 9, 13, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 13, 15, 16, 17, 19]
  Total reward: -4.4915, Per descriptor: -0.4492
Step 34: Currently selected descriptors: [0, 1, 2, 5, 9, 13, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [0, 1, 2, 5, 9, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 15, 16, 17, 19]
  Total reward: -4.4781, Per descriptor: -0.4976
Step 35: Currently selected descriptors: [0, 1, 2, 5, 9, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [1, 2, 5, 9, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 5, 9, 15, 16, 17, 19]
  Total reward: -4.4674, Per descriptor: -0.5584
Step 36: Currently selected descriptors: [1, 2, 5, 9, 15, 16, 17, 19]
  Action chosen: ADD descriptor 14
  New selection: [1, 2, 5, 9, 14, 15, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 5, 9, 14, 15, 16, 17, 19]
  Total reward: -4.4074, Per descriptor: -0.4897
Step 37: Currently selected descriptors: [1, 2, 5, 9, 14, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [1, 2, 5, 9, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 5, 9, 14, 16, 17, 19]
  Total reward: -4.4125, Per descriptor: -0.5516
Step 38: Currently selected descriptors: [1, 2, 5, 9, 14, 16, 17, 19]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 5, 9, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [1, 2, 5, 9, 12, 14, 16, 17, 19]
  Total reward: -4.3938, Per descriptor: -0.4882
Step 39: Currently selected descriptors: [1, 2, 5, 9, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [1, 2, 5, 9, 12, 14, 16, 17]
  Calculating reward for descriptors: [1, 2, 5, 9, 12, 14, 16, 17]
  Total reward: -4.4033, Per descriptor: -0.5504
Step 40: Currently selected descriptors: [1, 2, 5, 9, 12, 14, 16, 17]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 2, 5, 9, 12, 14, 16, 17]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 17]
  Total reward: -4.4205, Per descriptor: -0.4912
Step 41: Currently selected descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 2, 5, 9, 12, 14, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 17, 19]
  Total reward: -4.4102, Per descriptor: -0.4410
Step 42: Currently selected descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 17, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [0, 1, 2, 5, 9, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 19]
  Total reward: -4.3769, Per descriptor: -0.4863
Step 43: Currently selected descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 2, 5, 7, 9, 12, 14, 16, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 19]
  Total reward: -4.4053, Per descriptor: -0.4405
Step 44: Currently selected descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4210, Per descriptor: -0.4019
Step 45: Currently selected descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 2, 5, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4057, Per descriptor: -0.4406
Step 46: Currently selected descriptors: [0, 1, 2, 5, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4210, Per descriptor: -0.4019
Step 47: Currently selected descriptors: [0, 1, 2, 5, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4381, Per descriptor: -0.3698
Step 48: Currently selected descriptors: [0, 1, 2, 5, 6, 7, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4346, Per descriptor: -0.4031
Step 49: Currently selected descriptors: [0, 1, 2, 5, 6, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [0, 1, 2, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4257, Per descriptor: -0.3688
Step 50: Currently selected descriptors: [0, 1, 2, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 1, 2, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4304, Per descriptor: -0.3408
Step 51: Currently selected descriptors: [0, 1, 2, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [0, 1, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Total reward: -4.4041, Per descriptor: -0.3670
Step 52: Currently selected descriptors: [0, 1, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Calculating reward for descriptors: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Total reward: -4.3759, Per descriptor: -0.3978
Step 53: Currently selected descriptors: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18]
  Calculating reward for descriptors: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18]
  Total reward: -4.3895, Per descriptor: -0.4390
Step 54: Currently selected descriptors: [0, 4, 5, 6, 8, 9, 12, 14, 16, 18]
  Action chosen: ADD descriptor 13
  New selection: [0, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18]
  Calculating reward for descriptors: [0, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18]
  Total reward: -4.4216, Per descriptor: -0.4020
Step 55: Currently selected descriptors: [0, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18]
  Action chosen: ADD descriptor 11
  New selection: [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Calculating reward for descriptors: [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Total reward: -4.4288, Per descriptor: -0.3691
Step 56: Currently selected descriptors: [0, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Action chosen: REMOVE descriptor 0
  New selection: [4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Calculating reward for descriptors: [4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Total reward: -4.4356, Per descriptor: -0.4032
Step 57: Currently selected descriptors: [4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Action chosen: REMOVE descriptor 12
  New selection: [4, 5, 6, 8, 9, 11, 13, 14, 16, 18]
  Calculating reward for descriptors: [4, 5, 6, 8, 9, 11, 13, 14, 16, 18]
  Total reward: -4.4205, Per descriptor: -0.4420
Step 58: Currently selected descriptors: [4, 5, 6, 8, 9, 11, 13, 14, 16, 18]
  Action chosen: REMOVE descriptor 5
  New selection: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Calculating reward for descriptors: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Total reward: -4.4246, Per descriptor: -0.4916
Step 59: Currently selected descriptors: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Action chosen: ADD descriptor 12
  New selection: [4, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Calculating reward for descriptors: [4, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Total reward: -4.4463, Per descriptor: -0.4446
Step 60: Currently selected descriptors: [4, 6, 8, 9, 11, 12, 13, 14, 16, 18]
  Action chosen: REMOVE descriptor 12
  New selection: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Calculating reward for descriptors: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Total reward: -4.4246, Per descriptor: -0.4916
Step 61: Currently selected descriptors: [4, 6, 8, 9, 11, 13, 14, 16, 18]
  Action chosen: ADD descriptor 1
  New selection: [1, 4, 6, 8, 9, 11, 13, 14, 16, 18]
  Calculating reward for descriptors: [1, 4, 6, 8, 9, 11, 13, 14, 16, 18]
  Total reward: -4.4476, Per descriptor: -0.4448
Step 62: Currently selected descriptors: [1, 4, 6, 8, 9, 11, 13, 14, 16, 18]
  Action chosen: REMOVE descriptor 14
  New selection: [1, 4, 6, 8, 9, 11, 13, 16, 18]
  Calculating reward for descriptors: [1, 4, 6, 8, 9, 11, 13, 16, 18]
  Total reward: -4.5145, Per descriptor: -0.5016
Step 63: Currently selected descriptors: [1, 4, 6, 8, 9, 11, 13, 16, 18]
  Action chosen: REMOVE descriptor 11
  New selection: [1, 4, 6, 8, 9, 13, 16, 18]
  Calculating reward for descriptors: [1, 4, 6, 8, 9, 13, 16, 18]
  Total reward: -4.5636, Per descriptor: -0.5704
Step 64: Currently selected descriptors: [1, 4, 6, 8, 9, 13, 16, 18]
  Action chosen: ADD descriptor 3
  New selection: [1, 3, 4, 6, 8, 9, 13, 16, 18]
  Calculating reward for descriptors: [1, 3, 4, 6, 8, 9, 13, 16, 18]
  Total reward: -4.5263, Per descriptor: -0.5029
Step 65: Currently selected descriptors: [1, 3, 4, 6, 8, 9, 13, 16, 18]
  Action chosen: ADD descriptor 7
  New selection: [1, 3, 4, 6, 7, 8, 9, 13, 16, 18]
  Calculating reward for descriptors: [1, 3, 4, 6, 7, 8, 9, 13, 16, 18]
  Total reward: -4.4862, Per descriptor: -0.4486
Step 66: Currently selected descriptors: [1, 3, 4, 6, 7, 8, 9, 13, 16, 18]
  Action chosen: REMOVE descriptor 3
  New selection: [1, 4, 6, 7, 8, 9, 13, 16, 18]
  Calculating reward for descriptors: [1, 4, 6, 7, 8, 9, 13, 16, 18]
  Total reward: -4.5157, Per descriptor: -0.5017
Step 67: Currently selected descriptors: [1, 4, 6, 7, 8, 9, 13, 16, 18]
  Action chosen: ADD descriptor 2
  New selection: [1, 2, 4, 6, 7, 8, 9, 13, 16, 18]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 13, 16, 18]
  Total reward: -4.5249, Per descriptor: -0.4525
Step 68: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 13, 16, 18]
  Action chosen: ADD descriptor 12
  New selection: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16, 18]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16, 18]
  Total reward: -4.5216, Per descriptor: -0.4111
Step 69: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16]
  Total reward: -4.5201, Per descriptor: -0.4520
Step 70: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 16]
  Action chosen: ADD descriptor 15
  New selection: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16]
  Total reward: -4.5575, Per descriptor: -0.4143
Step 71: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16]
  Action chosen: ADD descriptor 19
  New selection: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Total reward: -4.5152, Per descriptor: -0.3763
Step 72: Currently selected descriptors: [1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Total reward: -4.5040, Per descriptor: -0.3465
Step 73: Currently selected descriptors: [0, 1, 2, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [0, 1, 2, 4, 6, 7, 8, 12, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 6, 7, 8, 12, 13, 15, 16, 19]
  Total reward: -4.4993, Per descriptor: -0.3749
Step 74: Currently selected descriptors: [0, 1, 2, 4, 6, 7, 8, 12, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 2, 4, 6, 7, 8, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 2, 4, 6, 7, 8, 13, 15, 16, 19]
  Total reward: -4.4684, Per descriptor: -0.4062
Step 75: Currently selected descriptors: [0, 1, 2, 4, 6, 7, 8, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Total reward: -4.4506, Per descriptor: -0.4451
Step 76: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 4, 6, 7, 8, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 4, 6, 7, 8, 13, 15, 16, 19]
  Total reward: -4.4389, Per descriptor: -0.4932
Step 77: Currently selected descriptors: [0, 4, 6, 7, 8, 13, 15, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Total reward: -4.4506, Per descriptor: -0.4451
Step 78: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 13, 15, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 4, 6, 7, 8, 9, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 13, 15, 16, 19]
  Total reward: -4.4717, Per descriptor: -0.4065
Step 79: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 13, 15, 16, 19]
  Action chosen: ADD descriptor 11
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 13, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 13, 15, 16, 19]
  Total reward: -4.5431, Per descriptor: -0.3786
Step 80: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 13, 15, 16, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 19]
  Total reward: -4.5410, Per descriptor: -0.4128
Step 81: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5879, Per descriptor: -0.3823
Step 82: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5671, Per descriptor: -0.3513
Step 83: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 18, 19]
  Total reward: -4.5302, Per descriptor: -0.3775
Step 84: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 15, 16, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5671, Per descriptor: -0.3513
Step 85: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 18, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Total reward: -4.5489, Per descriptor: -0.3249
Step 86: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Total reward: -4.4862, Per descriptor: -0.3451
Step 87: Currently selected descriptors: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.4851, Per descriptor: -0.3738
Step 88: Currently selected descriptors: [0, 1, 4, 6, 8, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 10
  New selection: [0, 1, 4, 6, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.4902, Per descriptor: -0.4082
Step 89: Currently selected descriptors: [0, 1, 4, 6, 8, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5884, Per descriptor: -0.3824
Step 90: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 19]
  Total reward: -4.5777, Per descriptor: -0.4162
Step 91: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5884, Per descriptor: -0.3824
Step 92: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Total reward: -4.5625, Per descriptor: -0.3510
Step 93: Currently selected descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Total reward: -4.5893, Per descriptor: -0.3824
Step 94: Currently selected descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 1, 4, 8, 9, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 8, 9, 11, 12, 15, 16, 17, 19]
  Total reward: -4.4948, Per descriptor: -0.4086
Step 95: Currently selected descriptors: [0, 1, 4, 8, 9, 11, 12, 15, 16, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Calculating reward for descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Total reward: -4.5893, Per descriptor: -0.3824
Step 96: Currently selected descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17]
  Calculating reward for descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17]
  Total reward: -4.6509, Per descriptor: -0.4228
Step 97: Currently selected descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 17]
  Action chosen: REMOVE descriptor 17
  New selection: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16]
  Calculating reward for descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16]
  Total reward: -4.7083, Per descriptor: -0.4708
Step 98: Currently selected descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16]
  Action chosen: ADD descriptor 19
  New selection: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.6248, Per descriptor: -0.4204
Step 99: Currently selected descriptors: [0, 1, 4, 7, 8, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 6
  New selection: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 4, 6, 7, 8, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5875, Per descriptor: -0.3823
  Training DQN with 937 experiences...
  DQN training loss: 9782972.000000
Episode 42 Summary:
  Total reward: -442.6809
  Steps taken: 100
  Final descriptors: 12
  Epsilon: 0.810 (81.0% random, 19.0% DQN)
  Avg last 10 episodes: -126.7276
  Best so far: 1.5090 (1 descriptors)

--- Episode 43/50 ---
Episode 43 - Epsilon: 0.810 (81.0% random, 19.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 18
  New selection: [18]
  Calculating reward for descriptors: [18]
  Total reward: 1.5359, Per descriptor: 1.5359
Step 1: Currently selected descriptors: [18]
  Action chosen: ADD descriptor 0
  New selection: [0, 18]
  Calculating reward for descriptors: [0, 18]
  Total reward: -4.6457, Per descriptor: -2.3228
Step 2: Currently selected descriptors: [0, 18]
  Action chosen: ADD descriptor 19
  New selection: [0, 18, 19]
  Calculating reward for descriptors: [0, 18, 19]
  Total reward: -4.5572, Per descriptor: -1.5191
Step 3: Currently selected descriptors: [0, 18, 19]
  Action chosen: REMOVE descriptor 0
  New selection: [18, 19]
  Calculating reward for descriptors: [18, 19]
  Total reward: -4.5212, Per descriptor: -2.2606
Step 4: Currently selected descriptors: [18, 19]
  Action chosen: ADD descriptor 10
  New selection: [10, 18, 19]
  Calculating reward for descriptors: [10, 18, 19]
  Total reward: -4.5363, Per descriptor: -1.5121
Step 5: Currently selected descriptors: [10, 18, 19]
  Action chosen: ADD descriptor 8
  New selection: [8, 10, 18, 19]
  Calculating reward for descriptors: [8, 10, 18, 19]
  Total reward: -4.4814, Per descriptor: -1.1203
Step 6: Currently selected descriptors: [8, 10, 18, 19]
  Action chosen: ADD descriptor 6
  New selection: [6, 8, 10, 18, 19]
  Calculating reward for descriptors: [6, 8, 10, 18, 19]
  Total reward: -4.5418, Per descriptor: -0.9084
Step 7: Currently selected descriptors: [6, 8, 10, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [6, 8, 10, 18]
  Calculating reward for descriptors: [6, 8, 10, 18]
  Total reward: -4.6284, Per descriptor: -1.1571
Step 8: Currently selected descriptors: [6, 8, 10, 18]
  Action chosen: ADD descriptor 13
  New selection: [6, 8, 10, 13, 18]
  Calculating reward for descriptors: [6, 8, 10, 13, 18]
  Total reward: -4.6417, Per descriptor: -0.9283
Step 9: Currently selected descriptors: [6, 8, 10, 13, 18]
  Action chosen: ADD descriptor 9
  New selection: [6, 8, 9, 10, 13, 18]
  Calculating reward for descriptors: [6, 8, 9, 10, 13, 18]
  Total reward: -4.7285, Per descriptor: -0.7881
Step 10: Currently selected descriptors: [6, 8, 9, 10, 13, 18]
  Action chosen: ADD descriptor 14
  New selection: [6, 8, 9, 10, 13, 14, 18]
  Calculating reward for descriptors: [6, 8, 9, 10, 13, 14, 18]
  Total reward: -4.5793, Per descriptor: -0.6542
Step 11: Currently selected descriptors: [6, 8, 9, 10, 13, 14, 18]
  Action chosen: ADD descriptor 12
  New selection: [6, 8, 9, 10, 12, 13, 14, 18]
  Calculating reward for descriptors: [6, 8, 9, 10, 12, 13, 14, 18]
  Total reward: -4.4726, Per descriptor: -0.5591
Step 12: Currently selected descriptors: [6, 8, 9, 10, 12, 13, 14, 18]
  Action chosen: REMOVE descriptor 13
  New selection: [6, 8, 9, 10, 12, 14, 18]
  Calculating reward for descriptors: [6, 8, 9, 10, 12, 14, 18]
  Total reward: -4.4115, Per descriptor: -0.6302
Step 13: Currently selected descriptors: [6, 8, 9, 10, 12, 14, 18]
  Action chosen: ADD descriptor 19
  New selection: [6, 8, 9, 10, 12, 14, 18, 19]
  Calculating reward for descriptors: [6, 8, 9, 10, 12, 14, 18, 19]
  Total reward: -4.3861, Per descriptor: -0.5483
Step 14: Currently selected descriptors: [6, 8, 9, 10, 12, 14, 18, 19]
  Action chosen: ADD descriptor 2
  New selection: [2, 6, 8, 9, 10, 12, 14, 18, 19]
  Calculating reward for descriptors: [2, 6, 8, 9, 10, 12, 14, 18, 19]
  Total reward: -4.4196, Per descriptor: -0.4911
Step 15: Currently selected descriptors: [2, 6, 8, 9, 10, 12, 14, 18, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 2, 6, 8, 9, 10, 12, 14, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 12, 14, 18, 19]
  Total reward: -4.4492, Per descriptor: -0.4449
Step 16: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 12, 14, 18, 19]
  Action chosen: ADD descriptor 17
  New selection: [0, 2, 6, 8, 9, 10, 12, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 12, 14, 17, 18, 19]
  Total reward: -4.4725, Per descriptor: -0.4066
Step 17: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 12, 14, 17, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Total reward: -4.4524, Per descriptor: -0.3710
Step 18: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [0, 2, 6, 8, 9, 10, 11, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 11, 14, 17, 18, 19]
  Total reward: -4.4747, Per descriptor: -0.4068
Step 19: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 11, 14, 17, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Total reward: -4.4524, Per descriptor: -0.3710
Step 20: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 17, 18, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]
  Total reward: -4.4534, Per descriptor: -0.3426
Step 21: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19]
  Action chosen: REMOVE descriptor 17
  New selection: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Total reward: -4.4435, Per descriptor: -0.3703
Step 22: Currently selected descriptors: [0, 2, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Action chosen: ADD descriptor 4
  New selection: [0, 2, 4, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Total reward: -4.4353, Per descriptor: -0.3412
Step 23: Currently selected descriptors: [0, 2, 4, 6, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 6
  New selection: [0, 2, 4, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [0, 2, 4, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Total reward: -4.4270, Per descriptor: -0.3689
Step 24: Currently selected descriptors: [0, 2, 4, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Action chosen: REMOVE descriptor 4
  New selection: [0, 2, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Calculating reward for descriptors: [0, 2, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Total reward: -4.4387, Per descriptor: -0.4035
Step 25: Currently selected descriptors: [0, 2, 8, 9, 10, 11, 12, 14, 15, 18, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 962 experiences...
  DQN training loss: 20650734.000000
Episode 43 Summary:
  Total reward: -106.5145
  Steps taken: 25
  Final descriptors: 11
  Epsilon: 0.806 (80.6% random, 19.4% DQN)
  Avg last 10 episodes: -120.7890
  Best so far: 1.5090 (1 descriptors)

--- Episode 44/50 ---
Episode 44 - Epsilon: 0.806 (80.6% random, 19.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 9
  New selection: [9]
  Calculating reward for descriptors: [9]
  Total reward: 1.2022, Per descriptor: 1.2022
Step 1: Currently selected descriptors: [9]
  Action chosen: ADD descriptor 19
  New selection: [9, 19]
  Calculating reward for descriptors: [9, 19]
  Total reward: -4.3921, Per descriptor: -2.1960
Step 2: Currently selected descriptors: [9, 19]
  Action chosen: ADD descriptor 4
  New selection: [4, 9, 19]
  Calculating reward for descriptors: [4, 9, 19]
  Total reward: -4.5356, Per descriptor: -1.5119
Step 3: Currently selected descriptors: [4, 9, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 4, 9, 19]
  Calculating reward for descriptors: [0, 4, 9, 19]
  Total reward: -4.4775, Per descriptor: -1.1194
Step 4: Currently selected descriptors: [0, 4, 9, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 4, 9, 16, 19]
  Calculating reward for descriptors: [0, 4, 9, 16, 19]
  Total reward: -4.3561, Per descriptor: -0.8712
Step 5: Currently selected descriptors: [0, 4, 9, 16, 19]
  Action chosen: ADD descriptor 12
  New selection: [0, 4, 9, 12, 16, 19]
  Calculating reward for descriptors: [0, 4, 9, 12, 16, 19]
  Total reward: -4.3658, Per descriptor: -0.7276
Step 6: Currently selected descriptors: [0, 4, 9, 12, 16, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 968 experiences...
  DQN training loss: 13023268.000000
Episode 44 Summary:
  Total reward: -20.9248
  Steps taken: 6
  Final descriptors: 6
  Epsilon: 0.802 (80.2% random, 19.8% DQN)
  Avg last 10 episodes: -105.6671
  Best so far: 1.5090 (1 descriptors)

--- Episode 45/50 ---
Episode 45 - Epsilon: 0.802 (80.2% random, 19.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 19
  New selection: [19]
  Calculating reward for descriptors: [19]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 1: Currently selected descriptors: [19]
  Action chosen: ADD descriptor 11
  New selection: [11, 19]
  Calculating reward for descriptors: [11, 19]
  Total reward: -4.1374, Per descriptor: -2.0687
Step 2: Currently selected descriptors: [11, 19]
  Action chosen: REMOVE descriptor 11
  New selection: [19]
  Calculating reward for descriptors: [19]
  Total reward: 1.5040, Per descriptor: 1.5040
Step 3: Currently selected descriptors: [19]
  Action chosen: ADD descriptor 5
  New selection: [5, 19]
  Calculating reward for descriptors: [5, 19]
  Total reward: -4.4027, Per descriptor: -2.2013
Step 4: Currently selected descriptors: [5, 19]
  Action chosen: ADD descriptor 12
  New selection: [5, 12, 19]
  Calculating reward for descriptors: [5, 12, 19]
  Total reward: -4.2074, Per descriptor: -1.4025
Step 5: Currently selected descriptors: [5, 12, 19]
  Action chosen: ADD descriptor 3
  New selection: [3, 5, 12, 19]
  Calculating reward for descriptors: [3, 5, 12, 19]
  Total reward: -4.2995, Per descriptor: -1.0749
Step 6: Currently selected descriptors: [3, 5, 12, 19]
  Action chosen: ADD descriptor 17
  New selection: [3, 5, 12, 17, 19]
  Calculating reward for descriptors: [3, 5, 12, 17, 19]
  Total reward: -4.3644, Per descriptor: -0.8729
Step 7: Currently selected descriptors: [3, 5, 12, 17, 19]
  Action chosen: ADD descriptor 15
  New selection: [3, 5, 12, 15, 17, 19]
  Calculating reward for descriptors: [3, 5, 12, 15, 17, 19]
  Total reward: -4.4248, Per descriptor: -0.7375
Step 8: Currently selected descriptors: [3, 5, 12, 15, 17, 19]
  Action chosen: REMOVE descriptor 3
  New selection: [5, 12, 15, 17, 19]
  Calculating reward for descriptors: [5, 12, 15, 17, 19]
  Total reward: -4.4427, Per descriptor: -0.8885
Step 9: Currently selected descriptors: [5, 12, 15, 17, 19]
  Action chosen: ADD descriptor 9
  New selection: [5, 9, 12, 15, 17, 19]
  Calculating reward for descriptors: [5, 9, 12, 15, 17, 19]
  Total reward: -4.3942, Per descriptor: -0.7324
Step 10: Currently selected descriptors: [5, 9, 12, 15, 17, 19]
  Action chosen: REMOVE descriptor 12
  New selection: [5, 9, 15, 17, 19]
  Calculating reward for descriptors: [5, 9, 15, 17, 19]
  Total reward: -4.3138, Per descriptor: -0.8628
Step 11: Currently selected descriptors: [5, 9, 15, 17, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [5, 9, 15, 17]
  Calculating reward for descriptors: [5, 9, 15, 17]
  Total reward: -4.3023, Per descriptor: -1.0756
Step 12: Currently selected descriptors: [5, 9, 15, 17]
  Action chosen: ADD descriptor 0
  New selection: [0, 5, 9, 15, 17]
  Calculating reward for descriptors: [0, 5, 9, 15, 17]
  Total reward: -4.3815, Per descriptor: -0.8763
Step 13: Currently selected descriptors: [0, 5, 9, 15, 17]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 5, 9, 17]
  Calculating reward for descriptors: [0, 5, 9, 17]
  Total reward: -4.5282, Per descriptor: -1.1320
Step 14: Currently selected descriptors: [0, 5, 9, 17]
  Action chosen: ADD descriptor 12
  New selection: [0, 5, 9, 12, 17]
  Calculating reward for descriptors: [0, 5, 9, 12, 17]
  Total reward: -4.3843, Per descriptor: -0.8769
Step 15: Currently selected descriptors: [0, 5, 9, 12, 17]
  Action chosen: ADD descriptor 19
  New selection: [0, 5, 9, 12, 17, 19]
  Calculating reward for descriptors: [0, 5, 9, 12, 17, 19]
  Total reward: -4.3818, Per descriptor: -0.7303
Step 16: Currently selected descriptors: [0, 5, 9, 12, 17, 19]
  Action chosen: ADD descriptor 16
  New selection: [0, 5, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 5, 9, 12, 16, 17, 19]
  Total reward: -4.3831, Per descriptor: -0.6262
Step 17: Currently selected descriptors: [0, 5, 9, 12, 16, 17, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 5, 7, 9, 12, 16, 17, 19]
  Calculating reward for descriptors: [0, 5, 7, 9, 12, 16, 17, 19]
  Total reward: -4.4420, Per descriptor: -0.5553
Step 18: Currently selected descriptors: [0, 5, 7, 9, 12, 16, 17, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 986 experiences...
  DQN training loss: 6987122.000000
Episode 45 Summary:
  Total reward: -66.7820
  Steps taken: 18
  Final descriptors: 8
  Epsilon: 0.798 (79.8% random, 20.2% DQN)
  Avg last 10 episodes: -106.9299
  Best so far: 1.5090 (1 descriptors)

--- Episode 46/50 ---
Episode 46 - Epsilon: 0.798 (79.8% random, 20.2% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 13
  New selection: [13]
  Calculating reward for descriptors: [13]
  Total reward: 1.4035, Per descriptor: 1.4035
Step 1: Currently selected descriptors: [13]
  Action chosen: ADD descriptor 3
  New selection: [3, 13]
  Calculating reward for descriptors: [3, 13]
  Total reward: -4.3741, Per descriptor: -2.1871
Step 2: Currently selected descriptors: [3, 13]
  Action chosen: ADD descriptor 8
  New selection: [3, 8, 13]
  Calculating reward for descriptors: [3, 8, 13]
  Total reward: -4.5988, Per descriptor: -1.5329
Step 3: Currently selected descriptors: [3, 8, 13]
  Action chosen: ADD descriptor 1
  New selection: [1, 3, 8, 13]
  Calculating reward for descriptors: [1, 3, 8, 13]
  Total reward: -4.5635, Per descriptor: -1.1409
Step 4: Currently selected descriptors: [1, 3, 8, 13]
  Action chosen: ADD descriptor 0
  New selection: [0, 1, 3, 8, 13]
  Calculating reward for descriptors: [0, 1, 3, 8, 13]
  Total reward: -4.5778, Per descriptor: -0.9156
Step 5: Currently selected descriptors: [0, 1, 3, 8, 13]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 3, 7, 8, 13]
  Calculating reward for descriptors: [0, 1, 3, 7, 8, 13]
  Total reward: -4.4580, Per descriptor: -0.7430
Step 6: Currently selected descriptors: [0, 1, 3, 7, 8, 13]
  Action chosen: ADD descriptor 5
  New selection: [0, 1, 3, 5, 7, 8, 13]
  Calculating reward for descriptors: [0, 1, 3, 5, 7, 8, 13]
  Total reward: -4.4317, Per descriptor: -0.6331
Step 7: Currently selected descriptors: [0, 1, 3, 5, 7, 8, 13]
  Action chosen: REMOVE descriptor 1
  New selection: [0, 3, 5, 7, 8, 13]
  Calculating reward for descriptors: [0, 3, 5, 7, 8, 13]
  Total reward: -4.3961, Per descriptor: -0.7327
Step 8: Currently selected descriptors: [0, 3, 5, 7, 8, 13]
  Action chosen: REMOVE descriptor 7
  New selection: [0, 3, 5, 8, 13]
  Calculating reward for descriptors: [0, 3, 5, 8, 13]
  Total reward: -4.4927, Per descriptor: -0.8985
Step 9: Currently selected descriptors: [0, 3, 5, 8, 13]
  Action chosen: ADD descriptor 16
  New selection: [0, 3, 5, 8, 13, 16]
  Calculating reward for descriptors: [0, 3, 5, 8, 13, 16]
  Total reward: -4.4001, Per descriptor: -0.7334
Step 10: Currently selected descriptors: [0, 3, 5, 8, 13, 16]
  Action chosen: ADD descriptor 2
  New selection: [0, 2, 3, 5, 8, 13, 16]
  Calculating reward for descriptors: [0, 2, 3, 5, 8, 13, 16]
  Total reward: -4.4514, Per descriptor: -0.6359
Step 11: Currently selected descriptors: [0, 2, 3, 5, 8, 13, 16]
  Action chosen: REMOVE descriptor 3
  New selection: [0, 2, 5, 8, 13, 16]
  Calculating reward for descriptors: [0, 2, 5, 8, 13, 16]
  Total reward: -4.4582, Per descriptor: -0.7430
Step 12: Currently selected descriptors: [0, 2, 5, 8, 13, 16]
  Action chosen: REMOVE descriptor 13
  New selection: [0, 2, 5, 8, 16]
  Calculating reward for descriptors: [0, 2, 5, 8, 16]
  Total reward: -4.3951, Per descriptor: -0.8790
Step 13: Currently selected descriptors: [0, 2, 5, 8, 16]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 2, 5, 8, 16]
  Calculating reward for descriptors: [0, 1, 2, 5, 8, 16]
  Total reward: -4.4577, Per descriptor: -0.7429
Step 14: Currently selected descriptors: [0, 1, 2, 5, 8, 16]
  Action chosen: ADD descriptor 11
  New selection: [0, 1, 2, 5, 8, 11, 16]
  Calculating reward for descriptors: [0, 1, 2, 5, 8, 11, 16]
  Total reward: -4.4286, Per descriptor: -0.6327
Step 15: Currently selected descriptors: [0, 1, 2, 5, 8, 11, 16]
  Action chosen: ADD descriptor 14
  New selection: [0, 1, 2, 5, 8, 11, 14, 16]
  Calculating reward for descriptors: [0, 1, 2, 5, 8, 11, 14, 16]
  Total reward: -4.3674, Per descriptor: -0.5459
Step 16: Currently selected descriptors: [0, 1, 2, 5, 8, 11, 14, 16]
  Action chosen: ADD descriptor 9
  New selection: [0, 1, 2, 5, 8, 9, 11, 14, 16]
  Calculating reward for descriptors: [0, 1, 2, 5, 8, 9, 11, 14, 16]
  Total reward: -4.3939, Per descriptor: -0.4882
Step 17: Currently selected descriptors: [0, 1, 2, 5, 8, 9, 11, 14, 16]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 1003 experiences...
  DQN training loss: 3824211.000000
Episode 46 Summary:
  Total reward: -69.8416
  Steps taken: 17
  Final descriptors: 9
  Epsilon: 0.794 (79.4% random, 20.6% DQN)
  Avg last 10 episodes: -104.7526
  Best so far: 1.5090 (1 descriptors)

--- Episode 47/50 ---
Episode 47 - Epsilon: 0.794 (79.4% random, 20.6% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 18
  New selection: [18]
  Calculating reward for descriptors: [18]
  Total reward: 1.5359, Per descriptor: 1.5359
Step 1: Currently selected descriptors: [18]
  Action chosen: ADD descriptor 17
  New selection: [17, 18]
  Calculating reward for descriptors: [17, 18]
  Total reward: -4.6586, Per descriptor: -2.3293
Step 2: Currently selected descriptors: [17, 18]
  Action chosen: ADD descriptor 8
  New selection: [8, 17, 18]
  Calculating reward for descriptors: [8, 17, 18]
  Total reward: -4.4880, Per descriptor: -1.4960
Step 3: Currently selected descriptors: [8, 17, 18]
  Action chosen: REMOVE descriptor 17
  New selection: [8, 18]
  Calculating reward for descriptors: [8, 18]
  Total reward: -4.4069, Per descriptor: -2.2035
Step 4: Currently selected descriptors: [8, 18]
  Action chosen: ADD descriptor 14
  New selection: [8, 14, 18]
  Calculating reward for descriptors: [8, 14, 18]
  Total reward: -4.2681, Per descriptor: -1.4227
Step 5: Currently selected descriptors: [8, 14, 18]
  Action chosen: ADD descriptor 7
  New selection: [7, 8, 14, 18]
  Calculating reward for descriptors: [7, 8, 14, 18]
  Total reward: -4.2131, Per descriptor: -1.0533
Step 6: Currently selected descriptors: [7, 8, 14, 18]
  Action chosen: ADD descriptor 10
  New selection: [7, 8, 10, 14, 18]
  Calculating reward for descriptors: [7, 8, 10, 14, 18]
  Total reward: -4.2849, Per descriptor: -0.8570
Step 7: Currently selected descriptors: [7, 8, 10, 14, 18]
  Action chosen: ADD descriptor 5
  New selection: [5, 7, 8, 10, 14, 18]
  Calculating reward for descriptors: [5, 7, 8, 10, 14, 18]
  Total reward: -4.3193, Per descriptor: -0.7199
Step 8: Currently selected descriptors: [5, 7, 8, 10, 14, 18]
  Action chosen: REMOVE descriptor 5
  New selection: [7, 8, 10, 14, 18]
  Calculating reward for descriptors: [7, 8, 10, 14, 18]
  Total reward: -4.2849, Per descriptor: -0.8570
Step 9: Currently selected descriptors: [7, 8, 10, 14, 18]
  Action chosen: REMOVE descriptor 10
  New selection: [7, 8, 14, 18]
  Calculating reward for descriptors: [7, 8, 14, 18]
  Total reward: -4.2131, Per descriptor: -1.0533
Step 10: Currently selected descriptors: [7, 8, 14, 18]
  Action chosen: ADD descriptor 6
  New selection: [6, 7, 8, 14, 18]
  Calculating reward for descriptors: [6, 7, 8, 14, 18]
  Total reward: -4.3073, Per descriptor: -0.8615
Step 11: Currently selected descriptors: [6, 7, 8, 14, 18]
  Action chosen: REMOVE descriptor 7
  New selection: [6, 8, 14, 18]
  Calculating reward for descriptors: [6, 8, 14, 18]
  Total reward: -4.4080, Per descriptor: -1.1020
Step 12: Currently selected descriptors: [6, 8, 14, 18]
  Action chosen: ADD descriptor 19
  New selection: [6, 8, 14, 18, 19]
  Calculating reward for descriptors: [6, 8, 14, 18, 19]
  Total reward: -4.3760, Per descriptor: -0.8752
Step 13: Currently selected descriptors: [6, 8, 14, 18, 19]
  Action chosen: ADD descriptor 7
  New selection: [6, 7, 8, 14, 18, 19]
  Calculating reward for descriptors: [6, 7, 8, 14, 18, 19]
  Total reward: -4.2992, Per descriptor: -0.7165
Step 14: Currently selected descriptors: [6, 7, 8, 14, 18, 19]
  Action chosen: ADD descriptor 13
  New selection: [6, 7, 8, 13, 14, 18, 19]
  Calculating reward for descriptors: [6, 7, 8, 13, 14, 18, 19]
  Total reward: -4.3522, Per descriptor: -0.6217
Step 15: Currently selected descriptors: [6, 7, 8, 13, 14, 18, 19]
  Action chosen: ADD descriptor 11
  New selection: [6, 7, 8, 11, 13, 14, 18, 19]
  Calculating reward for descriptors: [6, 7, 8, 11, 13, 14, 18, 19]
  Total reward: -4.4904, Per descriptor: -0.5613
Step 16: Currently selected descriptors: [6, 7, 8, 11, 13, 14, 18, 19]
  Action chosen: ADD descriptor 16
  New selection: [6, 7, 8, 11, 13, 14, 16, 18, 19]
  Calculating reward for descriptors: [6, 7, 8, 11, 13, 14, 16, 18, 19]
  Total reward: -4.4817, Per descriptor: -0.4980
Step 17: Currently selected descriptors: [6, 7, 8, 11, 13, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [6, 8, 11, 13, 14, 16, 18, 19]
  Calculating reward for descriptors: [6, 8, 11, 13, 14, 16, 18, 19]
  Total reward: -4.3511, Per descriptor: -0.5439
Step 18: Currently selected descriptors: [6, 8, 11, 13, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 13
  New selection: [6, 8, 11, 14, 16, 18, 19]
  Calculating reward for descriptors: [6, 8, 11, 14, 16, 18, 19]
  Total reward: -4.3112, Per descriptor: -0.6159
Step 19: Currently selected descriptors: [6, 8, 11, 14, 16, 18, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [6, 8, 11, 14, 16, 18]
  Calculating reward for descriptors: [6, 8, 11, 14, 16, 18]
  Total reward: -4.3308, Per descriptor: -0.7218
Step 20: Currently selected descriptors: [6, 8, 11, 14, 16, 18]
  Action chosen: ADD descriptor 1
  New selection: [1, 6, 8, 11, 14, 16, 18]
  Calculating reward for descriptors: [1, 6, 8, 11, 14, 16, 18]
  Total reward: -4.3788, Per descriptor: -0.6255
Step 21: Currently selected descriptors: [1, 6, 8, 11, 14, 16, 18]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 1024 experiences...
  DQN training loss: 6446542.500000
Episode 47 Summary:
  Total reward: -85.6877
  Steps taken: 21
  Final descriptors: 7
  Epsilon: 0.790 (79.0% random, 21.0% DQN)
  Avg last 10 episodes: -106.3959
  Best so far: 1.5090 (1 descriptors)

--- Episode 48/50 ---
Episode 48 - Epsilon: 0.790 (79.0% random, 21.0% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 16
  New selection: [16]
  Calculating reward for descriptors: [16]
  Total reward: 1.5951, Per descriptor: 1.5951
Step 1: Currently selected descriptors: [16]
  Action chosen: REMOVE descriptor 16
  New selection: []
  Calculating reward for descriptors: []
  Total reward: 0.0000, Per descriptor: 0.0000
Step 2: Currently selected descriptors: None
  Action chosen: ADD descriptor 9
  New selection: [9]
  Calculating reward for descriptors: [9]
  Total reward: 1.2022, Per descriptor: 1.2022
Step 3: Currently selected descriptors: [9]
  Action chosen: ADD descriptor 13
  New selection: [9, 13]
  Calculating reward for descriptors: [9, 13]
  Total reward: -5.7659, Per descriptor: -2.8830
Step 4: Currently selected descriptors: [9, 13]
  Action chosen: ADD descriptor 1
  New selection: [1, 9, 13]
  Calculating reward for descriptors: [1, 9, 13]
  Total reward: -4.9117, Per descriptor: -1.6372
Step 5: Currently selected descriptors: [1, 9, 13]
  Action chosen: ADD descriptor 4
  New selection: [1, 4, 9, 13]
  Calculating reward for descriptors: [1, 4, 9, 13]
  Total reward: -4.7403, Per descriptor: -1.1851
Step 6: Currently selected descriptors: [1, 4, 9, 13]
  Action chosen: REMOVE descriptor 13
  New selection: [1, 4, 9]
  Calculating reward for descriptors: [1, 4, 9]
  Total reward: -4.6499, Per descriptor: -1.5500
Step 7: Currently selected descriptors: [1, 4, 9]
  Action chosen: ADD descriptor 19
  New selection: [1, 4, 9, 19]
  Calculating reward for descriptors: [1, 4, 9, 19]
  Total reward: -4.5385, Per descriptor: -1.1346
Step 8: Currently selected descriptors: [1, 4, 9, 19]
  Action chosen: ADD descriptor 7
  New selection: [1, 4, 7, 9, 19]
  Calculating reward for descriptors: [1, 4, 7, 9, 19]
  Total reward: -4.3760, Per descriptor: -0.8752
Step 9: Currently selected descriptors: [1, 4, 7, 9, 19]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 4, 9, 19]
  Calculating reward for descriptors: [1, 4, 9, 19]
  Total reward: -4.5385, Per descriptor: -1.1346
Step 10: Currently selected descriptors: [1, 4, 9, 19]
  Action chosen: REMOVE descriptor 9
  New selection: [1, 4, 19]
  Calculating reward for descriptors: [1, 4, 19]
  Total reward: -4.6241, Per descriptor: -1.5414
Step 11: Currently selected descriptors: [1, 4, 19]
  Action chosen: ADD descriptor 14
  New selection: [1, 4, 14, 19]
  Calculating reward for descriptors: [1, 4, 14, 19]
  Total reward: -4.4149, Per descriptor: -1.1037
Step 12: Currently selected descriptors: [1, 4, 14, 19]
  Action chosen: ADD descriptor 6
  New selection: [1, 4, 6, 14, 19]
  Calculating reward for descriptors: [1, 4, 6, 14, 19]
  Total reward: -4.4781, Per descriptor: -0.8956
Step 13: Currently selected descriptors: [1, 4, 6, 14, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [1, 4, 6, 14]
  Calculating reward for descriptors: [1, 4, 6, 14]
  Total reward: -4.5337, Per descriptor: -1.1334
Step 14: Currently selected descriptors: [1, 4, 6, 14]
  Action chosen: ADD descriptor 7
  New selection: [1, 4, 6, 7, 14]
  Calculating reward for descriptors: [1, 4, 6, 7, 14]
  Total reward: -4.3717, Per descriptor: -0.8743
Step 15: Currently selected descriptors: [1, 4, 6, 7, 14]
  Action chosen: ADD descriptor 11
  New selection: [1, 4, 6, 7, 11, 14]
  Calculating reward for descriptors: [1, 4, 6, 7, 11, 14]
  Total reward: -4.6364, Per descriptor: -0.7727
Step 16: Currently selected descriptors: [1, 4, 6, 7, 11, 14]
  Action chosen: ADD descriptor 9
  New selection: [1, 4, 6, 7, 9, 11, 14]
  Calculating reward for descriptors: [1, 4, 6, 7, 9, 11, 14]
  Total reward: -4.5494, Per descriptor: -0.6499
Step 17: Currently selected descriptors: [1, 4, 6, 7, 9, 11, 14]
  Action chosen: REMOVE descriptor 7
  New selection: [1, 4, 6, 9, 11, 14]
  Calculating reward for descriptors: [1, 4, 6, 9, 11, 14]
  Total reward: -4.3704, Per descriptor: -0.7284
Step 18: Currently selected descriptors: [1, 4, 6, 9, 11, 14]
  Action chosen: REMOVE descriptor 11
  New selection: [1, 4, 6, 9, 14]
  Calculating reward for descriptors: [1, 4, 6, 9, 14]
  Total reward: -4.4857, Per descriptor: -0.8971
Step 19: Currently selected descriptors: [1, 4, 6, 9, 14]
  Action chosen: ADD descriptor 18
  New selection: [1, 4, 6, 9, 14, 18]
  Calculating reward for descriptors: [1, 4, 6, 9, 14, 18]
  Total reward: -4.5482, Per descriptor: -0.7580
Step 20: Currently selected descriptors: [1, 4, 6, 9, 14, 18]
  Action chosen: REMOVE descriptor 18
  New selection: [1, 4, 6, 9, 14]
  Calculating reward for descriptors: [1, 4, 6, 9, 14]
  Total reward: -4.4857, Per descriptor: -0.8971
Step 21: Currently selected descriptors: [1, 4, 6, 9, 14]
  Action chosen: ADD descriptor 10
  New selection: [1, 4, 6, 9, 10, 14]
  Calculating reward for descriptors: [1, 4, 6, 9, 10, 14]
  Total reward: -4.5191, Per descriptor: -0.7532
Step 22: Currently selected descriptors: [1, 4, 6, 9, 10, 14]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 1046 experiences...
  DQN training loss: 10957000.000000
Episode 48 Summary:
  Total reward: -84.7409
  Steps taken: 22
  Final descriptors: 6
  Epsilon: 0.786 (78.6% random, 21.4% DQN)
  Avg last 10 episodes: -112.0561
  Best so far: 1.5090 (1 descriptors)

--- Episode 49/50 ---
Episode 49 - Epsilon: 0.786 (78.6% random, 21.4% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 1046 experiences...
  DQN training loss: 4735807.000000
Episode 49 Summary:
  Total reward: 0.0000
  Steps taken: 0
  Final descriptors: 0
  Epsilon: 0.782 (78.2% random, 21.8% DQN)
  Avg last 10 episodes: -100.7742
  Best so far: 1.5090 (1 descriptors)

--- Episode 50/50 ---
Episode 50 - Epsilon: 0.782 (78.2% random, 21.8% DQN)
Starting with empty feature set...
Initial state shape: (49,)
Step 0: Currently selected descriptors: None
  Action chosen: ADD descriptor 9
  New selection: [9]
  Calculating reward for descriptors: [9]
  Total reward: 1.2022, Per descriptor: 1.2022
Step 1: Currently selected descriptors: [9]
  Action chosen: ADD descriptor 5
  New selection: [5, 9]
  Calculating reward for descriptors: [5, 9]
  Total reward: -4.6402, Per descriptor: -2.3201
Step 2: Currently selected descriptors: [5, 9]
  Action chosen: ADD descriptor 16
  New selection: [5, 9, 16]
  Calculating reward for descriptors: [5, 9, 16]
  Total reward: -4.2692, Per descriptor: -1.4231
Step 3: Currently selected descriptors: [5, 9, 16]
  Action chosen: ADD descriptor 2
  New selection: [2, 5, 9, 16]
  Calculating reward for descriptors: [2, 5, 9, 16]
  Total reward: -4.3591, Per descriptor: -1.0898
Step 4: Currently selected descriptors: [2, 5, 9, 16]
  Action chosen: ADD descriptor 18
  New selection: [2, 5, 9, 16, 18]
  Calculating reward for descriptors: [2, 5, 9, 16, 18]
  Total reward: -4.4474, Per descriptor: -0.8895
Step 5: Currently selected descriptors: [2, 5, 9, 16, 18]
  Action chosen: REMOVE descriptor 9
  New selection: [2, 5, 16, 18]
  Calculating reward for descriptors: [2, 5, 16, 18]
  Total reward: -4.4828, Per descriptor: -1.1207
Step 6: Currently selected descriptors: [2, 5, 16, 18]
  Action chosen: ADD descriptor 19
  New selection: [2, 5, 16, 18, 19]
  Calculating reward for descriptors: [2, 5, 16, 18, 19]
  Total reward: -4.4516, Per descriptor: -0.8903
Step 7: Currently selected descriptors: [2, 5, 16, 18, 19]
  Action chosen: ADD descriptor 12
  New selection: [2, 5, 12, 16, 18, 19]
  Calculating reward for descriptors: [2, 5, 12, 16, 18, 19]
  Total reward: -4.4304, Per descriptor: -0.7384
Step 8: Currently selected descriptors: [2, 5, 12, 16, 18, 19]
  Action chosen: REMOVE descriptor 2
  New selection: [5, 12, 16, 18, 19]
  Calculating reward for descriptors: [5, 12, 16, 18, 19]
  Total reward: -4.4032, Per descriptor: -0.8806
Step 9: Currently selected descriptors: [5, 12, 16, 18, 19]
  Action chosen: REMOVE descriptor 18
  New selection: [5, 12, 16, 19]
  Calculating reward for descriptors: [5, 12, 16, 19]
  Total reward: -4.3697, Per descriptor: -1.0924
Step 10: Currently selected descriptors: [5, 12, 16, 19]
  Action chosen: ADD descriptor 11
  New selection: [5, 11, 12, 16, 19]
  Calculating reward for descriptors: [5, 11, 12, 16, 19]
  Total reward: -4.5980, Per descriptor: -0.9196
Step 11: Currently selected descriptors: [5, 11, 12, 16, 19]
  Action chosen: REMOVE descriptor 19
  New selection: [5, 11, 12, 16]
  Calculating reward for descriptors: [5, 11, 12, 16]
  Total reward: -4.8806, Per descriptor: -1.2201
Step 12: Currently selected descriptors: [5, 11, 12, 16]
  Action chosen: ADD descriptor 19
  New selection: [5, 11, 12, 16, 19]
  Calculating reward for descriptors: [5, 11, 12, 16, 19]
  Total reward: -4.5980, Per descriptor: -0.9196
Step 13: Currently selected descriptors: [5, 11, 12, 16, 19]
  Action chosen: ADD descriptor 9
  New selection: [5, 9, 11, 12, 16, 19]
  Calculating reward for descriptors: [5, 9, 11, 12, 16, 19]
  Total reward: -4.4826, Per descriptor: -0.7471
Step 14: Currently selected descriptors: [5, 9, 11, 12, 16, 19]
  Action chosen: ADD descriptor 0
  New selection: [0, 5, 9, 11, 12, 16, 19]
  Calculating reward for descriptors: [0, 5, 9, 11, 12, 16, 19]
  Total reward: -4.4522, Per descriptor: -0.6360
Step 15: Currently selected descriptors: [0, 5, 9, 11, 12, 16, 19]
  Action chosen: ADD descriptor 15
  New selection: [0, 5, 9, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 5, 9, 11, 12, 15, 16, 19]
  Total reward: -4.5740, Per descriptor: -0.5717
Step 16: Currently selected descriptors: [0, 5, 9, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 10
  New selection: [0, 5, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 5, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.5269, Per descriptor: -0.5030
Step 17: Currently selected descriptors: [0, 5, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: ADD descriptor 1
  New selection: [0, 1, 5, 9, 10, 11, 12, 15, 16, 19]
  Calculating reward for descriptors: [0, 1, 5, 9, 10, 11, 12, 15, 16, 19]
  Total reward: -4.5051, Per descriptor: -0.4505
Step 18: Currently selected descriptors: [0, 1, 5, 9, 10, 11, 12, 15, 16, 19]
  Action chosen: REMOVE descriptor 16
  New selection: [0, 1, 5, 9, 10, 11, 12, 15, 19]
  Calculating reward for descriptors: [0, 1, 5, 9, 10, 11, 12, 15, 19]
  Total reward: -4.4783, Per descriptor: -0.4976
Step 19: Currently selected descriptors: [0, 1, 5, 9, 10, 11, 12, 15, 19]
  Action chosen: ADD descriptor 7
  New selection: [0, 1, 5, 7, 9, 10, 11, 12, 15, 19]
  Calculating reward for descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 15, 19]
  Total reward: -4.6112, Per descriptor: -0.4611
Step 20: Currently selected descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 15, 19]
  Action chosen: ADD descriptor 18
  New selection: [0, 1, 5, 7, 9, 10, 11, 12, 15, 18, 19]
  Calculating reward for descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 15, 18, 19]
  Total reward: -4.5856, Per descriptor: -0.4169
Step 21: Currently selected descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 15, 18, 19]
  Action chosen: ADD descriptor 13
  New selection: [0, 1, 5, 7, 9, 10, 11, 12, 13, 15, 18, 19]
  Calculating reward for descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 13, 15, 18, 19]
  Total reward: -4.5702, Per descriptor: -0.3808
Step 22: Currently selected descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 13, 15, 18, 19]
  Action chosen: REMOVE descriptor 15
  New selection: [0, 1, 5, 7, 9, 10, 11, 12, 13, 18, 19]
  Calculating reward for descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 13, 18, 19]
  Total reward: -4.5516, Per descriptor: -0.4138
Step 23: Currently selected descriptors: [0, 1, 5, 7, 9, 10, 11, 12, 13, 18, 19]
  Action chosen: STOP
  Agent chose to STOP
  Training DQN with 1069 experiences...
  DQN training loss: 9058685.000000
Episode 50 Summary:
  Total reward: -98.0655
  Steps taken: 23
  Final descriptors: 11
  Epsilon: 0.778 (77.8% random, 22.2% DQN)
  Avg last 10 episodes: -97.4036
  Best so far: 1.5090 (1 descriptors)

Training completed!
Best descriptors found: [12]
Number of best descriptors: 1
Final validation accuracy: 0.9026
Selected descriptor indices: [12]

================================================================================
DESCRIPTOR RANKING BY USAGE
================================================================================
Rank | Descriptor | Times Used | Total Reward
-----------------------------------------------
   1 | Desc20     |       577  |   -338.7964
   2 | Desc17     |       527  |   -301.1458
   3 | Desc 5     |       467  |   -274.3960
   4 | Desc13     |       434  |   -247.3402
   5 | Desc 2     |       430  |   -241.1691
   6 | Desc10     |       413  |   -241.4270
   7 | Desc 9     |       412  |   -230.1279
   8 | Desc 6     |       407  |   -241.6045
   9 | Desc 1     |       382  |   -214.1336
  10 | Desc18     |       378  |   -210.7254
  11 | Desc12     |       364  |   -202.4892
  12 | Desc16     |       364  |   -194.6049
  13 | Desc 7     |       358  |   -213.0635
  14 | Desc15     |       353  |   -202.5979
  15 | Desc 8     |       352  |   -192.3298
  16 | Desc19     |       348  |   -204.8454
  17 | Desc14     |       321  |   -184.4035
  18 | Desc 3     |       304  |   -176.0253
  19 | Desc11     |       297  |   -180.6846
  20 | Desc 4     |       247  |   -147.8586

Top Descriptors by Usage Frequency:
Top 4 most used: ['Desc20', 'Desc17', 'Desc5', 'Desc13']
Top 8 most used: ['Desc20', 'Desc17', 'Desc5', 'Desc13', 'Desc2', 'Desc10', 'Desc9', 'Desc6']
Top 12 most used: ['Desc20', 'Desc17', 'Desc5', 'Desc13', 'Desc2', 'Desc10', 'Desc9', 'Desc6', 'Desc1', 'Desc18', 'Desc12', 'Desc16']

Column graph saved to: result_rl_single_agent/descriptor_rewards_column_graph.png
PDF version also saved: result_rl_single_agent/descriptor_rewards_column_graph.pdf
